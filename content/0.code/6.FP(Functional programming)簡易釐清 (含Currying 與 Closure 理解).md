# A Simplified Clarification of Functional Programming (Including Currying and Closure)

###### tags: `Code Sense` `Design-Pattern`

I was recently watching a YouTube video on [Currying](https://www.youtube.com/watch?v=5lY7caTLyXA&lc=Ugwm-V71T7Ah3fVPSt14AaABAg&ab_channel=%E8%B5%B0%E6%AD%AA%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%B8%ABJames) when a comment piqued my interest in the role of closures in functional programming. As an OOP developer who hasn't done much FP in years, I decided to revisit these concepts. This post is a personal reflection on my understanding of Currying and closures, and an attempt to clarify the differences between OOP and FP, especially from the perspective of someone who has been primarily focused on object-oriented programming.


## Differences between OOP and FP in Pure Data Processing Scenarios

OOP excels in designing real-world architectures using objects and design patterns. However, FP seems to be more prevalent in data processing applications, often presented in the form of APIs. This is my initial understanding, and I aim to delve deeper into this topic through further research.

### Mathematical and Scientific Computing

A brief exploration of the literature reveals that FP draws its concepts and philosophy from a mathematical logic system known as lambda calculus. In lambda calculus, everything is a function, and the only operation is application. This simple and unified framework aligns closely with the mathematical concept of functions, aiding in the construction of concise, predictable, and easily reasoned programs.


 - Purity: In mathematics, the value of a function depends solely on its inputs, independent of any external state. This aligns with the concept of functions in lambda calculus and forms the foundation of "pure functions" in functional programming.
 
 - First-class functions: In mathematics, functions can be passed as inputs to other functions and can also be returned as outputs from other functions. This aligns with the concept of functions in lambda calculus and is the basis for the "functions as first-class citizens" concept in functional programming.


Therefore, it can be said that FP was deeply influenced by mathematics from its inception. However, this does not mean that functional programming is only suitable for mathematical problems. In fact, functional programming concepts such as immutability, **pure functions**, and **function composition** are useful in many different application contexts and domains.

Those who are more familiar with OOP might feel that these characteristics can also be implemented conceptually in OOP. However, in scenarios where data needs to be processed in large-scale parallel and asynchronous operations, FP's immutability and statelessness can offer significant advantages.

Another simpler example to illustrate the difference in data applications is as follows. Suppose we have a task to square each element in a dataset (e.g., a list of numbers). In an object-oriented implementation, we might create a DataSet class and provide a method for this class to perform the squaring operation:


```python
class DataSet:
    def __init__(self, data):
        self.data = data

    def square(self):
        for i in range(len(self.data)):
            self.data[i] = self.data[i] ** 2
```

The context is as follows:

```python
data = DataSet([1, 2, 3, 4, 5])
data.square()
print(data.data)  # Outputs: [1, 4, 9, 16, 25]
```

The problem with this implementation is that whenever we need to perform a new operation on the data (such as taking the square root, logarithm, etc.), we need to add a new method to the DataSet class. If there are many types of operations, the DataSet class will become very bloated.

In FP design, we abstract these operations into functions, and these functions can be easily applied to each element in the dataset as follows:

```python
def square(x):
    return x ** 2

data = [1, 2, 3, 4, 5]
data = list(map(square, data))

print(data)  # Outputs: [1, 4, 9, 16, 25]
```

In this scenario, when we need to add a new operation, we simply add a new function without modifying the data structure. Moreover, these functions can be reused for any type of dataset, not just our defined DataSet class. Therefore, for situations that require the same operations on a large amount of data, the functional programming style often provides greater flexibility and reusability.

You might think this example is a bit contrived and wonder why anyone would design objects for this application. You're absolutely right! FP tends to express computation as the evaluation of mathematical functions, focusing more on data manipulation and transformation rather than encapsulating data and behavior into objects as in object-oriented programming and describing the computational process using object interactions.

This doesn't mean that FP is unsuitable for scenarios that require object design, but rather that they have different approaches to solving problems. In fact, in many modern languages, FP and OOP are both considered important parts of the language and can be used together in many scenarios.

In the aforementioned example, if these data were encapsulated in objects in a more complex system and the objects had their own behaviors and states, then using OOP might be more appropriate. However, when we need to process large amounts of data and perform various transformations and manipulations on this data, the higher-order functions like map, reduce, and filter provided by FP allow us to describe these operations more directly.

With this explanation, you should have a clearer understanding of the differences between FP and OOP in the context of mathematical and scientific computing applications.

### Big data processing and analytics

The combination of functional programming (FP) and immutable data structures is highly effective in big data processing and analysis applications. For example, Apache Spark is an open-source cluster computing system for big data processing written in Scala, a language that supports FP, and leverages many FP concepts such as immutable datasets and higher-order functions.

Let's delve deeper into Apache Spark and the application of functional programming in big data processing.

Apache Spark is an open-source cluster computing system for large-scale data processing. It provides a high-level API for data manipulation called Resilient Distributed Dataset (RDD). An RDD is an immutable, distributed collection of elements of the same type.

In Spark, RDDs are the primary data structure, and all operations (such as map, filter, reduce) are performed on RDDs. Since RDDs are immutable, once created, they cannot be modified, allowing Spark to effectively track data lineage and changes in large-scale parallel computations.

Here's a simple example of a map-reduce operation using Spark's Python API (PySpark):

```python
from pyspark import SparkContext

sc = SparkContext("local", "count app")
nums = sc.parallelize([1, 2, 3, 4, 5])

# Add one to each number
add_one = nums.map(lambda x: x + 1)

#  Calculate the sum of all numbers
sum = add_one.reduce(lambda a, b: a + b)

print(sum)  # Output: 20

```
In this example, we first create an RDD (nums) and then use the map operation to increment each number in the RDD by one. Following that, we use the reduce operation to sum all the numbers. These operations are performed in the form of functions (lambda functions) and can be executed in parallel across multiple nodes automatically.

This is a practical application of functional programming in big data processing. By utilizing immutable data structures (RDDs) and higher-order functions (map, reduce, etc.), Spark enables the abstraction of large-scale data processing problems and provides an efficient, concise, and scalable solution.

If this example is too complex, let's consider a simpler one to understand the advantages of functional programming in big data processing. Suppose we have a dataset containing millions of records, each representing a person's personal information (e.g., name, age, address). Our task is to find all individuals who are over 18 years old.

In an object-oriented approach, we might handle this as follows:

```python

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

people = [...]  # Assuming this is a huge list containing millions of Person objects.

adults = []
for person in people:
    if person.age >= 18:
        adults.append(person)

```

In functional programming, this task can be abstracted as a filtering operation.

```python
# Assume this is a list containing millions of tuples, where each tuple represents a person's information.
people = [...]   

adults = filter(lambda person: person[1] >= 18, people)

```

In this example, the built-in filter function and a lambda function are used to achieve the goal. This approach is more concise and intuitive, and it can automatically leverage parallel processing for faster computation (e.g., when using a distributed computing framework like PySpark).

Speaking of which, when we look back at the example, FP designs are characterized by immutability and pure functions (where the output depends solely on the input). Therefore, they are particularly well-suited for data processing applications. However, the real world is not entirely pure. Operations like fetching data from a database and displaying it on the frontend involve many changes to state (different from data state). In these cases, OOP would be a better choice.


## Closures and Currying in Functional Programming


### Closures: Capturing State in Functions
While functional programming emphasizes immutability, some data manipulation processes still require the use of state. In such cases, closures provide a more concise and advanced way to achieve this. A closure is a special type of function that can access and manipulate variables that are outside its own scope, even when the function is called from outside its defining scope. This is especially useful when creating functions that need to remember a specific state. In Python, closures allow a function to "remember" the environment in which it was defined. For example:

```python
def make_multiplier(x):
    def multiplier(n):
        return x * n
    return multiplier

times3 = make_multiplier(3)
print(times3(10))  # Outputs: 30

```

The multiplier(n) function in this example is a closure. Why is that? Because it "remembers" the environment where it was created. When we call make_multiplier(3), we're essentially creating a new multiplier(n) function. This function "knows" that x is 3 (and this state doesn't change), even though multiplier(n) is defined inside make_multiplier(x). When it's returned and assigned to the times3 variable, it's actually left the "scope" or "environment" of make_multiplier(x). In other words, the multiplier(n) function is being called outside of the make_multiplier(x) function.

To further emphasize this point, the multiplier(n) function is indeed being called outside of the make_multiplier(x) function.

In Python, when you define a function, that function has its own scope, meaning it can only directly access variables defined within itself. In the make_multiplier(x) function, the function can access the variable x because x is passed in as an argument.

Then, inside the make_multiplier(x) function, a new function multiplier(n) is defined. This new function can access n because n is passed in as an argument, but it can also access x, even though x is defined in the outer make_multiplier(x) function. This is because multiplier(n) is created within the scope of make_multiplier(x), so it has access to the scope of make_multiplier(x).

The multiplier(n) function is then returned as the return value of the make_multiplier(x) function. So when you call make_multiplier(3), you actually get a new function. When this new function is called, it will multiply the input value by 3.

When you assign the return value of make_multiplier(3) (which is the multiplier(n) function) to times3 and call times3(10), even though the multiplier(n) function is now being called outside of the make_multiplier(x) function, it still "remembers" the value of x (which is 3 in this case). When you call times3(10) (which is actually calling multiplier(10)), it knows to multiply 10 by 3 because it "remembers" that the value of x is 3.


**This is what we call a closure: a function that remembers and can access variables from its outer scope (the x in our example), even when it's called outside the scope where it was created.** In other words, multiplier(n) remembers the environment it was created in, and it still has the ability to remember and access variables from its outer function (make_multiplier(x)).


### Grasping the concept of Currying

Functional programming often involves composing functions, which can lead to more concise and readable code. Currying is a technique that transforms a function that takes multiple arguments into a sequence of functions that each take a single argument. For example, a function f(x, y) that takes two arguments can be curried into a function g(x) that takes one argument and returns another function. In this case, you can provide the first argument first (e.g., g(2)) and get a new function that takes the second argument and returns the final result (e.g., g(2)(3) returns the same result as f(2, 3)). Simply put, currying is a technique for transforming a multi-argument function into a sequence of single-argument functions.   

```python
def multiply(x):
    def multiply_x(y):
        return x * y
    return multiply_x

double = multiply(2)
print(double(5))  # Outputs: 10
```

Transforming a function multiply that takes two arguments into a function multiply_x that takes one argument and returns another function, which also takes one argument. We can observe that multiply_x is also a closure because it remembers the value of x. Although this example appears similar to a closure, there are still some differences in their applications... let's continue!

### Distinctions in application scenarios between Currying and Closure

Let's summarize:

Closure: The primary purpose of a closure is to "remember" variables from its outer function. Even when the inner function is returned and used elsewhere, it can still access and manipulate those variables, even if the original outer function has finished executing. This can be used to create stateful functions, meaning their behavior is influenced by their "environment". In the aforementioned example, multiplier(n) is a closure.

Currying: The main purpose of currying is to transform a function that takes multiple arguments into a sequence of functions that each take a single argument. This allows for more flexible use of functions, especially when functions are passed as arguments. In your second example, multiply(x) has been curried.

Imagine we're developing a game and want to count the player's score. We can use closures to implement this:

```python
def create_score_counter():
    score = 0
    def add_score(points):
        nonlocal score
        score += points
        return score
    return add_score

counter = create_score_counter()
print(counter(10))  # Outputs: 10
print(counter(20))  # Outputs: 30
```
The create_score_counter function returns an add_score function, which is a closure that remembers and modifies the score variable in its outer environment. Even after the create_score_counter function has finished executing, the add_score function can still access and modify the score variable.

In this example, a closure is a more intuitive and simpler approach to achieve the requirement. We need to record and update a "state" (score), and this state needs to be preserved across consecutive function calls. Closures allow us to bundle the state (score in this case) with the function that operates on the state (add_score), and this state will be "remembered" across subsequent function calls.

(Currying) is primarily used to transform a function that takes multiple arguments into a sequence of functions that each take a single argument. It is useful when we need to "fix" some of the arguments (or default parameters) of a function, and the remaining arguments are provided later. However, in this example, our primary need is to "record and update state", not just to "fix some arguments".   

In another scenario, suppose we are processing a list, and we want to apply a function to each element in the list. We can use currying to create a function that takes a function and a list as arguments, and then returns a new function that takes an element and applies the function we passed in earlier:

```python
def map_function(func):
    def apply_func_to_list(lst):
        return [func(x) for x in lst]
    return apply_func_to_list

double = lambda x: x * 2
map_double = map_function(double)

print(map_double([1, 2, 3, 4, 5]))  # Outputs: [2, 4, 6, 8, 10]
```

The map_function is essentially performing currying: it takes a function as an argument and returns a new function, apply_func_to_list. This new function accepts a list as an argument and applies the function passed to map_function to each element in the list.

This example does not require a "state" that needs to be maintained and updated. The map_function in this example can be seen as a curried function: it first takes a function func and then returns a new function apply_func_to_list, which takes a list lst and applies func to each element of lst.

This characteristic of receiving function arguments in stages allows you to fix some parameters in advance (in this case, func) and generate a new function to handle subsequent parameters (in this case, lst). This feature can make code more concise and flexible in certain situations. In contrast, closures are a concise way to manage and update state.


After reading this, you should have a clearer understanding of FP design concepts, as well as closures and currying. However, to truly grasp these concepts, you need to apply them in practical, context-specific design scenarios.


## Notes

currying can also be implemented in C# using delegates, as shown below:

```csharp
public static void Main()
{
    Func<int, Func<int, int>> curriedMultiply = MultiplyCurried();
    Func<int, int> multiplyBy2 = curriedMultiply(2);

    int result = multiplyBy2(3); // result will be 6
    Console.WriteLine(result);
}

static Func<int, Func<int, int>> MultiplyCurried()
{
    return a => b => a * b;
}
```

Although it can be implemented, the primary design of delegates is for event handling, asynchronous calls, and callback functions, which differs from the application of closures in the data world. In the realm of data analysis and processing, the primary purpose of closures is to "remember" variables from outer functions and manipulate them within the closure. This is particularly useful for scenarios where internal state needs to be maintained and updated. For example, when performing statistical calculations or counting, closures can make our code more concise and easier to understand.

Delegates, on the other hand, are applied in general software design areas such as event handling, asynchronous calls, and callback functions. A delegate is essentially an object that holds a reference to a function or method. When a delegate is invoked, it can call the function or method it references. This allows for dynamic changes to function or method behavior and makes code more flexible at runtime.

I feel that I can have a more comprehensive understanding of FP. Whenever I hear people say there are two opposing beliefs, I think it's because they don't have a complete understanding of OOP and FP, or they lack sufficient experience in applying them in appropriate scenarios, which leads to a bias towards one or the other.