[{"id":"content:0.code:1.Refcotr閱讀.md","path":"/code/refcotr","dir":"code","title":"重構筆記","description":"","keywords":["2019/11/13"],"body":"  重構筆記  2019/11/13   Lazy Class   別開創無所謂的Class(Ex 指宣告一個變數, Inline Class),邏輯資料相同可以使用繼承延伸,Super Class。要設計Class仙藥思考它的合理性。  Speculative Generality   在設計時，預留太多未來可能會用的擴充點。彈性使用Template模式，然後寫成介面，ConcreateClass去設計跟Imp。  遇到不能關閉的程式，要考慮好資源回收與OOM問題。\n   1.Collapse Hierachy  2.Inline Class  3.Remove Parameter  4.Remove Method  Temporay Field   Class欄位過多，在替代變數命名尚不清楚會讓開發者混淆，這是在開發過程中在需求還不清楚會常遇到，盡量避免這種狀況發生。  Message Chains(過度耦合訊息練)   Fun串Fun太多得意思....使用垂直折疊、提取或是使用委託與封裝，使用注入。  Middle Man(中間轉手人)   Class放與這個Class不相干的內容，邏輯提煉出來其他模組，或使用把功能寫成父類別繼承，或用注入盡量避免這件事情  Inappropriate Intimacy(互相依賴)   過度互相依賴，或是沒邏輯性的互相依賴(亂使用繼承)。 讀卡機讀取票卡例子(讀卡機，票卡自己也需判斷黑名單)。\n   1.可以定義一個卡片Interface(鎖卡，解卡，判斷)。此Interface讓讀卡機繼承，讓讀卡機注入...(依賴注入,RW定義一個介面，再去實作)  2.使用委託註冊介面. Call Back方式把有註冊過的方式拉進Class做處理。  Alternative Class with different Interface(異曲同工的類別)   做Extract SuperClass   Incomplete Libary Class(不完美程式庫類別)   如果要改一點類別庫直接修改，大改套模式..EX:套裝飾者模式,或使用繼承~~~ New程式碼直接延接  Data Class(純稚資料類別)   如果你有資料結構Class專門存取，很多Class會使用他，建議寫Get Set(c#直接產生)。  Refuesed Bequest(被拒絕的遺贈)   繼承錯誤.  Comments(過多的註釋)   包Package或好的命名可以避免"},{"id":"content:0.code:2.依賴注入(DI).md","path":"/code/(di)","dir":"code","title":"依賴注入(DI)","description":"DI在目前許多軟體架構中是不可或缺的設計架構功能之一，此章節會闡述DI精神及介紹.Net的DI使用。","keywords":["A. 依賴注入(Dependency Injection)","B. 容器概念","C. Ioc(Inversion of Control)控制反轉","D. C# DI 框架 [範例請點我]"],"body":"  DI在目前許多軟體架構中是不可或缺的設計架構功能之一，此章節會闡述DI精神及介紹.Net的DI使用。  A. 依賴注入(Dependency Injection)  先來講依賴跟注入的概念  a. Dependency  依賴如字面上所述，在軟體中，我們很常遇到物件彼此相依的狀況。如下圖，在做計算時需做Printer輸出資訊，因此Calculator物件會相依Printer物件，則在Instance Calculator物件時則就需要同步Instance Printer物件並帶入Calculator物件中。       public     class     Calculator\n   {\n         public     Printer     Printer   {  get  ;  private     set  }\n         public     Add  (  int     a  ,   int     b  ){\n             var     sum     =   a  +  b;\n           Printer.  ConsoleOut  (sum);\n       }\n         public     Calculator  (  Printer     printer  ){\n           Printer   =   printer;\n       }\n   }\n   public     class     Printer\n   {\n         public     void     ConsoleOut  (  string     txt  ) \n       {\n           Console.  WriteLine  (txt);\n       }\n   }\n   static     class     Program\n   {\n         static     void     Main  ()\n       {\n             var     printer     =     new     Printer  ();\n             var     calculator     =     new     Calculator  (printer);\n           calculator.  Add  (  1  +  1  ); \n       }\n   }  這例子為Calculator依賴Printer，所以控制權不是在Printer身上。什麼意思? 簡單來說當Printer有異動時，會有一定程度是影響到Calculator的。  對於物件依賴這件事情我在網上看到一個例子描述還蠻貼切的，今天有一名8+9在吸食毒品如下。8+9 以為自己吸食毒品只是滿足自己的快感，他還以為他自己的意志行為是被自己所掌控  錯!!!  其實8+9這時候所有的行為已經被毒品所控制，再也離不開毒品了。    b. Dependency With Interface  那我們該如何解除依賴關係? 一般來說，在實作方法時，我們會讓物件去相依介面，讓物件彼此因介面而解偶，如下圖       public     class     Calculator\n   {\n         public     IPrinter     Printer   {  get  ;  private     set  }\n         public     Add  (  int     a  ,   int     b  ){\n             var     sum     =   a  +  b;\n           Printer.  ConsoleOut  (sum);\n       }\n         public     Calculator  (  IPrinter     printer  ){\n           Printer   =   printer;\n       }\n   }\n   public     class     Printer  :  IPrinter\n   {\n         public     void     ConsoleOut  (  string     txt  ) \n       {\n           Console.  WriteLine  (txt);\n       }\n   }\n     public     interface     IPrinter  {\n         void     ConsoleOut  (  string     txt  );\n   }\n     static     class     Program\n   {\n         static     void     Main  ()\n       {\n             IPrinter     printer     =     new     Printer  ();\n             var     calculator     =     new     Calculator  (printer);\n           calculator.  Add  (  1  +  1  ); \n       }\n   }  因相依介面，若我們要抽換功能，例如原本的Console輸出改成輸出至記事本。只需要在新增一個記事本輸出方法，替換掉原本的28行的printer即可。而這狀況我們稱為Dependency Inversion Principle(DIP)，依賴倒轉原則。簡單來說就是解除高階模組和低階模組的依賴關係。   高低階模組定義   高階模組指的是呼叫者(Caller)-Calculator   低階模組就是被呼叫者(Callee)-Printer  我們再回到8+9例子，今天想要讓8+9改過向上，戒毒成為奮發向上的好青年。因為現在8+9直接依賴著毒品，我們讓8+9改成依賴藥品這個介面。    現在我們成功讓8+9依賴藥品而不是毒品。然後再將做一個健康食品的類別實作藥品，然後偷偷把毒品換成健康食品。這樣子8+9以為自己吃的藥品是毒品，實際上卻是每天吃健康食品，於是8+9頭腦變好了 走路也不晃了 考試也考100分成為國家的棟樑。  c. Injection  接著講注入，上述Calculator例子注入方式稱為建構子注入，其實注入平常我們就有在使用。一般人比較不會注意到這些行為其實就是一種注入。常見的注入模式有三種   建構子注入(Constructor Injection)  屬性注入(Property Injection)  方法注入(Method Injection)  建構子注入(Constructor Injection)     // 汽車的抽象介面\n   public     interface     ICar   {\n         // 行駛汽車\n         void     run  ();\n   }\n     // 司機的抽象介面\n   public     interface     IDriver   {\n         // 司機駕駛汽車\n         void     drive  ();\n   }\n     // 實作司機的抽象類別\n   public     class     Driver     implements     IDriver   {\n         private   ICar car;\n         // 建構子方式注入抽象類別\n         public     Driver  (ICar   car  ){\n             this  .car   =   car;\n       }    \n       @  Override\n         public     void     drive  () {\n           car.  run  ();\n       }\n   }  屬性注入(Property Injection)     // 汽車的抽象介面\n   public     interface     ICar   {\n         // 行駛汽車\n         void     run  ();\n   }\n     // 司機的抽象介面\n   public     interface     IDriver   {\n         // 司機駕駛汽車\n         void     drive  ();\n   }\n     // 實作司機的抽象類別\n   public     class     Driver     implements     IDriver   {\n         private   ICar car;\n         // 使用setter來傳遞物件 (c# get set)\n         public     setCar  (ICar   car  ){\n             this  .car   =   car;\n       }\n         \n       @  Override\n         public     void     drive  () {\n           car.  run  ();\n       }\n   }  方法注入(Property Injection)     // 汽車的抽象介面\n   public     interface     ICar   {\n         // 行駛汽車\n         void     run  ();\n   }\n    \n   // 司機的抽象介面\n   public     interface     IDriver   {\n         // 司機駕駛汽車\n         void     drive  (ICar   car  );\n   }\n       // 實作司機的抽象類別\n   public     class     Driver     implements     IDriver   {\n          // 使用介面來傳遞物件\n       @  Override\n         public     void     drive  (ICar   car  ) {\n           car.  run  ();\n       }\n   }   在了解Dependency與Injection後，應該就可以理解相依注入動作就在於在Instance物件後放置對應的相應物件中  B. 容器概念  上述DI概念講完後，接著我們要述說容器的概念。A章節提到關於相依的問題，雖然我們可以透過介面去作解偶。但一般在大型專案物件複雜度及數量一定會是更複雜的狀態。因此有了容器的機制設計產生。  容器的概念在於把物件全都收到一個盒子中，當要使用物件時再去盒子拿資料。有點像是打高爾夫球人員要打高爾夫時都會準備一個球袋把要用的球桿放進球袋中，並帶一個球僮陪伴在旁。當要使用哪一支高爾夫球桿時直接告訴球童即可。  a. 窮人與有錢人的依賴注入方式  上述講解完後，相信目前對相依注入及容器有一定的概念。而注入部分一般分成窮人注入與有錢人注入。   我們一般稱為Poor DI(Dependency Injection)，由使用者手動創建以new物件的方式，各自注入，除了麻煩外而且會有傳遞注入等等的問題。  有錢人的注入方式，我們一般都會使用DI容器來完成，由框架或類別庫撰寫的容器，提供物件給予使用者使用，猶如上述所講的球童跟高爾夫球員關係一樣。使用者只需要在撰寫程式前設定好物件後，就不需要在手動注入。  C. Ioc(Inversion of Control)控制反轉  窮人跟有錢人，我們當然選擇當有錢人!(使用DI容器)。若我們使用DI容器去管理我們物件時，此時我們即可達到控制反轉的設計。  簡單來說A物件程式內部需要使用B物件，程序需自行在A物件去new B物件。由程序主動去控制，有了容器，這一切交給容器去控制(新增物件流程)即可。  如果說DIP 是解偶物件之間的依賴，IOC 就是對物件依賴流程控制的反轉。以常見的web框架而言，將監聽http 請求，解析請求等，包裝進框架，一般使用者並不用主動去處理解析請求，處理http請求的流程，由主動處理轉交給了框架，因此，所以框架其實也是一種IoC的設計。   你可以將IOC是一種設計模式，將流程控制重定向到外部處理程序或控制器來提供控制結果，而不是透過控制項(大多情境就是程序)來直接得到結果  D. C# DI 框架   [範例請點我]  上述聊完後，相信對於DI、容器、DIP與IOC有一定認知。接著就需要進入實作部分。在.NET中最常見的DI有兩套如下   Microsoft.Extensions.DependencyInjection  Autofac  上述提到注入三種方式(建構子、屬性與方法)，Autofac都有提供，而ASP.NET DI的目前只有建構子注入方式。網上大多是Web範例，在此使用這兩套DI工具使用在DeskTop Windows From。  Microsoft.Extensions.DependencyInjection  範例DI設定在DIServiceConfigure.cs  注入服務生命週期型態  服務生命週期指：透過 DI 取得某個元件時，是每次要求得建立一顆新物件，還是從頭到尾共用一個 Instance (執行個體-物件)。   1.AddSingleton (單一性)  2.AddTransient (暫時性)  3.AddScoped (範圍性)  1. AddSingleton (單一性)  整個程序只建立一個 Instance，任何時候都共用它。簡單來說就是程序中不同流程使用此物件時，他都為同一份物件，有點像是Static，差在於使用DI可做物件設計及抽換。  下圖為Asp.Net DI生命週期圖示，物件相依關係由左至右。    而在範例模擬中設計，物件對應可視為   Rqeuest : Button_Singleton_Click 按下  第一個圈 : Call LogController  第二個圈 : Call LogController2  Instance : SingletonLogRepository  Repository注入部分我們使用AddSingleton，而物件在Instance時，我們會建置Guid去觀察他是否為同一個物件。         // 系統單一物件定義使用，或沒有異部與大量Request問題，可直接用Singleton\n   collection.  AddSingleton  <  ISingletonLogRepository  ,   LogRepository  >();  當我們按下Button_Singleton_Click時，會去呼叫LogController及LogController2裡的SingletonLogRepository物件。並印出Guid。     private     void     Button_Singleton_Click  (  object     sender  ,   EventArgs     e  )\n   {\n         //var provider = DIServiceConfigure.GetProvider();\n         //var logController = provider.GetRequiredService<ILogController>();\n         var     log     =     \"Log1(Singleton):\"  +  \"UUID-\"  +  LogController.  OperationId  (  \"Singleton\"  );\n         var     log2     =     \"Log2(Singleton):\"     +     \"UUID-\"     +   LogController2.  OperationId  (  \"Singleton\"  );\n       richTextBox_Info.  AppendText  (log  +  \"  \\n  \"  );\n       richTextBox_Info.  AppendText  (log2   +     \"  \\n  \"  );\n       richTextBox_Info.  AppendText  (LogController.  QueryLogCount  ());\n   }  此時我們可以看到兩個印出來的UUID會完全相同。代表在SingletonLogRepository在Controller與Controller2中為同一個物件。    2. AddTransient (暫時性)  定義上為程序中每次要求物件(包含物件要其他相依物件)時就建立一個新的，永不共用。  下圖為 Asp.Net DI生命週期圖示，物件相依關係由左至右。    而在範例模擬中設計，物件對應可視為   Rqeuest : Button_Transient_Click 按下  第一個圈 : Call LogController  第二個圈 : Call LogController2  Instance : TransientLogRepository  Repository注入部分我們使用AddTransient，而物件在Instance時，我們會建置Guid去觀察他是否為同一個物件。     // 異步，且須大量Request的建議使用Transient (WundowsForm簡易Sample較難模擬)\n   collection.  AddTransient  <  ITransientLogRepository  ,   LogRepository  >();  當我們按下Button_Transient_Click時，會去呼叫LogController及LogController2裡的SingletonLogRepository物件。並印出Guid。     private     void     Button_Transient_Click  (  object     sender  ,   EventArgs     e  )\n   {\n        // 模擬多次Request\n        //var provider = DIServiceConfigure.GetProvider();\n        //var logController = provider.GetRequiredService<LogController>();\n        //var log = \"Log1(Transient):\" + \"UUID-\" + logController.GUID.ToString();\n        //richTextBox_Info.AppendText(log + \"\\n\");\n              // 單次Request\n        var     log     =     \"Log1(Transient):\"     +     \"UUID-\"     +   LogController.  OperationId  (  \"Transient\"  );\n        var     log2     =     \"Log2(Transient):\"     +     \"UUID-\"     +   LogController2.  OperationId  (  \"Transient\"  );\n      richTextBox_Info.  AppendText  (log   +     \"  \\n  \"  );\n      richTextBox_Info.  AppendText  (log2   +     \"  \\n  \"  );\n          //richTextBox_Info.AppendText(LogController.QueryLogCount());\n   }  此時我們可以看到兩個印出來的UUID會不相同。代表在TransientLogRepository在Controller與Controller2中為不同物件。    上述模擬範例其實只模擬一個Request1的狀況。根據定義，程序中每次要求元件時就建立一個新的物件，對此我們已再按多次Button來做模擬。要模擬這狀況，就需要再跟Container拿取Controller物件，在範例中Controller與Controller2都是注入AddTransient，我們將模擬多次Request區塊註解打開，並註解單次Request程式碼     private     void     Button_Transient_Click  (  object     sender  ,   EventArgs     e  )\n   {\n         // 模擬多次Request\n         var     provider     =   DIServiceConfigure.  GetProvider  ();\n         var     logController     =   provider.  GetRequiredService  <  LogController  >();\n         var     log     =     \"Log1(Transient):\"     +     \"UUID-\"     +   logController.GUID.  ToString  ();\n       richTextBox_Info.  AppendText  (log   +     \"  \\n  \"  );\n           // 模擬單次Request\n         //var log = \"Log1(Transient):\" + \"UUID-\" + LogController.OperationId(\"Transient\");\n         //var log2 = \"Log2(Transient):\" + \"UUID-\" + LogController2.OperationId(\"Transient\");\n         //richTextBox_Info.AppendText(log + \"\\n\");\n         //richTextBox_Info.AppendText(log2 + \"\\n\");\n           //richTextBox_Info.AppendText(LogController.QueryLogCount());\n   }  此時我們可以看到每次的UUID就會不相同，代表在Controller在每次跟Container拿取時都為不同物件。相對的，注入其他物件時也是同一個狀況。    3. AddScope  (範圍性)  Scope我覺得是最難了解的，直接看 Asp.Net DI生命週期圖示，物件相依一樣關係由左至右。如圖所示，程序中要求物件(包含物件要其他相依物件)時，這個Flow處理過程中用到的物件則為同一個物件。而第二次再次要物件時，則會跟第一次的物件是不一樣的物件。    我們已Call Dialog方式去模擬多次Request，程式碼這邊不多做解釋，結果與物件對照如下圖，觀察Instance部分物件分別為   SingletonLogRepository  TransientLogRepository  ScopedLogRepository  可以看到ScopedLogRepository，在同一次的Request Flow，LogController與LogService的LogRepository UUID為一樣的，但在第二次打開Dialog時，則UUID會與第一次的不同。這點會跟Singleton有很大的不同。  在此我們也可以看到Transaction則是在每個物件中，及每次Request都為不同UUID。    其實Scoped跟Transaction之間有時候蠻容易混淆的。對我來說比較好懂得在於Scoped在跟Container要物件時，若前一個物件還未dispose(生命週期還未結束)，則都是同一個物件。物件結束生命週期後在新的Request後才會在新增新的物件。而Transaction就無生命週期概念，在每一次要求物件時，都會New一個新的給他，有點像平常我們想用物件就New Instance的概念。  生命週期小結論  上述描述完後，沒意外應該會對注入的生命週期會有所了解。而在Web的世界中，這三種注入方式會很常被使用到。在每一次Http Request情境，Request具有連線即結束，在這狀況下的連線相關物件基本上就會使用Scoped，因此在Web情境，大多數物件都會使用Scoped注入。  但WindowsForm App下，其實我們最常使用的會是Singleton居多，其次是Transaction，Scoped狀況就比較少，因為WindowsForm一開始畫面就那些就載入到 memory中，除非我們將畫面dispose掉，然後再重新開啟畫面，此時就會建議使用Scoped注入。  Transaction使用場景比較會偏向用後就直接dispose，不過這種應用場景，我們很常直接手動去new物件.實際架構應用上目前我也沒太多經驗。  注入抽換  生命週期講完後，接著就是闡述關於抽換實體物件。範例中我們使用IPrinter注入抽換PrinterMethodA與PrinterMethodB。  在一開始我們IPrinter注入為PrinterMethodA，在按下button_Printer_Click按鈕時，Console則會印出MethodA Print:Prionter Out    此時我們將PrinterMethodA改成PrinterMethodB     collection.  AddTransient  <  IPrinter  ,   PrinterMethodB  >();  此時在按下button_Printer_Click按鈕時，Console則會印出MethodB Print:Prionter Out    另外我們也可以注入IPrinter List，只要注入多Concreate實體     collection.  AddTransient  <  IPrinter  ,   PrinterMethodA  >();\n   collection.  AddTransient  <  IPrinter  ,   PrinterMethodB  >();  就可注入多PrinterMethod方法     private     LogController     LogController  ;\n   private     LogController2     LogController2  ;\n     // 多重注入\n   private     IEnumerable  <  IPrinter  >   Printer  ;\n     public     Form1  (  IEnumerable  <  IPrinter  >   printer  ,\n                  LogController     logController  , \n                  LogController2     logController2  )\n   {\n         InitializeComponent  ();\n       LogController   =   logController;\n       LogController2   =   logController2;\n         // 多重注入\n       Printer   =   printer;\n   }    我們只須改Container設定，主程式都不用更動，即可抽換程式中所有物件用到IPrinter的地方。  AutoFac  範例DI設定在AutofacConfig.cs  AutoFac與 ASP.NET DI 注入生命週期概念其實大同小異，下圖為對應表  出處    根據對應表，在範例程式要換成Autofac範例，只需將Bootstrapper與Form.cs裡Button_Scoped_Click的Net DI程式碼註解掉，並解開Autofac註解相關程式碼。即可觀察注入物件生命週期的不同。  .github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-762058{color:#6F42C1;}.dark .ct-762058{color:#B392F0;}.ct-617022{color:#005CC5;}.dark .ct-617022{color:#79B8FF;}.ct-086898{color:#6A737D;}.ct-157101{color:#E36209;}.dark .ct-157101{color:#FFAB70;}.ct-952708{color:#032F62;}.dark .ct-952708{color:#9ECBFF;}"},{"id":"content:0.index.md","path":"/","dir":"","title":"Home","description":"","keywords":[],"body":"     Hakuna Matata.   I am a dedicated learner, and together with my friend, we have formed a team called Code Sense in Kaohsiung. We engage in research and study on a weekly basis, with a passion for learning new technologies and skills.Continual learning is the driving force of my life.     8-9 years of software development and maintenance experience  3-4 years of experience in automation domain development  1-2 years of experience in department software training and management  Familiar with integration and connection of various factory systems (  MES ,   WMS ,   PLC )  Proficient in web system front-end and back-end development and database design  Well-versed in measurement instrument and motor PC Base control (  RS232 ,   ModBusTCP ,   EtherCAT )      My Personal Moments.      Reading Blog   Regular Reading and Public Journal of Thoughts and Moods.[  Medium ]    Code Sense Trello   Regular Study and Discussion Sessions with Friends.\n[  Code Sense Trello ]    Slider   My Presentation Slides.[  Slider Link ]    Technical Documentation   Regular document writing and temporary storage.[  Hackmd ]"},{"id":"content:1.architecture:1.DDD實戰-Module.md","path":"/architecture/ddd-module","dir":"architecture","title":"DDD實戰-Module","description":"","keywords":["一、關於Module","二、構成Module考量五要素","三、Package Vs Module","四、一般Module設計方法","五、未使用DDD的一般Service服務設計","六、在DDD世界中的Module設計","補充","參考"],"body":"  DDD實戰-Module  一、關於Module  在闡述Module前，讓我們先來比對非物件化設計與物件化設計的差異性。看到下圖左，在非物件化的傳統設計，資料與方法操作上是整個拆開設計，在資料流複雜外我們可以看相依性高，偶合的狀況也較高。  接著討論物件化設計部分，先不論封裝等物件操作技巧，單純根據資料與方法關係設計出物件(物件特性:資料(Data) 物件行為:方法(Function))，我們可以看到原本互相依賴的Fun關係可各自獨立使用，在資料流上也較為單純。    物件化後，雖然在資料操作面上簡化許多，但隨著專案功能性逐漸增加，物件與功能處理流程上會趨近越複雜，如下圖為一個簡易的系統，此系統根據外部Sensor系統獲取、過濾與計算資料，在沒模組化的設計前提，可以看到Control與Data Flow呈現一個較零散的關係狀態    此時我們根據Sensor功能額外設計一個Sensor模組如下，此時我們就可以針對Sensor相對應的資料模組將之封裝在模組內，此模組對外則就單純開放運算(calculation)與過濾(filtering)的功能。  模組化後可以明顯看出控制與資料流的彼此相依性值，因此降低了修改與擴充狀況的互相影響性值。    模組化指是將  系統功能程序作分離獨立(特定功能class的容器) ，除了功能獨立外，也強調設計上可以根據功能隨意抽換模組。達到高內聚、低耦合的目的，進而提高開發者的生產力(將複雜的功能拆分管理)。並讓程式碼能夠透過引用的方式來重複使用，提升重用性(Reusable)   Modular design allows code to remain agile in the face of ever-changing requirements.   二、構成Module考量五要素   Propose:Module功能目標單一職責，盡量不要與其他模組設計有太多相依關係。  Interface:模組功能API所提供使用方式要簡潔易懂，通常User不需要去了解實際內部的實作方式，只需專注在確定輸入什麼，會輸出什麼可達到什麼功能。  Encapsulation:封裝模組，除了讓不暴露資料結構讓使用者亂使用外，對於在修改細節上也能較不容易直接影響使用端。另外再使用抽象實作上，物件抽象化多少還是難以避免Leaky Abstractions的問題。  Implementation:實作上除了考量功能正確性外還需考慮效能、測試與功能架構程式碼最小化。  Connection(關聯性):呼應Propose功能單一職責，將與其他模組相依性最小化。   三、Package Vs Module  在了解Module構成要素後~隨著專案模組(Module)的增加，將難以管理及問題的追蹤，這時候就能將模組(Module)打包成套件(Package)，利用其階層式的結構來彈性規劃模組(Module)。   Module:單一功能模組  Package:多Module組成  四、一般Module設計方法  在非以領域事件為出發點的設計上，大部分狀況會根據功能設計成物件與介面使用。下圖為Zebra SDK Package的Module列項，我們可以大致分得出，他的Module設計就是根據功能性值去區分(graphics, certificate...)    接著我們點近discovery看提供什麼API功能，可以看到可以使用的介面功能以及相關功能可使用的功能物件。    在點進個別更詳細功能介紹，我們就會看到這物件功能具有什麼資料特質、物件實體化須提供什麼參數以及此物件可使用哪些方法。   Field: address，IP or Mac Adress  Constructor:物件實體化須提供印表機的IP or Mac Adress  Method:可使用的物件功能，在此例看起來需實作getConnection功能    上述為印表機找到印表機裝置功能的模組化介紹   五、未使用DDD的一般Service服務設計  上述一般Module設計概念聊完，在聊DDD Module設計之前先來聊一下在一般未使用DDD領域設計的服務系統會如何設計。  在對大部分的開發者，一開始習慣設計都以數據為考量的集中式設計架構。設計架構上會出現比較常見到的分層式設計，大致分成Controller, Service, Repositories, Models   xxx/Model\n   數據庫Model、Request Model, Response Model  xxx/Controller\n   給Client端的API第一時間接口，提供Get,Post,Delete,Update API。除了此在此層一般都會安插屬性驗證Client第一時間傳過來的資料是否正確。並作實際的DTO(Object 與DB Model Mapping)轉換。  xxx/Service\n   這層基本上就是作商業邏輯的處哩，進到此層的資料基本上都是做完DTO轉換，在此層通常會作實際的資料邏輯處理處理完後再往DB方向送。  xxx/Repositorie\n   DataSource(DBContext)上一層，一般會除了實際面DataSource讀寫變更操作外，Source 資料Join處理也會在此層處理。一般多這一層都是為了隔開DataSource的來源切換，不管置換不同的DB系統，或是Source改成Shared Prefs，都可快速置換資料來源。     六、在DDD世界中的Module設計  上述稍微帶過Module的設計概念後，接著探討在DDD世界裡，Module的設計概念如何~大致分成幾個探討議題  1.DDD設計步驟流程     在探討需求架構DDD設計的第一步，就是根據需求情境列出事件風暴(Event storming)，並在事件風暴中的用戶操作、事件、以及依賴關係根據這些要素設計歸納出領域與實體。  接著第二步在領域實體之間找尋彼此務的關聯性，將具有相關的實體組合成聚合(Aggregate)，同時確定聚合根(Aggregate Root)。在聚合根行程時，基本上第一層邊界(邏輯邊界-虛線)也會跟著產生，他們會在同一個服務器中運行。  當聚合規劃好後~會根據業務及語意邊界等因素，將一個或多個聚合規劃訂製在一個限界上下文內(服務邊界)，形成領域模型。    2.程式碼一級目錄架構     Interface(API Interface)\n   給使用者API介面，使用者透過Restful請求，將資料傳到此層，解析用戶傳送的請求資訊，資料的組裝、資料傳輸格式以及 Facade 介面等代碼都會放在這一層目錄裡。  Application\n   他有點像是原先集中式設計Service的功能，實作所有相依於指定前端之使用案例的地方。 例如，與 Web API 服務相關的實作。若使用的是 CQRS 方法，它便會包含查詢、微服務接受的命令，甚至是微服務之間的事件驅動通訊 (整合事件)。  Domain\n   它主要存放領域層核心業務邏輯相關的代碼。領域層可以包含多個聚合代碼包，它們共同實現領域模型的核心業務邏輯。聚合以及聚合內的實體、方法、領域服務和事件等代碼會放在這一層目錄裡。  Infrastructure\n   它主要存放基礎資源服務相關的代碼，為其它各層提供的通用技術能力、三方套裝軟體、資料庫服務、配置和基礎資源服務的代碼都會放在這一層目錄裡。  3.在DDD Module準則  例子:如何對電商平台上的顧客進行模塊設計  對於顧客來說，一般須要維護顧客的   個人訊息  收穫地址  付款方法  這三個之間的關係是緊密相關，不可獨立存在，我們根據這三點抽象出三個Aggregate   Customer 個人訊息  AddressBook 收穫地址  Wallet 付款方法  那該如何去放置這些Aggregate，是針對每一個Aggregate作資料夾分類還是這三個Aggregate放同一格資料夾?基本上這三個Aggregate就是一個Custer Module，所以都會放到Custer Module資料夾內。    當整理出Aggregate與Module後，接著會開始根據各Module去實作事件應用處理  基本上我們在DDD模塊的設計上有幾個注意要點   Module應該要和Domain概念一致:一般一組聚合集成(領域)，我們會相對應建立一個Module。  根據通用語言來命名:模組命名要一眼就看出這是在做什麼的。  模組設計盡量鬆偶合:盡量與其他模組不要有太多的偶合，若有也許在領域設計上還沒切得很乾淨。  如果有PeerModule或父子Module出現，盡量避免循環相依。  4.關於Module命名    5.Module界線與限界上下文不同  為了對領域模型中進行準確建模，需要將領域模型劃分成多個子域，每個子域對應一個或多個限界區域。 模塊。所以，從子域到限界某些再到模塊，應該是依次包含關係。  補充  補充一   Abstracion:\n   將真實世界物體與事件的大量資訊縮減一個概念或是一個現象的資訊含量來將其廣義化，保存和一特定目的有關的資訊。例如，將一個皮製的足球抽象化成一個球，只保留一般球的屬性(形狀)和行為(滾)等資訊。  Leaky Abstractions\n   所有非不證自明的抽象概念，都有某種程度的疏漏。例如TCP雖簡化(抽象化)網路行為，設計上也保證網路傳送過程中不遺漏資訊，但不保證就真的能完整傳到資訊，例如我們無法避開海底電纜被魚咬斷因此斷訊的狀況。  參考   範例  The 5 Essential Elements of Modular Software Design  The Law of Leaky Abstractions  The Three Principles of Excellent API Design  解析Python模組(Module)和套件(Package)的概念  Module Design   Domain Events vs. Integration Events in Domain-Driven Design and microservices architectures   DDD理论学习系列（13）-- 模块   DDD理论学习系列——案例及目录"},{"id":"content:1.architecture:2.DDD-簡易整理.md","path":"/architecture/ddd","dir":"architecture","title":"DDD實戰-簡易整理","description":"","keywords":["一、回顧","二、何謂Entity,如何定義他","三、跟ValueObject有何不同","四、如何產出 Entity Id?","五、.NET Core 實作微服務領域模型"],"body":"  DDD實戰-簡易整理  一、回顧  (DDD) 重點在於協助您在使用案例相關的商務實際情況下建立模型，然後根據Domain定義後續不同的Context與彼此的對應關係，再與事件驅動方式實際實現。  書中所提例子 : 電商系統，人員瀏覽商並下訂後交易。   定義Domain\n   根據問題空間與解決方法定義出Domain\n   Core Domain :產品最有價值部分 (Ex AI 推薦購買商品需求)  Supporting Subdomain : 未提供核心競爭力，但支援核心所需功能 (Ex 購物需求)  Generic Subdomain : 未提供核心競爭力，但整個系統都可能會用到它 (Ex 身份認證需求、金流串接)      根據語意(Linguistic)與業務能力(Business Capability)定義BoundContext   重點一、通常識別 Bounded Context 會由兩點下手：語意(Linguistic)與業務能力(Business Capability)。  電商例子(語意-業務能力)   登入-帳號管理 => 身分管理Context (Identity)  商品-商品選擇 => 商品目錄Context (Catalog)  下購-購買功能 => 選購Context (Purchase)  重點二、注重業務能力勝過資料分類 (習慣性地用資料表去起始設計系統，甚至把業務邏輯與 ORM 框架綁在一起。這麼一來容易造成物件乘載太多的責任，比如說「顧客」是屬於「會員管理系統」還是屬於「購物系統」？)  Context定義出後，根據幾種方法(設計模式，或撰寫程式技巧)去做Context Mapping    - Shared Kernel\n - Partnership\n - Anti-corruption Layer\n - Open Host Service/Published Language\n - Separate Way\n - Big Ball of Mud\n - Customer-Supplier\n - Conformist\n     使用或設計軟體架構最小化建置與維護「需求系統」所需要的人力資源。\n   軟體的架構與功能需求沒有關係  軟體架構是非功性需球 Non-Funcitonal Requirement (系統達成的任務的能力)  常見軟體架構大概有這些類型：\n   MVC  MVP  Layered Architecture  Client Server  Microservice  Event-Driven Architecture  Pipe-Filter  MVVM  DDD 不等於 Clean Architecture，兩者關注的面向不同。DDD 的主要目的是將軟體的模型更貼近業務需求，架構只是為了達到目的的工具。     二、何謂Entity,如何定義他  根據電商前面例子, 身分管理、 商品目錄與選購中，你覺得什麼是Entity?  顧客、訂單、商品等等。這些物件不被他們的屬性所辨識(比如年齡、金額)，而是由一個專屬的身份標誌 (Identity)來辨識。這種時候，我們就需要 Entity 的幫助讓我們在不同的物件中找到我們要的那一個。  Entity 最大的特徵就是有 Identity 的概念，所以常會搭配一個擁有唯一值的 ID 欄位。但這邊要澄清一個誤解，不是有 ID 就是 Entity，重點是你在不在乎他生命週期的變化。  Entity具有幾個特徵   具有唯一值ID  具有狀態  生命週期有可能無限長  一個 Entity 是可變的、長壽的，所以通常會有複雜的生命週期變化，如一套 CRUD 的操作  不只會實作資料屬性，還會實作具有相關領域邏輯的作業或方法  實體代表領域物件，而且主要是由其身分識別、連續性及一段時間的持續性所定義，而不只是由包含這些項目的屬性所定義。 如同 Eric Evans 說，「主要由其身分識別定義的物件稱為「實體」（Entity）。 實體在領域模型中很重要，因為它們是模型的基礎。  已Order訂單為例子   訂單ID  訂單屬性(ID,Name,Address)  訂單操作Method(EditName, EditAddress)    三、跟ValueObject有何不同   當一個物件沒有概念上的標識 (conceptual identity)，而你只關心它的屬性時，這個物件就可以建立成 Value Object。  Value Object 的屬性都是為了要描述某一個事物的特徵。  判斷這兩者的標準就在於系統在不在乎這個物件的生命週期變化。      四、如何產出 Entity Id?   1. 來自用戶的輸入  這是一個非常直接的做法，比如使用用戶的 email 或是身分證字號等等作為 ID，但也容易造成額外的成本。最大的成本就在於，你需要由用戶負責產生符合需求的身份認證資料非常困難。此時的 ID 可能是唯一的，但卻有可能是不正確的。  甚至，身分證字號也有重複的可能性。  因此，我們可以將用戶輸入的資料作為 Entity 的屬性。這些屬性可以用來做搜尋用，但大多時候並不適合作為 Entity 的 ID。   2. 使用持久化機制來產生  最常見的就是使用資料庫自動生成 ID，最常見的就是 SQL 對 ID 下 AUTO_INCREMENT 讓 ID 的值自動遞增。又或者也可以向資料庫索取一個 UUID (或 GUID) 作為 ID 的值。  這樣的做法好處是可以減少程式的複雜性，直接把產生的工作交給持久化機制處理。但也容易招致效能問題的疑慮(UUID/GUID 的產生)。而且當你無法從程式碼找出 ID 的生產機制時，也會增加程式碼的隱含性不利於閱讀。  另外，使用持久化機制時，也需要特別考量這個 ID 的生成應該要在該物件持久化 (ie 存入資料庫) 之前或是之後，以配合程式的需求。  註：這裡會使用「持久化」一詞是因為儲存資料的方式不止資料庫一種，故用更通稱的方式描述。   3. 在程式中產生  在程式中產生 ID 是最常見的方法之一，這種方法好處是可以更容易掌握生產的時機，此外，更可以客製化你的 ID 格式，比如一筆訂單你可以用 order-20190930-c764e787-8182 作為 ID，如此一來，在 debug 時就不用被一堆天文數字般的 ID 搞得昏頭脹腦。所以以個人經驗來說，即使增加了一點複雜度，會最推薦這個方式。   4. 由另一個 Bounded Context 提供  最複雜的一種就是來自於另一個 Bounded Context 提供的 ID。這種可能出現在當你需要調用 API 的時候，得到對方的資料後存取下來。這種方式的複雜點在於，你不只要考慮本地端的 Entity，也需要考慮外部 Bounded Context 的改變情況，雖然可以透過訂閱另一個 Bounded Context 的方式做到，但仍舊十分麻煩。  五、.NET Core 實作微服務領域模型      參考 :\n  https://ithelp.ithome.com.tw/articles/10223150  https://docs.microsoft.com/zh-tw/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/microservice-domain-model  https://docs.microsoft.com/zh-tw/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/ddd-oriented-microservice"},{"id":"content:2.desktop:1.WindowsForm找不到類型xxxx上的建構涵式.md","path":"/desktop/windowsformxxxx","dir":"desktop","title":"WindowsForm找不到類型xxxx上的建構涵式","description":"","keywords":["情境","錯誤訊息","解決方法"],"body":"  WindowsForm找不到類型xxxx上的建構涵式  情境  近期在設計DeskTop頁面時有遇到幾個頁面基底邏輯相同的狀況，於是特別設置Base Page去讓UC繼承使用。因為頁面其實長差不多，所以最後決定不使用參考引用而直接使用繼承。  讓A(UC_3Dswitch_CalibrationFileManagement)繼承B(UC_3Dswitch_FileManagementBase)。  錯誤訊息  編譯上都沒有問題，但此時再使用Design模式時，發生找不到類型錯誤如下    解決方法    宣告無注入空的建構子，       // 宣告無注入空的建構子\n   public     UC_3Dswitch_FileManagementBase  ()\n   {\n     }\n   public     UC_3Dswitch_FileManagementBase  (  AppSetting     appSetting  ) \n   {\n       ProductLineDataPath   =   appSetting.ProductLineDataPath;\n       SNFolderNameLength   =   appSetting.SNFolderNameLength;\n         InitializeComponent  ();\n   }  因原先Base設定注入所宣告AppSetting物件，故發生上述無法載入錯誤。看起來Deisnger模式在Control物件使用上Defaul都是預設空的建構子設置。  .github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-086898{color:#6A737D;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-762058{color:#6F42C1;}.dark .ct-762058{color:#B392F0;}"},{"id":"content:3.cloud-gcp:GKE.md","path":"/cloud-gcp/gke","dir":"cloud-gcp","title":"GKE","description":"GKE為GCP提供的SAAS等級的kubernetes服務。相對於自行架設kubernetes運行環境簡化了許多建置部屬、管理及擴展設定的工作。以SAAS提供kubernetes容器平台服務的優點如下","keywords":[],"body":"  GKE  GKE為GCP提供的SAAS等級的kubernetes服務。相對於自行架設kubernetes運行環境簡化了許多建置部屬、管理及擴展設定的工作。以SAAS提供kubernetes容器平台服務的優點如下   容易上手 : Google對kubernetesr進行封裝及抽象，使用者不需要了解底層細節即可上手。能直接透過介面操作達到快速部屬與管理設定。不然一般許多部份都需要自己做相關起建，例如..\n   介面需安裝相對應的工具並做設定才可  版本升級修補需人為去維護  需自行安裝與配置監控與日誌工具  安全性設定  資源設定擴展需自行維護"},{"id":"content:4.database:1.MSSQL使用指令測試Server硬碟速度小技巧.md","path":"/database/mssqlserver","dir":"database","title":"MSSQL使用指令測試Server硬碟速度小技巧","description":"","keywords":["讀取速度","寫入速度"],"body":"  MSSQL使用指令測試Server硬碟速度小技巧  讀取速度  選抽一個資料庫 下BACKUP DATABASE指令，備分資料庫不做寫入，只做讀取，可得到讀取速度值。     BACKUP     DATABASE   [FUXIN_CPL]   TO     DISK     =  'NULL'     WITH     COPY_ONLY    下圖可看到結果每秒讀取速度為180MB/sec    寫入速度     BACKUP     DATABASE   [FUXIN_CPL]   TO     DISK     =  'C:\\TEST.BAK'     WITH     COPY_ONLY  此時會得到讀寫時間為每秒153MB    每秒153MB為讀寫時間，此時須作運算處裡將寫入時間算出  讀取總頁數共688頁，一頁8k => 688*8.0 / 1024 = 5.375M  寫入時間為 0.035-0.03 = 0.005  5.375M/0.005 = 1075M  .github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-952708{color:#032F62;}.dark .ct-952708{color:#9ECBFF;}"},{"id":"content:5.keycloak:1.身份驗證與授權與Keycloak.md","path":"/keycloak/keycloak","dir":"keycloak","title":"身份驗證與授權與Keycloak","description":"","keywords":["一、關於身份驗證與授權"],"body":"  身份驗證與授權與Keycloak  一、關於身份驗證與授權  身份驗證和授權是系統安全性非常重要的環節。身份驗證用於識別使用者是誰，而授權則賦予使用者某些特定權限。更具體來說，這整個過程可以分為四個部分：   身分識別 (Identification)：這是一個讓系統知道你是誰的過程。例如，當你使用用戶名或電子郵件地址登入系統時，就是進行身分識別。  身分驗證 (Authentication)：這個過程讓系統確認你確實是你聲稱的那個人。通常是通過輸入密碼、使用FaceID或OTP來完成的。  授權 (Authorization)：這涉及到角色分配。根據你的角色，系統會賦予你不同的權限。例如，一個“編輯者”角色可能有編輯內容的權限，而一個“閱讀者”角色則只能閱讀。  存取控制 (Access Control)：這涉及到具體的操作權限。比如，在一個IT管理系統中，一個普通使用者可能可以重啟伺服器和查看系統日誌，但不能部署新的程式碼。然而，一個開發者則可能有這樣的權限。  在你登入系統，輸入帳號密碼為身分識別與身分驗證，系統驗證完後，會根據身分授予角色。至於此角色權限則可以在後台系統上設置。至於這部分的詳細實做概念牽扯還是蠻多的...會再找時間針對這部分做一個細部講解。  1. 身分識別驗證與授權簡易實作  了解這些基礎概念後，我們可以考慮如何手動實現這四個部分。   身分識別 (Identification) : 最常見的實現方式是透過一個使用者註冊頁面，讓使用者輸入基本資料，例如用戶名和密碼。這些信息會被存儲在後端的資料庫中（密碼會被加密）。  身分驗證 (Authentication) : 驗證的方法有多種。   密碼驗證 : 簡單地說，就是將輸入的密碼與資料庫中存儲的密碼進行比對。  多因素驗證 : 二次驗證，例如OTP、FaceID，或是手機&Mail驗證  Session/Token管理 : 用戶登入後，系統會生成一個session或token並發送給用戶。後續的所有請求都需要這個token以確認身份。  授權 (Authorization) : 這部分簡易實作基本上會有三部份   角色管理：在資料庫中設計一個角色和權限的模型。例如，每個使用者可以有一個或多個角色，每個角色有不同的權限。  權限檢查：每次使用者請求某個資源或操作時，檢查他們的角色是否有相應的權限。  API設計：設計API時，確保每個API端點都有適當的授權檢查。  存取控制 (Access Control)   基於角色的存取控制 (RBAC)：根據使用者的角色決定他們可以訪問的資源。  細緻的權限設定：允許系統管理者為每個角色定制細緻的權限，例如某角色只能讀取資料但不能編輯。  其他考慮   日誌和監控：記錄所有的登錄嘗試、授權請求等，以便日後分析和審計。  資料庫安全性：確保資料庫有適當的加密和備份策略。  定期檢查和更新：隨著時間的推移，可能會出現新的安全威脅。定期檢查和更新你的身份驗證和授權策略，以確保它們始終是安全的。  2. 身分識別驗證、授權與Keycloak  通過使用Keycloak，我們能夠更為高效地實現身分識別、身分驗證、授權，以及存取控制等功能。   身分識別 (Identification)   不僅提供使用者註冊功能，讓使用者可以用基本資訊，比如用戶名或電子郵件進行註冊，還支持多種社交登入方式，如Google或Facebook。  身分驗證 (Authentication   支援多種身分驗證方法，包括密碼、OTP、FaceID等，也提供Token管理，當使用者成功登入後，Keycloak 會發放一個 token，使用者可以使用此 token 來存取其他受保護的資源。  授權 (Authorization)   可以定義多個角色，並為每個角色分配不同的權限，使用者可以被分配到一個或多個角色，這些角色決定了使用者可以訪問哪些資源。  存取控制 (Access Control)   支援基於角色的存取控制 (RBAC)。你可以設定哪些角色可以訪問哪些資源。  一般來說，要全面實施這四大功能通常需要大量的時間和資源。開發者不只需要寫大量的程式碼，還必須維護系統的安全性、效能，並確保與其他系統的良好整合。有了Keycloak，這一切都變得相對簡單。"},{"id":"content:5.keycloak:2.OIDC與SAML.md","path":"/keycloak/oidcsaml","dir":"keycloak","title":"OIDC vs SAML","description":"在這部分，我們將探討OIDC和SAML。正如前一章節所提，身分驗證和授權是整個安全流程中非常關鍵的環節。一般來說，會有專門的解決方案來處理這些問題。OIDC和SAML都是為這個目的而設計的標準協議，它們提供一個集中式的方法來驗證使用者身份，並界定他們可以訪問哪些資源或執行哪些操作。","keywords":["1. Open ID Connect (OIDC)："],"body":"  OIDC vs SAML  在這部分，我們將探討OIDC和SAML。正如前一章節所提，身分驗證和授權是整個安全流程中非常關鍵的環節。一般來說，會有專門的解決方案來處理這些問題。OIDC和SAML都是為這個目的而設計的標準協議，它們提供一個集中式的方法來驗證使用者身份，並界定他們可以訪問哪些資源或執行哪些操作。  1. Open ID Connect (OIDC)：  OIDC是一個建立在OAuth 2.0之上的身分認證層。OAuth 2.0本身是一個專注於授權的框架，而OIDC則在這個基礎上增加了身分驗證功能。這樣，應用程式不僅能知道使用者有哪些權限，還能瞭解使用者是誰，並獲取他們的基本資訊，比如名稱和電子郵件地址。  a. OAuth 2.0  OAuth 2.0 是一個授權框架，允許第三方應用程式在使用者同意的情況下存取使用者在某個服務上的資訊，而不需要分享使用者的密碼。通常在OAuth 2.0，會有幾個角色，我們這邊舉一個簡單情境，你希望使用「快速日記」App，而這個App提供使用Google帳戶登入的功能來使用Google雲端硬碟服務。   Resource Owner(資源擁有者) : 通常就是User(你)， 能授予應用程式取得受保護資料的人，通常就是終端使用者（end-user）。例如你希望使用「快速日記」App，而這個App提供使用Google帳戶登入的功能。在OAuth的流程中，當App請求許可存取你的資料時，你會給予（或拒絕）這個請求。  Resource Server(Resource Server) : 存放使用者受保護資料的伺服器，以這個例子來說就是Google雲端硬碟，當「快速日記」App希望保存或讀取日記時，它會向此伺服器提出請求。  Client (客戶端)：通常指稱想要取得受保護資源的「應用程式」，以這個例子來說就是「快速日記」App。 當「快速日記」App希望保存或讀取日記時，它會向此伺服器提出請求。  Authorization Server (授權伺服器) : 驗證 Resource Owner 的身份，並且在獲得同意之後，發放「Access Token」給應用程式（Client）的伺服器。以這個例子來說就是 (Google的授權伺服器)。  下圖整個驗證Flow  \n   驗證Flow     Client 到 Resource Owner :   Request Credentials : 當你打開「快速日記」App並選擇使用Google帳戶登入時，App首先會引導你到Google的登入頁面。  Authenticate : 你將在Google的頁面上輸入你的Google帳戶憑證，即用戶名和密碼。這一步是由Google完成的，而「快速日記」App不會看到或知道你的密碼。  Consent : 一旦驗證成功，Google會顯示一個請求同意頁面。在這裡，Google會詢問你是否允許「快速日記」App訪問特定的Google帳戶資料。  Credentials : 「Resource Owner」（使用者）提供的身份資訊或某種用於辨識其身份的資料。這只是一個授權請求，而實際的身份驗證會在Resource Owner和Authorization Server之間完成。    Client 到 Authorization Server   Authorization Request : 如果你同意上述的權限請求，「快速日記」App會從Google的授權伺服器請求一個授權碼。  Authorization Code : Google的授權伺服器會回傳一個短暫的授權碼給「快速日記」App。  Access Token : ，「快速日記」App會使用這個授權碼再次向Google的授權伺服器請求取得訪問令牌（Access Token）。    Client 到 Resource Server   Access Token: 一旦取得訪問令牌，「快速日記」App便可以使用此令牌來存取Google雲端硬碟（或其他你同意的資料）。  Protected Resource: 當「快速日記」App希望保存或讀取日記時，它會使用這個Access Token向Google雲端硬碟（作為資源伺服器）提出請求，然後Google雲端硬碟會根據該令牌提供相對應的資料或服務。  更詳細的其實還有關係到Redirect部分，可以參照這篇   https://cloudsundial.com/salesforce-oauth-flows  寫得還算詳細。  "},{"id":"content:5.keycloak:3.關於SSO.md","path":"/keycloak/sso","dir":"keycloak","title":"關於SSO","description":"","keywords":["三、SSO 簡述"],"body":"  三、SSO 簡述  OIDC和SAML討論完後，我們來聊聊單一登入（SSO）。SSO是一個身份驗證方案，它讓使用者能透過一次登入就可訪問多個應用程式和網站。簡而言之：   透過單一的登入窗口，進行單一的身分驗證，就可以讓許多的服務共同來使用這個驗證結果  OIDC和SAML都可以實現這樣的SSO功能。舉例來說，假設你在工作中要使用三個不同的平台：   郵件系統（Email System）  公司內部網站（Intranet）  報表和數據分析平台（Analytics Platform）  通常你得記住這三個系統各自的帳號和密碼。但有了SSO，你只需透過一個統一的登入界面（比如由Keycloak管理）登入一次，然後就能自由地訪問這三個不同的平台，無需再逐一輸入帳號和密碼。  總之，SSO幫你將多個獨立的系統集成為單一的入口點。這樣不僅減少了你需要記住多組密碼的困擾，還降低了由於多個系統各自存儧行密碼所帶來的安全風險。  流程範例大致如下：   Step1(箭頭1) : 用者首先訪問「Application 01」的 URL 並按下登入按鈕，然後會被引導到 Keycloak 登入頁面。  Step2: 用戶在 Keycloak 成功登入後，將被重新導向回「Application 01」的主頁。  Step3(箭頭3): 如果用戶在合理的時間內再次訪問「Application 02」，則不需要重新登入。  箭頭2實際上是指示用戶從「應用程式01」被引導到Keycloak的登入頁面這一過程。簡單來說，當用戶嘗試在「應用程式01」登入（箭頭1）後，他們會被重定向到Keycloak以完成身份驗證（箭頭2）。  "},{"id":"content:5.keycloak:4.Keycloak Introduce.md","path":"/keycloak/keycloak-introduce","dir":"keycloak","title":"Keycloak Introduce","description":"我們剛才談到實現SSO（單一登入）的功能，那麼現在問題來了：有沒有一個工具或平台能讓我們更方便地實現這一切呢？答案是有的，那就是Keycloak。Keycloak是一個集成了多種身份驗證和授權機制（包括OIDC和SAML）的開源身份和訪問管理解決方案。","keywords":["2. Keycloak 細部解析"],"body":"  Keycloak Introduce  我們剛才談到實現SSO（單一登入）的功能，那麼現在問題來了：有沒有一個工具或平台能讓我們更方便地實現這一切呢？答案是有的，那就是Keycloak。Keycloak是一個集成了多種身份驗證和授權機制（包括OIDC和SAML）的開源身份和訪問管理解決方案。  Keycloak的特點如下   多協議支持: Keycloak支持OIDC和SAML，所以你不必為了不同的應用而選擇不同的解決方案。  易於管理: Keycloak有一個使用者友善的管理界面，你可以輕鬆設定用戶、角色和權限。  靈活性: 它是開源的，意味著你可以根據自己的需要對它進行定制。  詳細提供以下功能   身分驗證(Authentication)   單點登入/登出（Single Sign-On/Single Sign-Out）: 讓使用者只需登入一次，就能訪問多個不同的應用和服務。  多因素認證（Multi-Factor Authentication, MFA）: 除了密碼外，還可以透過SMS、郵件或其他方法進行身份驗證。  支持外部身分源: AD，LDAP，Social Login(Google, FB...)。  使用者管理（User Management）   使用者身分 CRUD（Create, Read, Update, Delete）: 簡單地管理使用者資訊，包括建立、查詢、更新和刪除。  屬性管理（Attribute Management）: 可以給使用者賬戶添加多種屬性和標籤。  使用者分組（User Grouping）: 組織使用者到不同的群組以方便管理。  授權（Authorization）   Role-Based Access Control(RBA）: 基於角色給予使用者不同的訪問權限。  Attribute-Based Access Control(ABAC）: 根據使用者的特定屬性（如年齡、部門等）來給予權限。  User-based Access Control (UBAC) : 直接對個別用戶賦予權限，而不是通過角色或屬性。這在只有少數用戶需要訪問特定資源的情況下特別有用。  Context-based Access Control (CBAC) : 更動態的授權方式，考慮到目前的情境或環境狀況（如目前正在執行的操作，或者資源的當前狀態）來做出授權決策。  Rule-based Access Control (Using JavaScript) : 使用 JavaScript 程式碼來定義特定的授權規則。這是一個非常靈活的方式，可以根據極其特定的需求來制定授權策略。  Time-based Access Control : 依據時間來決定是否允許訪問，例如只有工作時間允許訪問某個資源。  Support for custom Access Control Mechanism (ACMs) through a Service Provider Interface (SPI) : 高度定制的選項，允許你通過 Service Provider Interface (SPI) 來實現自己的授權機制。這對於需要非常特殊授權邏輯的場景來說是一個非常強大的工具。  安全性（Security）   密碼政策（Password Policies）: 可以設定密碼的複雜度、有效期等。  會話管理（Session Management）: 查看和管理當前活躍的使用者會話。  應用安全（Client Security）: 對接入的客戶端進行安全設定和驗證。  其他   事件監控（Events Monitoring）: 監控和記錄關於認證、授權等的事件。  擴展性（Extensibility）: 支持自定義插件和腳本，以擴展基礎功能。  2. Keycloak 細部解析  a. Keycloak Core  為了充分利用Keycloak，並根據我們的需求進行客製化，我們必須了解其核心組件以及它們是如何互動的。以下為Keycloak Core Block圖     Realm:master：可想像成一個隔離的命名空間，裡面有你的使用者、角色、客戶端等資料。你可以有多個Realm，每個Realm都有其獨立的設定。\n   Client：代表需要與Keycloak進行互動的應用程式或服務。像是網頁應用或API。這些客戶端會使用Keycloak進行身份驗證。  Roles：確定使用者在Client中可以執行哪些操作。  Security Defense：確保Realm的安全性，例如對抗暴力攻擊或強化密碼政策。  User Federation：允許你把外部的使用者來源（如LDAP）連接到Keycloak。  Roles：通常用於定義訪問權限。例如，管理員角色可能允許使用者更改系統設定。  Groups：一組使用者的集合，有助於管理與分配角色。  Events：記錄Keycloak的所有活動，如誰何時登錄或更改設定。  Users：這是指註冊到Realm的使用者。他們可以有不同的角色或屬於不同的群組。  Identity Provider (IdP)：確認使用者身份的部分，允許使用者用像是Google或Facebook這類的外部服務進行登錄。  核心和外部區塊的互動部分。例如，當一個使用者使用Twitter賬號登錄時，Twitter會和Keycloak中的Identity Provider互動，然後IdP再與Realm互動，確認使用者的身份並賦予他適當的角色和權限。  另外這邊稍微提一下Realm裡面的Roles跟外部的Roles有什麼不同   Realm裡面的Roles (Realm-level Roles)：這些角色是直接相對於Realm本身的。一旦你在Realm中定義了一個角色，你就可以將它指派給任何Realm內的使用者。它們通常是更通用的，例如“管理員”或“使用者”，並且可以跨多個客戶端使用。  外部的Roles (Client-level Roles)：這些角色是相對於特定的客戶端（應用程式或服務）的。所以它們是在特定客戶端的上下文中定義和使用的。允許你為每個應用程式定制更具體的角色。例如，你可能有一個\"編輯\"角色在你的CMS系統中，而有一個\"購物者\"角色在你的電商網站中。  簡單來說，Realm內的角色是全域性的，可以在整個Realm中使用，而Client-level角色是特定於某個應用程式的。  b. Kyecloak 角色  使用Keycloak服務時，裡面有幾種角色必須釐清他們的關係   Realm : 每一個Realm在Keycloak中都代表了一個獨特的命名空間或領域。在同一個Keycloak實例中，不同的Realm之間的資料和設定是完全隔離的。例如，行銷部門和研發部門可能有不同的應用程式和使用者，因此他們可以在不同的Realm中被管理。某種程度有點像Project概念。   設定 : 每個Realm都有自己獨特的設定，包括但不限於認證策略、令牌生命週期、SMTP設定等。這意味著你可以為不同的組織或專案客製化其身份和訪問管理策略。  使用者和客戶端 : 每個Realm內都有其專屬的Users和Clients。例如，兩個不同的Realm之間的Users是不可以交互認證的。  事件和審計 : 可以為每個Realm單獨配置事件和審計策略，以追踪和記錄Realm內的活動。  Clients : 通常代表你想要與Keycloak整合的應用程式或服務。定義了如何與那些應用程式或服務進行交互，包括認證方法、回調URL等。例如有一個Web應用程式和一個手機應用程式，兩者都需要身份驗證。在這種情況下，你可以為每個應用程式設定一個Client，並為它們設定不同的認證流程或訪問限制。   設定 : Clients的設定包括如何與其進行認證的具體細節，例如回調URL、認證方法、封裝方法等。包含協議，可能是OpenID Connect、SAML 2.0。  角色 : 你可以在每個Client裡設置特定的角色，這些角色可以賦予給使用者，以決定他們在該Client中可以進行哪些操作。  Users : Users基本上是真實的個體，如員工或客戶。   設定 : 在Keycloak中，User的憑證（如密碼）是存儲在User的設定中。但是，具體的認證流程（例如，如何驗證這些憑證）是由Client來定義的。  與Client的關係 : Users在Clients中獲得訪問令牌，這些令牌決定了他們在該Client中可以進行哪些操作。例如，一個User可能在一個Client中具有\"讀者\"的角色，在另一個Client中具有\"管理員\"的角色。  Groups : Groups代表了一種組織層次結構，可以將Users組合在一起。這允許管理者更容易地管理大量使用者和其訪問權限。   設定 : 跟Users一樣，Groups也可以有其自己的屬性和設定。例如，你可以為某個Group設定一個特定的屬性，然後所有屬於該Group的Users都可以看到或使用這個屬性。  角色賦予 : 可以將角色賦予給一個Group，然後所有屬於那個Group的Users都會繼承這些角色。  靈活性 : 一個User可以同時屬於多個Group。例如，一個User可能同時是\"研發團隊\"和\"高級工程師\"這兩個Groups的成員。  Role : 角色是一種用於表示使用者或群組所擁有的權限的方式。換句話說，角色定義了使用者或群組可以執行哪些操作或訪問哪些資源。例如，您可能有一個\"管理員\"角色，該角色允許使用者訪問和修改所有資源，而\"編輯者\"角色則可能只允許使用者修改，但不能刪除資源。   設定 : 在Keycloak中，角色可以分配給單個使用者或群組。當使用者試圖訪問某個資源或執行某個操作時，系統會檢查他們所分配的角色是否具有所需的權限。  角色的類型：Realm比較偏向Keycloak設定管理權限，客戶端角色比較偏向客戶端API使用權限。  Realm角色：可分配給Realm中的任何使用者或群組。例如，Realm範疇的\"管理員\"角色允許使用者管理整個Realm的設定。  客戶端角色：只能分配給特定客戶端的使用者或群組。例如，一個\"編輯器\"角色在\"新聞應用程式\"客戶端可能意味著使用者可以發布新的新聞文章，但在另一個\"帳單系統\"客戶端，相同的\"編輯器\"角色可能有完全不同的權限。  最後稍微用圖舉個他們關係的例子     Client：在此領域中的應用程式或服務，用戶會透過它進行認證。  Role 1, 2, 3, 4：這些是在該Realm中定義的角色。角色通常代表某些權限或能力。  Users：代表該Realm中的所有用戶。  Group 1, 2, 3… n：代表不同的用戶群組。每個群組可能有不同的權限和角色。  User 1：當此用戶登入時，被賦予了Role 1角色，並且是Group 1, Group 2, 和 Group 3的成員。 而 User 2 用戶登入時，被賦予了Role 2角色，並且是Group 2, Group 3, 和 Group 5的成員。最後User 3 用戶登入時，會被賦予了Role 4角色，並且是Group 2, Group 3, Group 4, 和 Group 5的成員。  可以看到Keycloak如何將角色和群組賦予用戶。這有助於管理哪些用戶可以訪問哪些資源，以及他們可以執行哪些操作。此外，通過將用戶分組，可以輕鬆地管理大量用戶的權限，而不必逐一配置。"},{"id":"content:100.ironman-gcp:Cloud.md","path":"/ironman-gcp/cloud","dir":"ironman-gcp","title":"Cloud","description":"","keywords":[],"body":""},{"id":"content:101.license:1.ACE.md","path":"/license/ace","dir":"license","title":"ACE [模擬考題]","description":"For Taipei Cathy Bank Cloud AP Group一起整理","keywords":[],"body":"  ACE [  模擬考題 ]  For Taipei Cathy Bank Cloud AP Group一起整理     Every employee of your company has a Google account. Your operational team needs to manage a large number of instances on Compute Engine. Each member of this team needs only administrative access to the servers. Your security team wants to ensure that the deployment of credentials is operationally efficient and must be able to determine who accessed a given instance. What should you do?     A. Generate a new SSH key pair. Give the private key to each member of your team. Configure the public key in the metadata of each instance.\n  B. Ask each member of the team to generate a new SSH key pair and to send you their public key. Use a configuration management tool to deploy those keys on each instance.\n  C. Ask each member of the team to generate a new SSH key pair and to add the public key to their Google account. Grant the compute.osAdminLogin role to the Google group corresponding to this team.\n  D. Generate a new SSH key pair. Give the private key to each member of your team. Configure the public key as a project- wide public SSH key in your Cloud Platform project and allow project-wide public SSH keys on each instance.\n  \n    解題  答案為C，基本上就是考IAM帳戶管理控制  公司每位員工都有Google帳戶，而運營團隊需要管理大量的Compute Engine實例。每位團隊成員都需要對這些虛擬機器有管理權限，但只限於管理權限，不需要其他額外的權限。希望部署這些訪問權限的方式要高效，且之後能追踪到哪位員工訪問了特定的實例。   A.生成一個新的SSH密鑰對，將私鑰給團隊的每個成員，並在每個實例的元數據中配置公鑰。這種方法的問題在於所有成員共享相同的私鑰，這不僅安全風險高，而且無法追蹤具體人員的訪問。  B.要求團隊的每個成員生成一個新的SSH密鑰對並將他們的公鑰發給你。使用配置管理工具在每個實例上部署這些密鑰。這個方法能夠實現每個成員都有自己的密鑰，從而提高安全性並能追蹤到每個人的訪問，但部署公鑰的過程可能會比較繁瑣。  C.要求團隊的每個成員生成一個新的SSH密鑰對並將公鑰添加到他們的Google帳戶中。給予對應這個團隊的Google群組compute.osAdminLogin角色。這個方法不僅確保了每個成員都有自己的密鑰，還利用了GCP的IAM（Identity and Access Management）功能來管理訪問權限，同時也簡化了密鑰的部署過程。  D. 生成一個新的SSH密鑰對，將私鑰給團隊的每個成員，在你的Cloud Platform項目中配置公鑰為項目範圍內的公開SSH密鑰，並允許在每個實例上使用項目範圍的公開SSH密鑰。這個選項同樣存在A選項的問題，即共享私鑰並不能追蹤到具體個人。     You need to create a custom VPC with a single subnet. The subnet's range must be as large as possible. Which range should you use?   A. 0.0.0.0/0\nB. 10.0.0.0/8\nC. 172.16.0.0/12\nD. 192.168.0.0/16\n  \n    解題  答案為B，考CIDR（Classless Inter-Domain Routing）  詢問如何在Google Cloud Platform（GCP）上創建一個自定義虛擬私有雲（VPC）並設定一個單一子網，使得這個子網的IP範圍盡可能大。   A. 0.0.0.0/0 - 這個範圍代表所有可能的IPv4地址，但它不是一個實際可用於子網的範圍，因為它用於特殊目的（例如路由規則中表示任何地址）。  B. 10.0.0.0/8 - 這個範圍在私有地址空間中是可用的，並且提供了最大的IP地址範圍，大約有16777216個可用地址（2^24）。這是一個廣泛用於大型網絡的範圍。 (/8表示前8位是網絡地址，剩下的24位（32-8=24）是主機地址。所以，可以有224224個可能的地址。)  C. 172.16.0.0/12 - 這也是私有地址空間的一部分，但提供的地址數量少於10.0.0.0/8範圍，大約有1048576個可用地址（2^20）。(/12表示前12位是網絡地址，剩下的20位（32-12=20）是主機地址。所以，可以有220220個可能的地址。)  D. 192.168.0.0/16 - 這個範圍同樣屬於私有地址空間，提供的IP地址數量更少，大約有65536個可用地址（2^16）。(/16表示前16位是網絡地址，剩下的16位（32-16=16）是主機地址。所以，可以有216216個可能的地址。)     You want to select and configure a cost-effective solution for relational data on Google Cloud Platform. You are working with a small set of operational data in one geographic location. You need to support point-in-time recovery. What should you do?   A. Select Cloud SQL (MySQL). Verify that the enable binary logging option is selected. \nB. Select Cloud SQL (MySQL). Select the create failover replicas option.\nC. Select Cloud Spanner. Set up your instance with 2 nodes.\nD. Select Cloud Spanner. Set up your instance as multi-regional.\n \n   \n    解題  答案是A，考Cloud SQL 及對 Cloud Spanner 選用上認知  這個問題是關於在Google Cloud Platform（GCP）上選擇和配置一個成本效益高的關聯式數據存儲解決方案。考慮的情境是你正在處理一個小型的運營數據集，而且這些數據只需要在一個地理位置存儲。此外，你需要支持點時間恢復（Point-in-Time Recovery, PITR），這意味著你需要能夠恢復到數據庫在過去任何一個特定時間點的狀態。   A. 選擇Cloud SQL (MySQL)。確保選擇了啟用二進制日誌記錄選項。   Cloud SQL是一個完全管理的關聯式數據庫服務，支持MySQL等流行的數據庫系統。啟用二進制日誌記錄是支持點時間恢復的一個要求，因為它可以記錄數據庫的所有更改，從而允許恢復到特定的時間點。   B. 選擇Cloud SQL (MySQL)。選擇創建故障轉移副本選項。   創建故障轉移副本提高了數據庫的可用性和災難恢復能力，但它不直接與支持點時間恢復的需求相關。   C. 選擇Cloud Spanner。設置你的實例為2個節點。   Cloud Spanner是一個完全管理的、水平可擴展的關聯式數據庫服務，支持全球分佈的數據庫和強一致性。但對於一個小型數據集且只在一個地理位置的需求來說，Cloud Spanner可能是一個過於昂貴的選項，尤其是當只需要點時間恢復這一特定功能時。   D. 選擇Cloud Spanner。設置你的實例為多區域。   這個選項提供了高可用性和災難恢復能力，但與C選項一樣，對於小型數據集來說，這是一個成本較高的解決方案，並且超出了只需要一個地理位置存儲的需求。     You want to configure autohealing for network load balancing for a group of Compute Engine instances that run in multiple zones, using the fewest possible steps. You need to configure re-creation of VMs if they are unresponsive after 3 attempts of 10 seconds each. What should you do?   A. Create an HTTP load balancer with a backend configuration that references an existing instance group. Set the health check to healthy (HTTP)\nB. Create an HTTP load balancer with a backend configuration that references an existing instance group. Define a balancing mode and set the maximum RPS to 10.\nC. Create a managed instance group. Set the Autohealing health check to healthy (HTTP)\nD. Create a managed instance group. Verify that the autoscaling setting is on.\n \n   \n    解題  答案是C， ref :   https://cloud.google.com/compute/docs/tutorials/high-availability-autohealing  這題考的是如何在Google Cloud Platform上為運行在多個區域的Compute Engine實例群組配置網絡負載均衡的自動修復功能，並且要求用盡可能少的步驟完成。自動修復功能能夠檢測到實例因無響應而失效時自動重新創建實例。具體來說，題目要求配置系統在實例經過3次每次10秒的嘗試無響應後進行重新創建。   A. 創建一個HTTP負載均衡器，並且配置後端參照一個現有的實例群組。設置健康檢查為健康(HTTP): 這個選項設置了HTTP負載均衡器並使用健康檢查，但是主要聚焦在流量分配而非自動修復。  B. 創建一個HTTP負載均衡器，並且配置後端參照一個現有的實例群組。定義一個平衡模式並設置最大RPS為10: 這個選項同樣是設置HTTP負載均衡器，聚焦在處理請求的能力上，與自動修復無關。  C. 創建一個管理的實例群組。設置自動修復健康檢查為健康(HTTP): 這個選項直接指向了自動修復的需求，通過在管理的實例群組中設置健康檢查來達到當實例無響應時自動重新創建的目標。  D. 創建一個管理的實例群組。驗證自動擴展設置是否開啟: 雖然這個選項涉及到管理的實例群組，但是它聚焦在自動擴展上，與問題中要求的自動修復功能不直接相關。     You are using multiple configurations for gcloud. You want to review the configured Kubernetes Engine cluster of an inactive configuration using the fewest possible steps. What should you do?   A. Use gcloud config configurations describe to review the output.\nB. Use gcloud config configurations activate and gcloud config list to review the output. \nC. Use kubectl config get-contexts to review the output.\nD. Use kubectl config use-context and kubectl config view to review the output.\n \n    \n    解題  答案是D，考gcloud config指令在GKE上應用  如何在使用Google Cloud SDK（gcloud）的多配置環境中，用最少的步驟審查一個不活躍配置下的Kubernetes Engine集群配置。   A. 使用gcloud config configurations describe來審查輸出。 這個命令用於顯示當前或指定配置的詳細信息，但不直接針對Kubernetes Engine集群的配置。  B. 使用gcloud config configurations activate命令可以切換到一個特定的配置，然後使用gcloud config list可以查看當前激活配置的詳細設置。這個方法直接關聯到gcloud工具和Google Cloud平台的配置，但它更多地是關於查看gcloud CLI的配置，而不直接指向Kubernetes Engine集群的具體配置。  C. kubectl config get-contexts命令顯示所有可用的上下文。每個上下文代表一個連接到特定Kubernetes集群的設定。這個命令快速顯示了所有配置的上下文，但它不切換到這些上下文或直接審查它們的細節。  D. kubectl config use-context允許你切換到一個特定的Kubernetes上下文（這個上下文可能是指向一個特定的Kubernetes Engine集群），而kubectl config view能夠讓你查看當前的kubectl配置，包括與所選上下文相關的配置。這對於審查Kubernetes Engine集群的配置來說，是一種更直接的方法。     Your company uses Cloud Storage to store application backup files for disaster recovery purposes.\nYou want to follow Google's recommended practices. Which storage option should you use?   A. Multi-Regional Storage\nB. Regional Storage\nC. Nearline Storage\nD. Coldline Storage\n \n   \n    解題  答案是D, 考對Storage認知，基本上題目提到備份檔案，代表要存取的資料時長時間不會去異動他的，所以答案選Coldline Storage(D)。  使用雲端儲存來儲存應用程式的備份檔案，目的是為了災難恢復。並且遵循Google的建議做法。當我們說備份檔案是為了diaster恢復，這意味著這些文件不太可能經常被存取，但在必要時需要能迅速取得。   A. 資料會分散儲存在多個區域中，主要適用於那些需要在全球多個地點進行高頻率存取的數據。適用情境: 如果你有一個網站或應用，並希望全球的用戶都能快速存取資料。  B. 資料僅儲存在特定的區域中。這意味著它比多區域儲存更有地域性，但同時也具有高的存取速度。適用情境: 如果你的應用或服務主要是針對某一特定地理區域的用戶，例如只在亞洲。  C. 是一種低成本的儲存方式，適用於那些你不經常需要存取，但當需要時，你希望能在數秒內獲取的數據。適用情境: 假設你有一些資料，大概每月需要查看或使用一次。可選擇Nearline Storage  D. 用於那些很少存取的資料，但可能在未來需要它們。成本非常低，但取得資料時可能需要較長的時間。適用情境: 如果你有需要長期保存但很少存取的資料，例如備份或檔案存檔，那麼冷儲存是個好選擇。     Several employees at your company have been creating projects with Cloud Platform and paying for it with their personal credit cards, which the company reimburses. The company wants to centralize all these projects under a single, new billing account. What should you do?   A. Contact cloud-billing@google.com with your bank account details and request a corporate billing account for your company.\nB. Create a ticket with Google Support and wait for their call to share your credit card details over the phone.\nC. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organizarion.\nD. In the Google Cloud Platform Console, create a new billing account and set up a payment method.\n \n    \n    解題  答案為D  探討的是如何將一個公司內多個員工為了工作目的而分別使用個人信用卡支付的Google雲端平台（GCP）項目，統一到一個公司的計費帳戶下。這樣做的目的是為了讓公司能夠更有效地管理雲端資源的費用和項目，避免個別員工需要先行支付然後再報銷的不便和風險。   A. 聯絡Google的計費部門的電子郵件地址，並提供你的銀行帳戶詳細資訊，請求為公司建立一個企業計費帳戶。  B. 通過創建支持票務並等待通話來分享信用卡詳細資訊。這個選項在處理計費問題時通常不是推薦的做法，因為涉及到信用卡資訊的共享應該通過安全的方法進行。  C. 在Google雲端平台控制台中，前往資源管理器並將所有項目移至根組織。這個選項解決了項目組織的問題，但並未直接解決計費帳戶的統一問題。  D. 在Google雲端平台控制台中創建一個新的計費帳戶並設置支付方式。這是解決問題的直接方法，允許公司設置一個中央計費帳戶並將所有現有和未來的項目關聯到這個帳戶。這樣，公司可以直接管理所有雲端資源的費用，而不需要員工個別支付並求報銷。     You have an application that looks for its licensing server on the IP 10.0.3.21. You need to deploy the licensing server on Compute Engine. You do not want to change the configuration of the application and want the application to be able to reach the licensing server. What should you do?   A. Reserve the IP 10.0.3.21 as a static internal IP address using gcloud and assign it to the licensing server.\nB. Reserve the IP 10.0.3.21 as a static public IP address using gcloud and assign it to the licensing server.\nC. Use the IP 10.0.3.21 as a custom ephemeral IP address and assign it to the licensing server.\nD. Start the licensing server with an automatic ephemeral IP address, and then promote it to a static internal IP address\n \n    \n    解題  答案為A  有一個應用程式，該應用程式依賴於一個具有固定IP地址（10.0.3.21）的伺服器。你需要在Google Compute Engine上部署這個伺服器，而且不希望更改應用程式的配置。你應該怎麼做才能讓應用程式能夠正確地連接到這個伺服器？   A. 此選項建議使用gcloud命令行工具預先保留10.0.3.21作為靜態內部IP地址，並將其分配給認證伺服器。  B. 此選項建議使用gcloud工具將10.0.3.21保留為靜態公共IP地址。  C. 使用10.0.3.21作為臨時（ephemeral）IP地址  D. 建議首先使用自動分配的臨時IP啟動認證伺服器，然後再將其提升（或更改）為靜態內部IP地址。  上述四個選項以A的設定，就算VM重啟，IP地址也會保持不變。其餘三個，B實作上不建議使用公用IP，C的話臨時IP會在虛擬機重啟或停止會更動，最後D在VM啟動後，還需要進行額外的步驟更改IP地址。選項A是最好的解決方案，因為它確保了即使虛擬機器重啟，IP地址也會保持不變。而且它使用的是內部IP，適合於內部應用程式和伺服器之間的通信。     You are deploying an application to App Engine. You want the number of instances to scale based on request rate. You need at least 3 unoccupied instances at all times. Which scaling type should you use?   A. Manual Scaling with 3 instances.\nB. Basic Scaling with min_instances set to 3.\nC. Basic Scaling with max_instances set to 3\nD. Automatic Scaling with min_idle_instances set to 3.\n \n    \n    解題  D、ref:  https://cloud.google.com/appengine/docs/legacy/standard/python/how-instances-are-managed  題目希望您選擇一個scale策略，使應用程式的Instance可以基於請求速率自動調整，而且任何時候都至少有3個未被使用的實例。   A. 手動設定要運行的實例數量，不考慮當前的請求量。  B. 基本Scale基於請求速率和其他指標進行伸縮，但它也允許您設定最小實例數量。  C. 設定最多只能有3個實例運行，這不符合題目要求始終有3個“未被使用”的實例。  D. 自動伸縮允許實例數量根據實際的請求負載動態調整。  答案D，這題很明顯D為Automatic Scaling，字面上意思就是確保了有3個始終未被使用的實例，並且會根據請求速率自動調整其他實例數量。稍微提一下min_instances與min_idle_instances不一樣。min_instances只保證至少有3個實例運行，不管它們是否處於空閒狀態。min_idle_instances確保有3個實例始終處於空閒狀態，所以隨時可以開始處理新的請求。   補充：\nAn instance of an auto-scaled service is always running. \nHowever, an instance of a manual or basic scaled service can be either running or stopped. \nAll instances of the same service and version share the same state.\n     You have a development project with appropriate IAM roles defined. You are creating a production project and want to have the same IAM roles on the new project, using the fewest possible steps. What should you do?   A. Use gcloud iam roles copy and specify the production project as the destination project.\nB. Use gcloud iam roles copy and specify your organization as the destination organization.\nC. In the Google Cloud Platform Console, use the 'create role from role' functionality.\nD. In the Google Cloud Platform Console, use the 'create role' functionality and select all applicable permissions\n \n    \n    解題  A  如何最有效地在新的專案中複製或遷移既有的IAM角色設定。   A. 使用gcloud iam roles copy並指定生產專案作為目標專案。 這個選項建議使用gcloud命令行工具來直接複製一個角色到另一個專案。  B. 使用gcloud iam roles copy並指定你的組織作為目標組織。 這個選項也是使用gcloud命令行工具，但是建議將角色複製到整個組織範圍，這樣所有專案都能夠繼承這個角色。  C. 在Google Cloud Platform Console中，使用'create role from role'功能。 這個選項建議在GCP控制台中使用一個具體功能來從一個現有角色創建一個新角色。  D. 在Google Cloud Platform Console中，使用'create role'功能並選擇所有適用的權限。 這個選項建議手動在GCP控制台中創建一個新角色，並從頭開始選擇所需的權限。  答案是A，C沒有這個指令     You need a dynamic way of provisioning VMs on Compute Engine. The exact specifications will be in a dedicated configuration file. You want to follow Google's recommended practices. Which method should you use?   A. Deployment Manager\nB. Cloud Composer\nC. Managed Instance Group\nD. Unmanaged Instance Group\n \n   \n    解題  A  這個問題是關於在Google Cloud Platform（GCP）上動態配置和管理虛擬機（VMs）的最佳方法。特別是，它詢問如何根據一個專門的配置文件準確地配置VMs，同時遵循Google推薦的實踐。  A. Deployment Manager 已經於2022年終止服務，官方建議使用KRM 或 Terraform。原使用方法應為配置Yaml使其可以自動建置與增加VM。  B. Cloud Composer基於 Apache Airflow，是一個完全管理的工作流程自動化工具，用於建立、計畫、監控和管理工作流程。比較像在自動化建立GCP相關服務並整合  C. Managed Instance Group (MIG) (Migrate to Virtual Machines) 支持負載均衡、自動擴展和滾動更新，確保指定數量的實例始終是健康的和運行的。例如，如果MIG中的一個實例失效，MIG會自動替換該實例，以維持所需的實例數量。MIG還可以基於CPU使用率或其他指標動態調整實例的數量。  D. Unmanaged Instance Group 允許您組織一組單獨的實例，但不自動管理實例的生命週期。     You have a Dockerfile that you need to deploy on Kubernetes Engine. What should you do?   A. Use kubectl app deploy <dockerfilename>.\nB. Use gcloud app deploy <dockerfilename>.\nC. Create a docker image from the Dockerfile and upload it to Container Registry. \n   Create a Deployment YAML file to point to that image. Use kubectl to create the deployment with that file.\nD. Create a docker image from the Dockerfile and upload it to Cloud Storage. \n   Create a Deployment YAML file to point to that image. Use kubectl to create the deployment with that file.\n \n   \n    解題  C,  這個問題是關於如何在Google Kubernetes Engine (GKE) 上部署一個Docker容器。具體來說，它詢問當你有一個Dockerfile時，應該怎麼做才能將它部署到Kubernetes集群中。  A. 使用kubectl app deploy   。 這個命令格式並不正確，kubectl沒有app deploy這個指令。  B. 使用gcloud app deploy   。 這是Google Cloud Platform上的App Engine應用部署命令，用於部署App Engine應用，而不是用於Kubernetes Engine上部署Docker容器。  C. 從Dockerfile創建一個docker映像並將其上傳到Container Registry。創建一個指向該映像的Deployment YAML文件。使用kubectl來用該文件創建部署。 這是一個典型的流程，用於在Kubernetes上部署容器化應用。首先，你需要從Dockerfile構建一個Docker映像，然後將該映像推送到一個容器映像庫（在這裡是Google Container Registry）。接著，你需要創建一個Deployment的YAML配置文件，指定如何運行你的容器映像，最後使用kubectl命令來根據YAML文件創建部署。  D.  從Dockerfile創建一個docker映像並將其上傳到Cloud Storage。創建一個指向該映像的Deployment YAML文件。使用kubectl來用該文件創建部署。 這個選項建議將映像上傳到Google Cloud Storage，但這不是容器映像的標準存儲方式。通常，容器映像應該被推送到一個容器註冊中心，如Google Container Registry或Docker Hub。     Your development team needs a new Jenkins server for their project. You need to deploy the server using the fewest steps possible. What should you do?   A. Download and deploy the Jenkins Java WAR to App Engine Standard.\nB. Create a new Compute Engine instance and install Jenkins through the command line interface.\nC. Create a Kubernetes cluster on Compute Engine and create a deployment with the Jenkins Docker image.\nD. Use GCP Marketplace to launch the Jenkins solution.\n \n   \n    解題  D  您的開發團隊需要一個新的Jenkins伺服器用於他們的專案。您需要使用最少的步驟來部署伺服器。您應該怎麼做？  A. 下載並部署Jenkins Java WAR到App Engine Standard。  B. 創建一個新的Compute Engine實例並通過命令行介面安裝Jenkins。  C. 在Compute Engine上創建一個Kubernetes集群，並使用Jenkins Docker映像創建一個部署。  D. 使用GCP Marketplace啟動Jenkins解決方案。    https://cloud.google.com/solutions/using-jenkins-for-distributed-builds-on-compute-engine     You need to update a deployment in Deployment Manager without any resource downtime in the deployment. Which command should you use?   A. gcloud deployment-manager deployments create --config <deployment-config-path>\nB. gcloud deployment-manager deployments update --config <deployment-config-path>\nC. gcloud deployment-manager resources create --config <deployment-config-path>\nD. gcloud deployment-manager resources update --config <deployment-config-path>\n \n    \n    解題  B  如何使用Google Cloud Deployment Manager來更新一個現有部署，同時確保更新過程中不會導致任何資源的停機。Deployment Manager是一個基於資源的配置管理系統，允許你使用模板來自動創建、更新和管理Google Cloud資源。  A: 這個命令用於創建一個新的部署，並不適用於更新現有部署  B: 這個命令用於更新一個現有的部署。如果你的目標是在不停機的情況下更新部署，這是正確的選擇。  C: 這個命令用於創建新資源，而不是更新現有部署。  D: 這個選項不是一個實際存在的命令。在Deployment Manager中，資源的更新是通過更新部署來實現的，而不是直接對資源進行更新。 \n      You need to run an important query in BigQuery but expect it to return a lot of records. You want to find out how much it will cost to run the query. You are using on-demand pricing. What should you do?   A. Arrange to switch to Flat-Rate pricing for this query, then move back to on-demand.\n\nB. Use the command line to run a dry run query to estimate the number of bytes read. Then convert that bytes estimate to dollars using the Pricing Calculator.\n\nC. Use the command line to run a dry run query to estimate the number of bytes returned. Then convert that bytes estimate to dollars using the Pricing Calculator.\n\nD. Run a select count (*) to get an idea of how many records your query will look through. Then convert that number of rows to dollars using the Pricing Calculator.\n \n   \n    解題  B  這個問題是關於如何在使用Google Cloud BigQuery時，事先估算出一個查詢操作的成本。BigQuery是Google Cloud提供的一個大數據分析平台，它允許用戶存儲和查詢大量數據。BigQuery提供兩種計費模式：按需定價（on-demand pricing）和固定費率定價（flat-rate pricing）。按需定價根據查詢處理的數據量計費，而固定費率定價則允許用戶為一定的查詢容量支付固定費用。  A. 安排在這次查詢時切換到固定費率定價，然後再切回按需定價。 這個選項在技術上可行，但對於一次查詢來說過於繁瑣，且並非成本估算的直接方法。  B. 使用命令行運行一次試運行（dry run）查詢來估算讀取的字節數。然後使用定價計算器將這個字節估算轉換成美元。 這是一個有效的方法，因為BigQuery的按需定價是根據查詢分析的數據量來計費的，而不是基於返回的記錄數。這允許用戶在實際運行查詢前獲得成本估算。簡單來說按需定價可以做一個模擬估算的意思。  C. 使用命令行運行一次試運行查詢來估算返回的字節數。然後使用定價計算器將這個字節估算轉換成美元。 這個選項似乎有誤，因為BigQuery的費用是根據查詢過程中掃描的數據量來計算的，而不是基於查詢結果返回的數據量。  D. 運行一個select count (*)查詢來獲得你的查詢將查看多少記錄。然後使用定價計算器將這個行數轉換成美元。 這個方法不適用於估算成本，因為它並不考慮查詢實際上會掃描多少數據。BigQuery的費用計算基於查詢的數據量，而不是結果集的大小。     You have a single binary application that you want to run on Google Cloud Platform. You decided to automatically scale the application based on underlying infrastructure CPU usage. Your organizational policies require you to use virtual machines directly. You need to ensure that the application scaling is operationally efficient and completed as quickly as possible. What should you do?   A. Create a Google Kubernetes Engine cluster, and use horizontal pod autoscaling to scale the application.\nB. Create an instance template, and use the template in a managed instance group with autoscaling configured.\nC. Create an instance template, and use the template in a managed instance group that scales up and down based on the time of day.\nD. Use a set of third-party tools to build automation around scaling the application up and down, based on Stackdriver CPU usage monitoring.\n \n   \n    解題  B  這題在問的是，當你有一個單一的二進制應用程式，並希望在Google Cloud Platform（GCP）上運行這個應用程式時，如何根據底層基礎設施的CPU使用率自動調整應用程式的規模，同時要求操作效率高且迅速完成，而且還要遵循組織政策直接使用虛擬機（VM）。  A. 建立一個 GKE，使用橫向自動擴展設定應用 (題目要求用VM)  B. 建立一個 instance template ，並在 managed instance group 搭配 autoscaling configured 使用該template  C. 建立一個 instance template ，並在 managed instance group 中使用該模板，該 instance group 根據時間進行縮放  D. 使用第三方工具，基於 Stackdriver CPU 監看自動擴縮應用程式  最適合的選項是B：創建一個實例模板，並在一個配置了自動擴展的管理實例群組中使用該模板。這樣可以直接在虛擬機上運行應用程式，並根據CPU使用率自動調整應用程式的規模，符合操作效率高且快速完成的要求。選項C和D提供了基於時間或使用第三方工具的解決方案，這可能不如直接使用GCP內建的功能那樣操作高效且快速。   Instance template（實例模板）是一種Google Cloud Platform（GCP）的資源，用於定義虛擬機實例的配置。當你需要創建許多具有相同配置的虛擬機時，實例模板可以幫助你實現快速且一致的部署。     You are analyzing Google Cloud Platform service costs from three separate projects. You want to use this information to create service cost estimates by service type, daily and monthly, for the next six months using standard query syntax. What should you do?   A. Export your bill to a Cloud Storage bucket, and then import into Cloud Bigtable for analysis.\nB. Export your bill to a Cloud Storage bucket, and then import into Google Sheets for analysis.\nC. Export your transactions to a local file, and perform analysis with a desktop tool.\nD. Export your bill to a BigQuery dataset, and then write time window-based SQL queries for analysis.\n \n    \n    解題  D  這道題目是關於如何使用Google Cloud Platform（GCP）上的工具來分析三個不同項目的服務成本，並基於這些資料來預估未來六個月每種服務類型的日常和月度成本。選項中提供了不同的方法來達成這個目標，問題在於找出最合適的方式。  A. 將你的賬單導出到Cloud Storage桶，然後導入到Cloud Bigtable進行分析。 Cloud Bigtable是一個高效能的NoSQL數據庫服務，適用於大規模數據分析，但它可能不是分析賬單數據最直觀或成本效益最高的選擇。  B. 將你的賬單導出到Cloud Storage桶，然後導入到Google Sheets進行分析。 Google Sheets是一個雲端試算表應用，適合進行較小規模的數據分析和預算規劃，但可能不適合處理大量資料或進行複雜的時間窗口基礎的SQL查詢。  C. 將你的交易記錄導出到本地文件，並使用桌面工具進行分析。 這是一個選項，但它可能不利於自動化或規模化分析，且無法充分利用GCP提供的強大數據處理能力。  D. 將你的賬單導出到一個BigQuery數據集，然後撰寫基於時間窗口的SQL查詢進行分析。 BigQuery是一個企業級的數據倉庫服務，支持快速SQL查詢，非常適合進行大規模數據分析。通過將賬單數據導入BigQuery，你可以利用其強大的分析能力來執行複雜的查詢，如基於時間窗口的成本預估。  選項D是最佳選擇，因為它允許你利用BigQuery的強大查詢能力來分析賬單數據，並預測未來幾個月的服務成本。這種方法支持標準查詢語法，適合進行複雜的時間序列分析，且能夠處理大量數據，非常適合於成本估算的需求。     You need to set up a policy so that videos stored in a specific Cloud Storage Regional bucket are moved to Coldline after 90 days, and then deleted after one year from their creation. How should you set up the policy?   A. Use Cloud Storage Object Lifecycle Management using Age conditions with SetStorageClass and Delete actions. Set the SetStorageClass action to 90 days and the Delete action to 275 days (365-90).\n\nB. Use Cloud Storage Object Lifecycle Management using Age conditions with SetStorageClass and Delete actions. Set the SetStorageClass action to 90 days and the Delete action to 365 days.\n\nC. Use gsutil rewrite and set the Delete action to 275 days (365-90).\n\nD. Use gsutil rewrite and set the Delete action to 365 days.\n  \n    解題  B  如何設定一個策略，使得特定的Cloud Storage區域性儲存桶中的影片檔案在創建後90天自動轉移到Coldline存儲類別，並在創建後一年被自動刪除。  要實現這一點，你需要使用Cloud Storage的物件生命周期管理功能。物件生命周期管理允許你根據指定的條件（例如文件的年齡、存儲類別等）自動執行操作（如刪除文件或改變文件的存儲類別）。這是通過在儲存桶中設定規則來完成的。  A: 使用Cloud Storage物件生命周期管理，根據文件年齡設定SetStorageClass和Delete動作。將SetStorageClass動作設定為90天，Delete動作設定為275天（365-90）。這個選項的計算方法錯誤，因為它假設你需要在轉移後的時間計算刪除動作，但是Delete應該從原始創建日期計算365天。   正確的做法應該是將SetStorageClass動作設定為90天，以將文件轉移到Coldline存儲，然後將Delete動作直接設定為365天，表示從文件創建之日起一年後刪除，無論其是否已被轉移到Coldline存儲。这样，文件在创立90天后转移至Coldline，到达创立365天时被删除，而不是在转移后开始计算删除的时间。  B: 使用Cloud Storage物件生命周期管理，根據文件年齡設定SetStorageClass和Delete動作。將SetStorageClass動作設定為90天，Delete動作設定為365天。這是正確的設定方式，因為它確保了文件在創建後90天轉移到Coldline，並在創建後一年被刪除，無論其在90天時的存儲類別變更。  C 和 D: 使用gsutil rewrite命令並設定Delete動作。這些選項並不支持自動基於檔案年齡轉換存儲類別或自動刪除檔案的功能。     You have a Linux VM that must connect to Cloud SQL. You created a service account with the appropriate access rights. You want to make sure that the VM uses this service account instead of the default Compute Engine service account. What should you do?   A. When creating the VM via the web console, specify the service account under the 'Identity and API Access' section.\n\nB. Download a JSON Private Key for the service account. On the Project Metadata, add that JSON as the value for the key compute-engine-service- account.\n\nC. Download a JSON Private Key for the service account. On the Custom Metadata of the VM, add that JSON as the value for the key compute-engine-service-account.\n\nD. Download a JSON Private Key for the service account. After creating the VM, ssh into the VM and save the JSON under ~/.gcloud/compute-engine-service-account.json.\n \n   \n    解題  A，正確的做法是選項A：在創建VM的過程中，透過網頁控制台，在“身份和API訪問”部分指定你想使用的服務帳戶。這樣做可以確保VM在創建時就配置好了正確的服務帳戶，無需後續手動操作或保存私鑰到VM上，這也是一種更安全的做法。  這題目在詢問當你擁有一台需要連接到Cloud SQL的Linux虛擬機（VM），且已經創建了一個具有適當訪問權限的服務帳戶時，你應該如何配置VM，使其使用這個指定的服務帳戶來代替默認的Compute Engine服務帳戶。  A. 在網頁控制台創建VM時，在“身份和API訪問”部分指定服務帳戶。  B. 為服務帳戶下載一個JSON私鑰。在項目元數據上，將該JSON作為compute-engine-service-account鍵的值添加。  C. 為服務帳戶下載一個JSON私鑰。在VM的自定義元數據上，將該JSON作為compute-engine-service-account鍵的值添加。  D. 為服務帳戶下載一個JSON私鑰。創建VM後，ssh進入VM並將JSON保存在~/.gcloud/compute-engine-service-account.json下。     You created an instance of SQL Server 2017 on Compute Engine to test features in the new version. You want to connect to this instance using the fewest number of steps. What should you do?   A. Install a RDP client on your desktop. Verify that a firewall rule for port 3389 exists.\n\nB. Install a RDP client in your desktop. Set a Windows username and password in the GCP Console. Use the credentials to log in to the instance.\n\nC. Set a Windows password in the GCP Console. Verify that a firewall rule for port 22 exists. Click the RDP button in the GCP Console and supply the credentials to log in.\n\nD. Set a Windows username and password in the GCP Console. Verify that a firewall rule for port 3389 exists. Click the RDP button in the GCP Console, and supply the credentials to log in\n \n    \n    解題  B  當你在Compute Engine上創建了一個SQL Server 2017的實例以測試新版本的功能時，應該如何使用最少的步驟連接到這個實例。  A. 在你的桌面安裝一個RDP（遠端桌面協議）客戶端。確認存在針對端口3389的防火牆規則。  B. 在你的桌面安裝一個RDP客戶端。在GCP控制台設置一個Windows用戶名和密碼。使用這些憑證登入實例。  C. 在GCP控制台設置一個Windows密碼。確認存在針對端口22的防火牆規則。點擊GCP控制台中的RDP按鈕，並提供憑證以登入。  D. 在GCP控制台設置一個Windows用戶名和密碼。確認存在針對端口3389的防火牆規則。點擊GCP控制台中的RDP按鈕，並提供憑證以登入。  在Google Cloud Platform (GCP) 上，Compute Engine提供的Windows映像（Image）預設已經啟用了遠端桌面連線（Remote Desktop Protocol, RDP），且相關的防火牆規則（對於端口3389，即RDP使用的端口）通常也是預設開啟的。這樣的設計是為了讓用戶能夠更容易地開始使用虛擬機實例，無需進行複雜的初始設定。  因此，在這種情況下，當你需要連接到Compute Engine上的SQL Server 2017實例時，主要步驟實際上就是：  在GCP控制台為Compute Engine實例設置Windows用戶名和密碼。這一步是必要的，因為它提供了登入Windows系統的認證。\n使用任何標準的RDP客戶端軟件從你的桌面連接到該實例。由於RDP和對應的防火牆規則已經預設啟用，這一步應該是直接可行的。\n因此，選項B是最合理的選擇，因為它直接指向了實際操作中需要完成的主要步驟，而無需擔心遠端桌面連線或防火牆設置的問題。这样的设计极大地简化了在GCP上部署和管理Windows虚拟机实例的过程。     You have one GCP account running in your default region and zone and another account running in a non-default region and zone. You want to start a new Compute Engine instance in these two Google Cloud Platform accounts using the command line interface. What should you do?   A. Create two configurations using gcloud config configurations create [NAME]. \n  Run gcloud config configurations activate [NAME] to switch between accounts \n  when running the commands to start the Compute Engine instances.\n\nB. Create two configurations using gcloud config configurations create [NAME]. \n  Run gcloud configurations list to start the Compute Engine instances.\n\nC. Activate two configurations using gcloud configurations activate [NAME]. \n  Run gcloud config list to start the Compute Engine instances.\n\nD. Activate two configurations using gcloud configurations activate [NAME]. \n  Run gcloud configurations list to start the Compute Engine instances.\n \n    \n    解題  A  關於如何使用Google Cloud Platform (GCP) 的gcloud命令行工具來管理不同帳戶和配置，並在這些帳戶中啟動(激活)新的Compute Engine實例。   command line interface指得就是gcloud CLI（Command Line Interface）  A: 這個選項提供了一個步驟來管理不同的GCP帳戶或項目的方法。首先，使用gcloud config configurations create   NAME 創建不同的配置文件，每個配置對應一個帳戶或項目。然後，通過gcloud config configurations activate   NAME 來激活特定的配置，這樣就可以在該配置對應的帳戶或項目中運行命令了。這是啟動Compute Engine實例時切換帳戶的有效方法。  B: 這個選項提到了創建配置和列出配置的命令，但沒有提到如何激活特定配置或如何在特定配置下啟動實例的步驀。  C 和 D: 這兩個選項提到了gcloud configurations activate   NAME 和gcloud configurations list命令，但實際上，正確的命令應該是gcloud config configurations activate   NAME 用於激活配置，而gcloud config list可以用來查看當前激活配置的詳細信息。這兩個選項中的命令和步驟描述不準確或不完整。  A是最合適的選項，因為它正確描述了如何創建和激活配置，以及在不同的GCP帳戶或項目中管理和啟動Compute Engine實例的流程。     You significantly changed a complex Deployment Manager template and want to confirm that the\ndependencies of all defined resources are properly met before committing it to the project.\nYou want the most rapid feedback on your changes. What should you do?   A. Use granular logging statements within a Deployment Manager template authored in Python.\nB. Monitor activity of the Deployment Manager execution on the Stackdriver Logging page of the GCP Console.\nC. Execute the Deployment Manager template against a separate project with the same configuration, \n   and monitor for failures.\nD. Execute the Deployment Manager template using the --preview option in the same project, \n   and observe the state of interdependent resources.\n \n   \n    解題  D  GCP 上面建立新的資源，基本上可以下列透過三種方式：   直接在 Web UI 上用瀏覽器操作  Deployment Manager  直接呼叫 GCP 的 API  這題是在詢問，當你對一個複雜的Deployment Manager模板進行了重大更改後，如何在提交到項目之前確認所有定義資源的依賴關係是否得到了妥善處理，以便能夠最快速地獲得對這些更改的反饋。  A. 在Python編寫的Deployment Manager模板中使用細粒度日誌語句。這個方法可以提供一定的反饋，但可能不是最快或最直接的方法來檢查依賴關係是否正確。  B. 在GCP Console的Stackdriver Logging頁面上監控Deployment Manager執行的活動。這同樣可以提供反饋，但是相對間接，且需要等待部署執行。   Stackdriver Logging，現在被稱為Google Cloud's Operations Suite的一部分，是Google Cloud提供的一項服務，用於收集、查看和分析Google Cloud和Amazon Web Services (AWS)上的虛擬機器和應用程式的日誌數據。這項服務支援日誌數據的即時分析，並允許用戶通過強大的搜尋功能來檢索和過濾日誌。它是Google Cloud's Operations Suite的核心組件之一，旨在幫助開發人員和運維團隊監控和診斷跨多種雲服務和應用程式的問題。  C. 對一個具有相同配置的單獨項目執行Deployment Manager模板，並監控是否有失敗發生。這個方法可以提供實際的測試反饋，但是比較耗時且可能影響到其他項目。  D. 使用--preview選項在相同項目中執行Deployment Manager模板，並觀察相互依賴資源的狀態。這個方法可以在不真正執行部署的情況下，快速地提供對依賴關係和配置更改的預覽和驗證。  基於快速獲得反饋的需求，選項D提供了一種在實際提交更改之前，快速檢查和預覽資源依賴關係是否正確的方法。     You are building a pipeline to process time-series data. Which Google Cloud Platform services should you put in boxes 1,2,3, and 4?     A. Cloud Pub/Sub, Cloud Dataflow, Cloud Datastore, BigQuery\nB. Firebase Messages, Cloud Pub/Sub, Cloud Spanner, BigQuery\nC. Cloud Pub/Sub, Cloud Storage, BigQuery, Cloud Bigtable\nD. Cloud Pub/Sub, Cloud Dataflow, Cloud Bigtable, BigQuery\n \n    \n    解題  D  這個題目給出了一個處理時序數據的Google Cloud Platform (GCP)架構圖，要求你選擇適合放入四個標示為1、2、3和4的框中的GCP服務。這些框代表數據流通的不同階段：  數據接收：數據從設備通過閘道器進入GCP。\n數據處理：數據在GCP內部進行處理。\n數據儲存：處理後的數據被存儲起來。\n數據分析：存儲的數據進行分析。   Cloud Pub/Sub: 用於消息傳遞和流式數據的實時傳遞，適合放在1號框中，作為數據的接收點。  Cloud Dataflow: 是一個完全管理的服務，用於轉換和豐富數據在流和批處理模式下，適合放在2號框中，處理數據。  Cloud Storage: 是一個對象存儲服務，用於存儲大量未處理或處理後的數據，適合放在3號框中。  BigQuery: 是一個完全管理的大數據分析平台，適合放在4號框中，進行數據分析。  根據這些描述，正確答案應該是選項D：Cloud Pub/Sub, Cloud Dataflow, Cloud Bigtable, BigQuery。這樣的選擇符合時序數據處理的一般流程：從接收數據（Pub/Sub），到處理數據（Dataflow），再到儲存數據（Bigtable是一種適合時序數據的NoSQL數據庫），最後進行數據分析（BigQuery）。     You have a project for your App Engine application that serves a development environment.\nThe required testing has succeeded and you want to create a new project to serve as your production environment. What should you do?   A. Use gcloud to create the new project, and then deploy your application to the new project.\nB. Use gcloud to create the new project and to copy the deployed application to the new project.\nC. Create a Deployment Manager configuration file that copies the current App Engine deployment into a new project.\nD. Deploy your application again using gcloud and specify the project parameter with the new project name to create the new project.\n \n   \n    解題  這個題目是關於如何在Google Cloud Platform上使用App Engine應用程式，從一個已經存在的開發環境項目（project）創建一個新的生產環境項目。選項中提供了幾種不同的方法來創建新項目並部署應用程式。  A. 使用gcloud命令行工具創建新項目，然後將應用程式部署到新項目中。\nB. 使用gcloud命令行工具創建新項目並將已部署的應用程式複製到新項目。\nC. 創建一個Deployment Manager配置文件，將當前App Engine部署複製到新項目中。\nD. 再次使用gcloud部署應用程式，並指定新項目的項目參數以創建新項目。  正確的做法是選項A。你需要首先創建一個新的項目，然後將你的應用程式部署到這個新項目中作為生產環境。在Google Cloud中，一個項目是最高層級的組織單位，它代表了一組設置和服務資源的集合。你不能直接將一個項目中的應用程式複製到另一個項目，因此選項B和C不可行。同樣地，選項D的描述也不正確，因為你不能通過部署應用程式來創建一個新項目；項目必須先存在才能部署應用程式。  具體作法如下  1.創建新的GCP項目：  使用gcloud命令行工具創建一個新的Google Cloud Platform項目。可以使用下面的命令：   gcloud projects create [YOUR_PROJECT_ID] --name=\"[YOUR_PROJECT_NAME]\"\n\n  其中  YOUR_PROJECT_ID 是你選擇的項目ID（這個ID必須是唯一的），而  YOUR_PROJECT_NAME 是你給項目的名稱。  2.設置計費資訊：  新項目創建後，你需要為它設置計費資訊。這通常需要在Google Cloud Console中手動完成。  3.部署應用程式到新項目：  在你的開發機器上，配置gcloud命令行工具以使用新項目：   gcloud config set project [YOUR_PROJECT_ID]\n  然後部署你的App Engine應用程式到新項目中：   gcloud app deploy [YOUR_APP_YAML_PATH] --project=[YOUR_PROJECT_ID]\n   YOUR_APP_YAML_PATH 是你的App Engine應用程式配置文件的路徑。  4.驗證部署：  部署完成後，檢查應用程式是否正確運行。你可以使用以下命令來瀏覽你的應用程式：   gcloud app browse --project=[YOUR_PROJECT_ID]\n     You need to configure IAM access audit logging in BigQuery for external auditors.\nYou want to follow Google-recommended practices. What should you do?   A. Add the auditors group to the 'logging.viewer' and 'bigQuery.dataViewer' predefined IAM roles.\nB. Add the auditors group to two new custom IAM roles.\nC. Add the auditor user accounts to the 'logging.viewer' and 'bigQuery.dataViewer' predefined IAM roles.\nD. Add the auditor user accounts to two new custom IAM roles.\n\n \n   \n    解題  A  這題在問如何為外部審計人員配置BigQuery的IAM（Identity and Access Management）訪問審計日誌。目的是確保審計人員可以查看日誌和數據，但同時遵循Google推薦的最佳做法。  A. 將審計人員組添加到'logging.viewer'和'bigQuery.dataViewer'這兩個預定義的IAM角色。\nB. 為審計人員組創建兩個新的自定義IAM角色。\nC. 將審計人員的用戶帳戶添加到'logging.viewer'和'bigQuery.dataViewer'這兩個預定義的IAM角色。\nD. 為審計人員的用戶帳戶創建兩個新的自定義IAM角色。  在這些選項中，選項A和C都提到了將審計人員（無論是以組還是個別用戶帳戶的形式）添加到預定義的IAM角色中。'logging.viewer'角色允許用戶查看日誌，而'bigQuery.dataViewer'角色允許用戶查看BigQuery中的數據。  選項B和D提到了創建自定義的IAM角色，這可以提供更細緻的訪問控制，但並非Google推薦的實踐，除非有特定需求。  根據Google的最佳做法，最簡單且推薦的方法是使用預定義的IAM角色，因為它們已經為特定的服務定義了必要的許可權。因此，選項A或C會是合適的選擇。通常建議使用組（選項A）而不是個別用戶帳戶（選項C），因為這樣可以更容易地管理多個審計人員的訪問權限。如果審計人員已經組織在一個Google群組中，那麼將該組添加到這些角色會是最好的做法。     You need to set up permissions for a set of Compute Engine instances to enable them to write data into a particular Cloud Storage bucket. You want to follow Google-recommended practices. What should you do?   A. Create a service account with an access scope. Use the access scope 'https://www.googleapis.com/auth/devstorage.write_only'.\nB. Create a service account with an access scope. Use the access scope 'https://www.googleapis.com/auth/cloud-platform'.\nC. Create a service account and add it to the IAM role 'storage.objectCreator' for that bucket.\nD. Create a service account and add it to the IAM role 'storage.objectAdmin' for that bucket.\n \n   \n    解題  C  為一組Compute Engine實例設置權限，使它們能夠寫入數據到特定的Cloud Storage桶，你應該根據Google推薦的做法進行操作  A. 創建一個服務帳戶並賦予訪問範圍。使用訪問範圍'  https://www.googleapis.com/auth/devstorage.write_only'，這個範圍僅允許寫入訪問權限，不允許讀取或列出桶中的對象。  B. 創建一個服務帳戶並賦予訪問範圍。使用訪問範圍'  https://www.googleapis.com/auth/cloud-platform'，這個範圍賦予對所有Cloud  Platform服務的完整訪問權限。  C. 創建一個服務帳戶，並將其添加到該桶的IAM角色'storage.objectCreator'，此角色賦予服務帳戶向該桶中創建對象的權限。  D. 創建一個服務帳戶，並將其添加到該桶的IAM角色'storage.objectAdmin'，此角色賦予服務帳戶對該桶中對象的完全管理權限，包括讀取、寫入和刪除。  根據Google的最佳做法，最好是遵循最小權限原則，只賦予足夠的權限以完成任務，不多給不必要的權限。因此，選項C（將服務帳戶添加到IAM角色'storage.objectCreator'）是最佳選擇     You have sensitive data stored in three Cloud Storage buckets and have enabled data access logging.\nYou want to verify activities for a particular user for these buckets, using the fewest possible steps.\nYou need to verify the addition of metadata labels and which files have been viewed from those buckets. What should you do?   A. Using the GCP Console, filter the Activity log to view the information.\nB. Using the GCP Console, filter the Stackdriver log to view the information. \nC. View the bucket in the Storage section of the GCP Console.\nD. Create a trace in Stackdriver to view the information.\n \n   \n    解題  A  如何利用Google Cloud Platform (GCP) 的日誌功能來檢查特定用戶對於三個Cloud Storage桶的數據存取活動，特別是要驗證用戶是否添加了元數據標籤以及查看了哪些文件。如果要以最少的步驟完成這個任務，應該採取哪種做法。  A. 使用GCP控制台，過濾「活動日誌」以查看這些信息。\nB. 使用GCP控制台，過濾「Stackdriver日誌」以查看這些信息。   Stackdriver 被整合成現在 GCP Cloud Logging，用來記錄自定義Log。\nC. 在GCP控制台的「存儲」部分查看桶。\nD. 在Stackdriver中創建一個追踪以查看這些信息。  A步驟為  步驟：   登入GCP控制台。  點擊左上角的漢堡菜單（三條橫線）。  在菜單中找到並點擊“Logging”（日誌記錄）。  點擊“Activity log”（活動日誌）標籤。  點擊“Filter”（篩選）按鈕。  在“Resource”（資源）欄位，輸入三個Cloud Storage存儲桶的名稱。  在“User”（用戶）欄位，輸入你想要審核的特定用戶的名稱。  點擊“Apply”（應用）按鈕。  活動日誌會展示這個特定用戶在三個指定Cloud Storage存儲桶上的所有活動記錄。你可以檢視這些記錄以確認是否有添加元數據標籤的動作，以及哪些文件被查看過。  選擇B、C和D不如選擇A高效，因為它們不提供按用戶或資源過濾結果的選項，或者需要較多的步驟和資源來執行。  選擇B提到的操作需要在Stackdriver（現在稱為Google Cloud's operations suite的一部分）中創建追踪。創建追踪可能會比較複雜，並且如果沒有準確的了解如何設定，容易導致錯誤。此外，這個過程相比於直接查看活動日誌，可能更加耗時。  選項C和D提供的方法不允許用戶根據特定的用戶或特定的資源（如特定的Cloud Storage存儲桶）來過濾和查看活動。在驗證特定用戶的行為時，能夠按用戶或資源進行篩選是非常重要的，因為這樣可以直接定位到相關的活動日誌條目。     You are the project owner of a GCP project and want to delegate control to colleagues to manage buckets and files in Cloud Storage. You want to follow Google-recommended practices. Which IAM roles should you grant your colleagues?   A. Project Editor\nB. Storage Admin\nC. Storage Object Admin \nD. Storage Object Creator\n \n   \n    解題  C, 只管Sotrage裡面的東西..所以不會是B  你是一個Google Cloud Platform (GCP)項目的擁有者，並希望將權限委派給同事去管理Cloud Storage中的桶(bucket)和文件(object)，你應該賦予他們哪種IAM(身份及存取管理)角色，以便遵循Google推薦的最佳實踐。  A. Project Editor: 這個角色允許對項目中的資源進行廣泛的修改操作，但它提供的權限範圍比較廣，可能不是最適合細粒度控制Cloud Storage資源的選擇。  B. Storage Admin: 此角色提供對Cloud Storage資源的完全管理許可權，包括創建、刪除桶，以及管理桶內的對象和設置。它是一個適合需要完整控制Cloud Storage資源的情況。  C. Storage Object Admin: 此角色專注於對存儲在桶中的對象進行管理，包括創建、刪除和修改對象。它不提供創建或刪除桶的能力。  D. Storage Object Creator: 這個角色限於允許創建對象（文件）在桶中，但不允許刪除或修改現有對象，適合只需要上傳文件權限的情境。     You have an object in a Cloud Storage bucket that you want to share with an external company.\nThe object contains sensitive data. You want access to the content to be removed after four hours.\nThe external company does not have a Google account to which you can grant specific user-based access privileges. You want to use the most secure method that requires the fewest steps. What should you do?   A. Create a signed URL with a four-hour expiration and share the URL with the company.\n\nB. Set object access to 'public' and use object lifecycle management to remove the object after four hours.\n\nC. Configure the storage bucket as a static website and furnish the object's URL to the company. Delete the object from the storage bucket after four hours.\n\nD. Create a new Cloud Storage bucket specifically for the external company to access. Copy the object to that bucket. Delete the bucket after four hours have passed. \n \n   \n    解題  A  如何安全地與一個外部公司分享一個包含敏感資料的物件（object），該物件存儲在Google Cloud Storage桶（bucket）中，並且要求在四小時後自動撤銷對該內容的訪問權限。外部公司沒有Google賬戶，因此無法透過基於用戶的訪問權限直接分享。  A. 創建一個帶有四小時過期時間的簽名URL，並與該公司分享。**這是一種安全的分享方法，允許非Google用戶透過簽名URL訪問特定物件，該URL在設定的時間後自動失效，無需手動介入。  B. 將物件訪問設置為'public'，並使用物件生命周期管理在四小時後刪除物件。**這種方法會暴露敏感資料給公眾直到被刪除，風險較高。  C. 將存儲桶配置為靜態網站，提供物件的URL給該公司。四小時後從存儲桶中刪除物件。**這個選項需要手動操作刪除物件，且在刪除前物件對所有人可見，不是最安全的選擇。  D. 專門為外部公司訪問創建一個新的Cloud Storage桶，將物件復制到該桶中。四小時後刪除該桶。**這個方法比較繁瑣，需要創建新的存儲桶並在四小時後手動刪除。     You are creating a Google Kubernetes Engine (GKE) cluster with a cluster autoscaler feature enabled.\nYou need to make sure that each node of the cluster will run a monitoring pod that sends container metrics to a third-party monitoring solution. What should you do?   A. Deploy the monitoring pod in a StatefulSet object.\nB. Deploy the monitoring pod in a DaemonSet object.\nC. Reference the monitoring pod in a Deployment object.\nD. Reference the monitoring pod in a cluster initializer at the GKE cluster creation time.\n \n   \n    解題  B  如何在Google Kubernetes Engine (GKE) 集群中確保每個節點都運行一個監控Pod，這個Pod負責將容器的度量指標發送到第三方監控解決方案。在Kubernetes中，有幾種不同的方式來部署和管理Pods，這個題目考察的是選擇哪一種部署方式最合適。  **A. 在StatefulSet物件中部署監控Pod。**StatefulSet主要用於管理有狀態的應用，保證Pod的順序和唯一性，並不適合確保每個節點都運行一個Pod的場景。  **B. 在DaemonSet物件中部署監控Pod。**DaemonSet確保所有（或者某些特定的）節點運行一份Pod的副本。當有節點加入集群時，會自動添加Pod到新節點，當節點從集群中移除時，這些Pod也會被回收。這適合於部署集群範圍內的監控和日誌收集。  **C. 在Deployment物件中引用監控Pod。**Deployment主要用於無狀態應用，提供聲明式更新等特性。雖然它可以擴展Pod副本數量，但不能保證在每個節點上都運行一個Pod。  **D. 在GKE集群創建時，於集群初始化器中引用監控Pod。**這不是Kubernetes的標準操作，也不提供一種機制來確保每個節點都運行指定的Pod。  根據題目要求，最佳選項是B. 在DaemonSet物件中部署監控Pod，因為它能夠保證每個節點都運行一個監控Pod，從而實現對整個集群的監控。  特殊型別服務、StatefulSet\\ DaemonSet\\ Deployment 概念   DaemonSet 確保每個 Node 都有一個 Pod 運行副本。每個 Node 都會監控 Pod  StatefulSet 它設計用於管理需長久儲存、依序啟動和停止的 Pod  Deployment 集群初始化程序（cluster initializer）通常用于在集群创建时进行一次性操作，而不是确保在每个节点上运行一个 Pod。   StatefulSet具體做法：   創建StatefulSet：你定義一個StatefulSet資源，指定應用的容器映像、所需的服務名稱（用於網絡通信），以及存儲卷的配置（通常是通過PersistentVolumeClaim來實現持久化存儲）。  部署和管理：Kubernetes為每個StatefulSet的Pod創建一個唯一的、有序的標識符，並根據定義的規則來管理這些Pod的部署和擴展。這包括在更新或擴展StatefulSet時保持Pod的啟動順序。  DaemonSet具體做法：   創建DaemonSet：你定義一個DaemonSet資源，指出要運行的容器映像和需要在每個節點上運行的任務或服務。  自動部署：Kubernetes自動在現有的每個節點上部署指定的Pod。當有新節點加入集群時，DaemonSet會自動在這些新節點上啟動其Pod副本，確保每個節點都運行該服務。     You want to send and consume Cloud Pub/Sub messages from your App Engine application. The Cloud Pub/Sub API is currently disabled. You will use a service account to authenticate your application to the API. You want to make sure your application can use Cloud Pub/Sub. What should you do?   A. Enable the Cloud Pub/Sub API in the API Library on the GCP Console.\nB. Rely on the automatic enablement of the Cloud Pub/Sub API when the Service Account accesses it.\nC. Use Deployment Manager to deploy your application. Rely on the automatic enablement of all APIs used by the application being deployed.\nD. Grant the App Engine Default service account the role of Cloud Pub/Sub Admin. Have your application enable the API on the first connection to Cloud Pub/ Sub.\n \n    \n    解題  A.  很單純邏輯，The Cloud Pub/Sub API is currently disabled，所以就是啟用API...其餘不用多看     You need to monitor resources that are distributed over different projects in Google Cloud Platform. You want to consolidate reporting under the same Stackdriver Monitoring dashboard. What should you do?   A. Use Shared VPC to connect all projects, and link Stackdriver to one of the projects.\n\nB. For each project, create a Stackdriver account. In each project, create a service account for that project and grant it the role of Stackdriver Account Editor in all other projects.\n\nC. Configure a single Stackdriver account, and link all projects to the same account.\n\nD. Configure a single Stackdriver account for one of the projects. In Stackdriver, create a Group and add the other project names as criteria for that Group.\n \n    \n    解題  C  如何在Google Cloud Platform（GCP）中監控分布於不同項目之間的資源，並希望將報告整合到同一個Stackdriver監控儀表板下。  A. 使用Shared VPC連接所有項目，並將Stackdriver鏈接到其中一個項目。 Shared VPC允許不同的GCP項目共享網絡資源，但這與在Stackdriver中整合監控資源的要求不直接相關。  B. 對每個項目創建一個Stackdriver賬戶。在每個項目中，為該項目創建一個服務賬戶，並在所有其他項目中授予它Stackdriver賬戶編輯者角色。 這種方法在理論上可以工作，但它需要復雜的設置且管理起來相當繁瑣，並不是一個高效的解決方案。  C. 配置單一的Stackdriver賬戶，並將所有項目鏈接到同一賬戶。 這是一個直接且高效的方法，允許你將來自不同GCP項目的監控資料整合到一個Stackdriver儀表板中。這樣做可以簡化監控和報告的過程，是Google推薦的做法。  D. 為其中一個項目配置單一的Stackdriver賬戶。在Stackdriver中創建一個群組，並將其他項目名作為該群組的標準。 這種方法也可以實現跨項目的資源監控，但它比選項C更加間接和複雜。  最佳做法是選擇C，配置單一的Stackdriver賬戶並將所有項目鏈接到這個賬戶。這樣可以最簡單直接地實現跨多個GCP項目的資源監控和報告整合。   訪問Google Cloud Console： 首先，登入你的Google Cloud Console (console.cloud.google.com)。  選擇或創建一個Stackdriver賬戶：   如果你已經有一個Stackdriver賬戶，可以直接使用。  如果沒有，你需要創建一個。在Google Cloud Console的導航菜單中選擇“Monitoring”或在搜索框中搜索“Monitoring”，然後跟隨指引創建一個新的Stackdriver賬戶。  將項目鏈接到Stackdriver賬戶：   在創建或選擇你的Stackdriver賬戶後，你會被引導到Stackdriver的儀表板。在這裡，你可以添加或鏈接其他Google Cloud項目到你的Stackdriver賬戶。  在Stackdriver儀表板上，尋找“設置”或“管理”選項，然後選擇“帳戶設置”或類似選項。  找到“項目”或“添加項目”選項，選擇你想要監控的Google Cloud項目，並將它們添加到你的Stackdriver賬戶中。  設置權限：   確保你有足夠的權限來將項目添加到Stackdriver賬戶。你可能需要擁有這些項目的“項目擁有者”或“項目編輯者”角色。  對於需要監控的每個項目，確保Stackdriver服務賬戶（通常是自動創建的）具有足夠的權限來訪問和收集監控數據。  驗證配置：   完成添加和配置後，返回到Stackdriver儀表板，檢查是否能夠看到所有鏈接項目的監控數據。  你可以創建自定義儀表板來顯示跨多個項目的關鍵指標，或使用預設的監控視圖來查看資源的狀態。     You are deploying an application to a Compute Engine VM in a managed instance group. The application must be running at all times, but only a single instance of the VM should run per GCP project. How should you configure the instance group?   A. Set autoscaling to On, set the minimum number of instances to 1, and then set the maximum number of instances to 1. \n\nB. Set autoscaling to Off, set the minimum number of instances to 1, and then set the maximum number of instances to 1. \n\nC. Set autoscaling to On, set the minimum number of instances to 1, and then set the maximum number of instances to 2. \n\nD. Set autoscaling to Off, set the minimum number of instances to 1, and then set the maximum number of instances to 2.\n \n    \n    解題  A, 要開autoscaling，不然掛了無法自動復原     You want to verify the IAM users and roles assigned within a GCP project named my-project. What should you do?   A. Run gcloud iam roles list. Review the output section.\nB. Run gcloud iam service-accounts list. Review the output section.\nC. Navigate to the project and then to the IAM section in the GCP Console. Review the members and roles. \nD. Navigate to the project and then to the Roles section in the GCP Console. Review the roles and status.\n \n    \n    解題  C  如何查驗在一個名為 my-project 的 Google Cloud Platform (GCP) 項目中指派給 IAM（Identity and Access Management，身份與存取管理）用戶和角色的方式。  A. Run gcloud iam roles list. Review the output section. 這個命令列出所有可用的IAM角色，但不會顯示哪些用戶或服務賬戶被指派了這些角色。  B. Run gcloud iam service-accounts list. Review the output section. 這個命令會列出所有的服務賬戶，但同樣不會提供哪些角色被指派給這些服務賬戶的資訊。  C. Navigate to the project and then to the IAM section in the GCP Console. Review the members and roles. 這是正確的操作步驟。在GCP Console中的IAM部分，你可以查看到所有被授予訪問該項目的成員（用戶、服務賬戶等）以及他們被指派的角色。  D. Navigate to the project and then to the Roles section in the GCP Console. Review the roles and status. 這個操作會讓你查看到所有可用的角色及其狀態，但不會顯示哪些成員被指派了這些角色。     You need to create a new billing account and then link it with an existing Google Cloud Platform project. What should you do?   A. Verify that you are Project Billing Manager for the GCP project. Update the existing project to link it to the existing billing account.\n\nB. Verify that you are Project Billing Manager for the GCP project. Create a new billing account and link the new billing account to the existing project.\n\nC. Verify that you are Billing Administrator for the billing account. Create a new project and link the new project to the existing billing account.\n\nD. Verify that you are Billing Administrator for the billing account. Update the existing project to link it to the existing billing account.\n \n    \n    解題  題目要求創建一個新的計費帳戶，然後將這個新的計費帳戶與一個已經存在的GCP專案連結。這個過程涉及到兩個角色：「計費管理員」和「項目計費管理員」。這些角色確保了只有擁有適當權限的使用者能夠更改計費和專案設定。  A. 驗證你是GCP專案的項目計費管理員。更新現有專案，將其連結到現有計費帳戶。  這個選項提到了更新現有專案以連結到一個「現有」的計費帳戶，但題目要求創建一個「新的」計費帳戶並進行連結，因此這個選項不正確。  B. 驗證你是GCP專案的項目計費管理員。創建一個新的計費帳戶並將新計費帳戶連結到現有專案。  這個選項正好符合題目的要求：先確認你擁有對專案的計費管理權限，然後創建一個新的計費帳戶，並將這個新帳戶與一個已存在的專案連結。這是一個看起來很合理的步驟。  C. 驗證你是計費帳戶的計費管理員。創建一個新專案並將新專案連結到現有計費帳戶。  這個選項與題目要求不符，因為它講的是創建一個新的專案並將其連結到一個已存在的計費帳戶，而不是創建新的計費帳戶。  D. 驗證你是計費帳戶的計費管理員。更新現有專案，將其連結到現有計費帳戶。  這個選項同樣沒有涉及到創建一個新的計費帳戶，所以也不符合題目的要求。  正確答案\n根據以上分析，正確答案是 B。這個選項直接回應了題目的需求，即創建一個新的計費帳戶並將其與一個已存在的GCP專案連結，同時確保操作者有適當的權限（作為專案的項目計費管理員）。這樣的流程不僅合乎邏輯，也符合GCP管理計費和專案的標準操作程序。    Billing Administrator（計費管理員）   職責範圍：計費管理員主要負責管理計費帳戶的設定和付款方式。這包括創建和管理計費帳戶、設定付款方式、查看和管理計費報告和成本分析，以及設定預算和警報。  權限範圍：計費管理員有權訪問和修改計費帳戶的所有相關資訊。這意味著他們可以對計費帳戶進行廣泛的操作，從而控制成本和付款。  Project Billing Manager（項目計費管理員）   職責範圍：項目計費管理員主要負責將特定的GCP專案與一個計費帳戶連結。他們確保專案的使用費用被正確記錄和計費到指定的計費帳戶。  權限範圍：項目計費管理員的權限限於  特定專案的計費設定 。他們可以變更專案所關聯的計費帳戶，但不能管理計費帳戶本身的財務細節或設定。  核心差異  權限範圍：計費管理員擁有對計費帳戶的全面控制權，而項目計費管理員的控制權限限於將專案連結到計費帳戶。  職責重點：計費管理員關注的是計費帳戶和付款管理，而項目計費管理員則專注於管理專案的計費和成本追蹤。    總的來說，這兩個角色共同協作，確保GCP資源的使用費用得到正確管理和計費。計費管理員負責帳戶層面的管理，而項目計費管理員則確保專案層面的計費設定正確無誤。     You have one project called proj-sa where you manage all your service accounts. You want to be able to use a service account from this project to take snapshots of VMs running in another project called proj-vm. What should you do?   A. Download the private key from the service account, and add it to each VMs custom metadata.\nB. Download the private key from the service account, and add the private key to each VM's SSH keys.\nC. Grant the service account the IAM Role of Compute Storage Admin in the project called proj-vm.\nD. When creating the VMs, set the service account's API scope for Compute Engine to read/write\n \n   \n    解題  這是一個關於如何在GCP中使用一個專案中的服務帳戶來對另一個專案中運行的虛擬機（VMs）進行快照操作的問題。  A. 從服務帳戶下載私鑰，並將其添加到每台VM的自定義元數據中。  這種做法會引入安全風險，因為將私鑰直接存儲在VM的元數據中並不是一種安全的做法。  B. 從服務帳戶下載私鑰，並將私鑰添加到每台VM的SSH鑰匙中。  同樣，這也不是推薦的做法，因為它涉及到將敏感的私鑰分發到多台VM上，這可能會導致安全問題。  C. 在名為proj-vm的專案中，授予服務帳戶Compute Storage Admin的IAM角色。  這是一種安全的做法，因為它通過IAM（身份及存取管理）授權機制賦予服務帳戶必要的權限，使其能夠在不同專案中進行操作，而無需直接處理任何敏感的私鑰信息。  D. 創建VM時，設置服務帳戶的Compute Engine API範圍為讀/寫  雖然這個選項看起來似乎提供了所需的權限，但它實際上是在設置服務帳戶對Compute Engine API的訪問範圍，並不直接賦予服務帳戶在另一個專案中操作的權限。  正確答案是 C。這個選項通過給予服務帳戶適當的IAM角色（Compute Storage Admin）  設置圖片        You created a Google Cloud Platform project with an App Engine application inside the project.\nYou initially configured the application to be served from the us- central region.\nNow you want the application to be served from the asia-northeast1 region. What should you do?   A. Change the default region property setting in the existing GCP project to asia-northeast1.\n\nB. Change the region property setting in the existing App Engine application from us-central to asia-northeast1.\n\nC. Create a second App Engine application in the existing GCP project and specify asia-northeast1 as the \nregion to serve your application.\n\nD. Create a new GCP project and create an App Engine application inside this new project. Specify asia-northeast1 as the region to serve your application\n \n   \n    解題  A. 在現有的GCP項目中更改預設區域屬性設定為asia-northeast1。  這個選項可能會讓人誤解，因為GCP項目本身並不允許直接更改預設區域。特別是對於App Engine應用程序，一旦設定了部署區域，在App Engine的標準環境中是無法更改的。  B. 將現有App Engine應用程序的區域屬性設定從us-central更改為asia-northeast1。  這個選項同樣不可行，因為App Engine應用程序一旦部署在某個區域，就無法將它遷移到另一個區域。  C. 在現有的GCP項目中創建第二個App Engine應用程序，並指定asia-northeast1作為服務您的應用程序的區域。  這是一個可行的選項。GCP允許在同一個項目中創建多個App Engine應用程序，每個應用程序可以在不同的區域運行。不過，值得注意的是，每個GCP項目在每個區域只能有一個App Engine應用實例，這意味著如果你要在另一個區域部署相同的應用，你需要創建一個新的應用實例。  D. 創建一個新的GCP項目並在這個新項目中創建一個App Engine應用程序。指定asia-northeast1作為服務您的應用程序的區域。  這也是一個有效的選項，且是最乾淨的解決方案。創建一個新的GCP項目，並在該項目中設定App Engine應用程序的區域為asia-northeast1，可以確保應用程序在所需的區域內運行，而不影響原有的項目設置或應用程序。  考慮到GCP和App Engine的工作原理，D 是最佳選項。這是因為App Engine的應用區域一旦設定，在標準環境中就不能更改。     You need to grant access for three users so that they can view and edit table data on a Cloud Spanner instance. What should you do?   A. Run gcloud iam roles describe roles/spanner.databaseUser. Add the users to the role. \nB. Run gcloud iam roles describe roles/spanner.databaseUser. Add the users to a new group. Add the group to the role. \nC. Run gcloud iam roles describe roles/spanner.viewer - -project my-project. Add the users to the role. \nD. Run gcloud iam roles describe roles/spanner.viewer - -project my-project. Add the users to a new group. Add the group to the role\n \n    \n    解題  這題就考IAM...以IAM權限角色選擇，要能編輯鐵定不能寫viwer，接下來就是考慮一次要授予三個人這個權限，用Group的做法會比較妥當。可以集中管理就做集中管理，答案就是B     You create a new Google Kubernetes Engine (GKE) cluster and want to make sure that it always runs a supported and stable version of Kubernetes. What should you do?   A. Enable the Node Auto-Repair feature for your GKE cluster. \nB. Enable the Node Auto-Upgrades feature for your GKE cluster. \nC. Select the latest available cluster version for your GKE cluster. \nD. Select Container-Optimized OS (cos) as a node image for your GKE cluster.\n \n    \n    解題  這題很簡單，答案直覺就是B...(upgrades)  A的Auto-Repair為節點自動修復。  C這表示當你創建或升級 GKE 集群時，你選擇了最新的可用版本。但這不保證它將來仍然是受支援的版本。  D為一種特別為運行容器而優化的操作系統。選擇它可以提供一個簡化且安全的環境來運行你的應用程式，但它與確保 Kubernetes 版本受支援和穩定無直接關係。     You have an instance group that you want to load balance. You want the load balancer to terminate the client SSL session. The instance group is used to serve a public web application over HTTPS. You want to follow Google recommended practices. What should you do?   A. Configure an HTTP(S) load balancer. \nB. Configure an internal TCP load balancer. \nC. Configure an external SSL proxy load balancer. \nD. Configure an external TCP proxy load balancer\n \n   \n    解題  在Google Cloud Platform（GCP）上，當你想要設定一個負載平衡器來終止客戶端的SSL會話（也就是進行SSL解密），並且這個負載平衡器是用來服務一個公開的Web  A. 配置一個HTTP(S)負載平衡器。  這是正確的選擇，因為HTTP(S)負載平衡器能夠在負載平衡器層面終止SSL會話，並且支援公開的Web應用程式透過HTTPS服務。  B. 配置一個內部TCP負載平衡器。  這不是正確的選擇，因為內部TCP負載平衡器是用於內部網絡流量的負載平衡，不適用於公開的Web應用程式。  C. 配置一個外部SSL代理負載平衡器。  雖然SSL代理負載平衡器也支援SSL會話的終止，但它主要用於非HTTP/HTTPS流量的SSL終止。對於要服務HTTPS的Web應用程式，HTTP(S)負載平衡器是更加適合的選擇。  D. 配置一個外部TCP代理負載平衡器。  這也不是正確的選擇，因為TCP代理負載平衡器主要用於TCP流量的負載平衡，而不是終止SSL會話。  基於以上分析，A. 配置一個HTTP(S)負載平衡器 是最符合Google推薦做法的選擇，用於終止客戶端的SSL會話並服務一個公開的Web應用程式透過HTTPS。   設定一個負載平衡器來終止客戶端的SSL會話，這個過程被稱為SSL終止（SSL Termination）。這裡的「終止」指的是加密連接在達到負載平衡器時被解密，之後負載平衡器再將解密後的流量轉發到後端伺服器。這意味著SSL加密和解密的工作是在負載平衡器上完成的，而不是在每個後端伺服器上進行。   停止SSL加密過程 ：雖然**  HTTP(S)負載平衡器  和  外部SSL代理負載平衡器 **都能做到這一點，但考慮到您的應用程式是基於Web的，您可能還會需要根據HTTP/HTTPS的具體內容進行路由決策，例如根據URL路徑。  因此，選擇**  HTTP(S)負載平衡器 **會是更合適的選擇，因為它不僅可以終止SSL會話，還可以提供基於HTTP/HTTPS內容的高度靈活的路由能力。     SSL終止的過程   客戶端到負載平衡器的連接：   客戶端（例如瀏覽器）通過HTTPS向負載平衡器發起一個連接請求。  負載平衡器接收到請求後，使用其SSL證書來與客戶端進行加密連接的建立，這個過程包括加密的鑰匙交換。  解密和轉發流量：   一旦加密連接建立，負載平衡器就會解密客戶端發來的加密流量。  解密後，負載平衡器讀取請求內容，並根據設定的負載平衡策略決定將請求轉發到哪個後端伺服器。  後端伺服器處理請求：   後端伺服器收到來自負載平衡器的請求（此時請求已經是解密的），處理請求，並返回響應給負載平衡器。  負載平衡器可以選擇對響應再次進行加密，然後發送回客戶端，或者直接以明文形式發送，取決於配置和需求。  為什麼要使用SSL終止？   性能優化：將加解密的工作集中在負載平衡器上，可以減輕後端伺服器的負擔，提高整體系統的處理能力。  簡化證書管理：只需在負載平衡器上管理SSL證書，無需在每台後端伺服器上分別配置和更新，這樣可以大大簡化證書的管理工作。  安全性：雖然SSL終止意味著在負載平衡器和後端伺服器之間的流量可能是未加密的，但在一個受控和安全的網絡環境中，這種設置仍然能夠提供足夠的安全保障。如果需要，也可以在負載平衡器和後端伺服器之間再次進行加密，這被稱為SSL重新加密（SSL Re-encryption）。     You have 32 GB of data in a single file that you need to upload to a Nearline Storage bucket.The WAN connection you are using is rated at 1 Gbps, and you are the only one on the connection. You want to use as much of the rated 1 Gbps as possible to transfer the file rapidly. How should you upload the file?   A. Use the GCP Console to transfer the file instead of gsutil.\nB. Enable parallel composite uploads using gsutil on the file transfer.\nC. Decrease the TCP window size on the machine initiating the transfer. \nD. Change the storage class of the bucket from Nearline to Multi-Regional.\n \n    \n    解題  答案是B，要最大限度地利用1 Gbps的速度快速上傳大型檔案，最佳的方法是使用平行複合上傳。這是因為gsutil的平行複合上傳會將大檔案分割成多個較小的部分，這些部分可以並行上傳，從而加快整體上傳速度。   選項A：使用GCP控制台可能不如使用gsutil效率，特別是對於大型檔案。\n  選項B：平行複合上傳允許檔案在上傳到Google Cloud Storage時被分割並且並行上傳，從而加快上傳速度。  選項C：降低TCP窗口大小可能會減慢傳輸速度，而不是加快它。  選項D：更改存儲類別並不影響上傳速度。此外，選擇Multi-Regional可能會增加存儲成本。     You've deployed a microservice called myapp1 to a Google Kubernetes Engine cluster using the YAML file specified below:  You need to refactor this configuration so that the database password is not stored in plain text. You want to follow Google- recommended practices. What should you do?   A. Store the database password inside the Docker image of the container, not in the YAML file.\nB. Store the database password inside a Secret object. Modify the YAML file to populate the DB_PASSWORD environment variable from the Secret.\nC. Store the database password inside a ConfigMap object. Modify the YAML file to populate the DB_PASSWORD environment variable from the ConfigMap.\nD. Store the database password in a file inside a Kubernetes persistent volume, and use a persistent volume claim to mount the volume to the container.\n \n   \n    解題  當您在Kubernetes中管理敏感數據，如數據庫密碼，推薦的做法是使用Kubernetes Secrets。  A. 將數據庫密碼存儲在Docker映像內是不推薦的。這樣做很不安全，且不符合最佳做法。任何可以訪問此映像的人都可以檢索密碼。  B. 這是正確的選擇。您可以在Kubernetes中使用Secrets存儲敏感信息，然後在YAML配置中參考這些Secrets，以將數據傳遞給容器環境變量。 (不是很建議的Solution…但考試ㄇ…)  C. ConfigMap主要用於存儲非機密配置，而不是存儲敏感數據，如密碼。  D. 雖然這個選擇理論上可行，但使用Secret物件是更簡單且更加安全的方法來管理敏感數據。     You are running an application on multiple virtual machines within a managed instance group\nand have autoscaling enabled. The autoscaling policy is configured so that additional instances are added to the group if the CPU utilization of instances goes above 80%. VMs are added until the instance group reaches its maximum limit of five VMs or until CPU utilization of instances lowers to 80%. The initial delay for HTTP health checks against the instances is set to 30 seconds. The virtual machine instances take around three minutes to become available for users. You observe that when the instance group autoscales, it adds more instances then necessary to support the levels of end-user traffic. You want to properly maintain instance group sizes when autoscaling. What should you do?   A. Set the maximum number of instances to 1.\nB. Decrease the maximum number of instances to 3.\nC. Use a TCP health check instead of an HTTP health check.\nD. Increase the initial delay of the HTTP health check to 200 seconds.\n \n   \n    解題  您正在一個受管理的實例組中的多個虛擬機上運行應用程序，並已啟用自動縮放功能。自動縮放策略配置為，如果實例的CPU利用率超過80%，則將額外的實例添加到組中。添加VM，直到實例組達到其最大限制的五個VM，或直到實例的CPU利用率降低到80%。針對實例進行HTTP健康檢查的初始延遲設置為30秒。虛擬機實例需要大約三分鐘才能供用戶使用。您觀察到，當實例組自動縮放時，它會添加比支持最終用戶流量所需的更多實例。您希望在自動縮放時正確維護實例組的大小。您應該怎麼做？  問題指出，當實例組自動縮放時，它會添加不必要的多餘實例。這可能是因為健康檢查的初始延遲過短，導致自動縮放策略在新實例完全啟動並處理流量之前就試圖添加更多的實例。  A. 這不是一個好選擇，因為只有一個實例將不能滿足需要擴展的需求。\nB. 減少到3的實例最大數量可能不足以處理高流量。\nC. 使用TCP健康檢查與HTTP健康檢查之間的選擇不太可能解決這個問題。\nD. 增加HTTP健康檢查的初始延遲將允許新實例有更多的時間啟動並開始處理流量，這可能會解決過度擴展的問題。  答案是D     You need to select and configure compute resources for a set of batch processing jobs. These jobs take around 2 hours to complete and are run nightly. You want to minimize service costs. What should you do?   A. Select Google Kubernetes Engine. Use a single-node cluster with a small instance type.\nB. Select Google Kubernetes Engine. Use a three-node cluster with micro instance types.\nC. Select Compute Engine. Use preemptible VM instances of the appropriate standard machine type. \nD. Select Compute Engine. Use VM instance types that support micro bursting.\n \n   \n    解題  對於批量處理工作，特別是當您希望最小化成本時，選擇預先中止(Preemptible) VM實例是一個好選擇。這些實例比常規實例便宜很多，但可能會在任何時候被GCP回收，這在批量處理工作中是可以接受的，因為它們可以容易地重新啟動。  A. 這不是最經濟的選擇，因為Kubernetes Engine可能對批處理作業過於冗余。\nB. 同上，對於批處理，Kubernetes Engine可能不是最經濟的選擇。\nC. 預先中止的VM實例非常適合短期和可中斷的批量處理工作，而且它們比常規VM實例便宜很多。\nD. Micro bursting是當小型VM實例在短時間內超出其基礎性能時使用的，這可能不是最佳選擇。     You recently deployed a new version of an application to App Engine and then discovered a bug in the release. You need to immediately revert to the prior version of the application. What should you do?   A. Run gcloud app restore.\n\nB. On the App Engine page of the GCP Console, select the application that needs to be reverted and click Revert.\n\nC. On the App Engine Versions page of the GCP Console, route 100% of the traffic to the previous version.\n\nD. Deploy the original version as a separate application. Then go to App Engine settings and split traffic between applications so that the original version serves 100% of the requests.\n \n    \n    解題  當您需要迅速還原到先前的版本時，最快捷且不會造成中斷的方法是調整流量分配。  A. **  gcloud app restore **不是有效的命令。\nB. GCP控制台的App Engine頁面上沒有直接的\"Revert\"選項。\nC. 通過App Engine的版本控制，您可以輕鬆地將所有流量路由到先前的版本。\nD. 這個選項過於複雜，且不是建議的方法。     You deployed an App Engine application using gcloud app deploy, but it did not deploy to the intended project. You want to find out why this happened and where the application deployed. What should you do?   A. Check the app.yaml file for your application and check project settings.\nB. Check the web-application.xml file for your application and check project settings.\nC. Go to Deployment Manager and review settings for deployment of applications.\nD. Go to Cloud Shell and run gcloud config list to review the Google Cloud configuration used for deployment.\n \n   \n    解題  你使用 gcloud app deploy 部屬應用程式，但應用程式並未部屬到目標專案，你想要找出爲何會發生這樣的事  A. 檢查應用程式內的 app.yaml ，確認專案設定，app.yaml: 是 App 執行時的參數相關設定，不是 Deploy 的設定  B. 檢查應用程式內的 web-application.xml ，確認專案設定，web-application.xml: GCP 沒有服務會吃到這個設定，也不知道這個設定是給誰的  C. 前往 Deployment Manager 確認該應用程式的設定，題目情境是使用 gcloud app deploy  D. 前往 Cloud Shell 執行 gcloud config list 確認 deployment 的相關設定       You want to configure 10 Compute Engine instances for availability when maintenance occurs.Your requirements state that these instances should attempt to automatically restart if they crash. Also, the instances should be highly available including during system maintenance. What should you do?   A. Create an instance template for the instances. Set the 'Automatic Restart' to on. Set the 'On-host maintenance' to Migrate VM instance. Add the instance template to an instance group.\n\nB. Create an instance template for the instances. Set 'Automatic Restart' to off. Set 'On-host maintenance' to Terminate VM instances. Add the instance template to an instance group.\n\nC. Create an instance group for the instances. Set the 'Autohealing' health check to healthy (HTTP).\n\nD. Create an instance group for the instance. Verify that the 'Advanced creation options' setting for 'do \nnot retry machine creation' is set to off.\n \n    \n    解題  為了確保Compute Engine實例在維護期間的可用性，並且在出現故障時自動重新啟動  A選項是符合需求的正確做法。透過創建一個實例模板，並設定「自動重新啟動」為開啟狀態，以及在主機維護期間選擇「遷移VM實例」，能確保實例在遇到系統維護或故障時仍保持高可用性。再將此模板加入實例群組中，可以進一步提高整體應用的可靠性和可用性。  B選項提出的設定「自動重新啟動」關閉，以及在主機維護時選擇「終止VM實例」，這明顯與需求相反，因為它不會在實例崩潰時自動重啟，也不會在系統維護期間保持實例的可用性。  C選項提到為實例群組設置「自動修復」健康檢查，雖然這有助於確保實例的健康狀態，但它並未直接解決在系統維護期間或實例崩潰時保持高可用性的需求。  D選項談到確認「高級創建選項」中的「不重試機器創建」設置是否關閉，這更多關注於創建實例的過程，而不是實例崩潰或系統維護期間的自動重啟和高可用性策略。  綜上所述，A選項提供了一個全面的解決方案，能夠滿足自動重新啟動以及在系統維護期間保持實例高可用性的需求。     You host a static website on Cloud Storage. Recently, you began to include links to PDF files on this site. Currently, when users click on the links to these PDF files, their browsers prompt them to save the file onto their local system. Instead, you want the clicked PDF files to be displayed within the browser window directly, without prompting the user to save the file locally. What should you do?   A. Enable Cloud CDN on the website frontend.\nB. Enable 'Share publicly' on the PDF file objects.\nC. Set Content-Type metadata to application/pdf on the PDF file objects.\nD. Add a label to the storage bucket with a key of Content-Type and value of application/pdf.\n \n   \n    解題  當您希望在點擊PDF文件鏈接時，讓用戶在瀏覽器窗口中直接查看PDF內容，而不是提示用戶將文件保存到本地系統，您需要設定正確的MIME類型。MIME類型告訴瀏覽器文件的類型，從而瀏覽器可以決定如何處理該文件。  C選項提到將PDF文件對象的Content-Type元數據設置為application/pdf。這是達到您目標的正確方法。通過這樣設置，當用戶點擊PDF文件鏈接時，瀏覽器識別到文件類型為PDF，並嘗試在瀏覽器內直接顯示文件，而不是提示用戶進行下載。  A選項，啟用Cloud CDN對於改變文件如何被瀏覽器處理（即顯示或下載）沒有直接影響。CDN主要用於內容的快速分發。  B選項，啟用PDF文件對象的'公開分享'並不直接影響文件在瀏覽器中的打開方式。它只確保沒有存取控制限制阻止用戶訪問這些文件。  D選項，在存儲桶上添加帶有Content-Type鍵和application/pdf值的標籤並不會改變對象的實際Content-Type元數據。對於如何處理特定文件，瀏覽器查看的是文件對象的Content-Type元數據，而不是存儲桶的標籤。  C選項是正確的選擇，因為它通過設置正確的Content-Type元數據來直接在瀏覽器中打開PDF文件，而無需下載。     You have a virtual machine that is currently configured with 2 vCPUs and 4 GB of memory. It is running out of memory. You want to upgrade the virtual machine to have 8 GB of memory. What should you do?   A. Rely on live migration to move the workload to a machine with more memory.\nB. Use gcloud to add metadata to the VM. Set the key to required-memory-size and the value to 8 GB.\nC. Stop the VM, change the machine type to n1-standard-8, and start the VM.\nD. Stop the VM, increase the memory to 8 GB, and start the VM.\n \n   \n    解題  選D，VM 的 CPU / RAM 是無法 live 變更的，硬碟空間可以live變更，但需注意硬碟只能擴不能縮     You have production and test workloads that you want to deploy on Compute Engine. Production\nVMs need to be in a different subnet than the test VMs. All the VMs must be able to reach each other\nover Internal IP without creating additional routes. You need to set up VPC and the 2 subnets. Which configuration meets these requirements?   A. Create a single custom VPC with 2 subnets. Create each subnet in a different region and with a different CIDR range.\n\nB. Create a single custom VPC with 2 subnets. Create each subnet in the same region and with the same CIDR range.\n\nC. Create 2 custom VPCs, each with a single subnet. Create each subnet in a different region and with a different CIDR range.\n\nD. Create 2 custom VPCs, each with a single subnet. Create each subnet in the same region and with the same CIDR range.\n \n   \n    解題  要滿足生產環境和測試環境的虛擬機（VM）部署在不同子網中，同時又能夠通過內部IP互相連接而不需要創建額外路由的需求，最佳做法是將所有VM部署在同一個自定義虛擬私人網路（VPC）中，但在不同的子網下。這樣設置可以確保即使在不同子網中的VM也能在同一VPC內部通信，無需額外路由設置。  A選項提出了在一個自定義VPC中創建兩個子網，每個子網在不同的地區且擁有不同的CIDR範圍。這符合需求，因為即使子網在不同地區，它們仍然屬於同一VPC內，從而能夠實現內部互連。  B選項提議在同一個自定義VPC中創建兩個子網，且兩個子網在相同的地區且擁有相同的CIDR範圍。這個選項是不可行的，因為兩個子網不能擁有相同的CIDR範圍，這會導致IP地址衝突。  C選項和D選項都提議創建兩個自定義VPC，每個VPC包含一個子網。這兩個選項都不能滿足需求，因為在不同VPC之間的VM默認是不能直接通信的，除非設置VPC對等連接，這違背了不創建額外路由的要求。  A選項是符合要求的最佳配置，它能夠確保生產環境和測試環境的VM在不同子網中，同時保持了它們之間的內部通信能力，且無需額外路由設置。     You need to create an autoscaling managed instance group for an HTTPS web application. You want to make sure that unhealthy VMs are recreated. What should you do?   A. Create a health check on port 443 and use that when creating the Managed Instance Group.\nB. Select Multi-Zone instead of Single-Zone when creating the Managed Instance Group.\nC. In the Instance Template, add the label 'health-check'.\nD. In the Instance Template, add a startup script that sends a heartbeat to the metadata server.\n \n   \n    解題  要創建一個自動擴展的管理實例組（Managed Instance Group, MIG）來支持HTTPS網絡應用，並且確保不健康的虛擬機（VM）被重新創建，最直接且有效的方法是使用健康檢查（Health Check）。  A選項提議創建一個在端口443上的健康檢查，並在創建管理實例組時使用該健康檢查。這是一個符合需求的選擇，因為HTTPS應用通常運行在端口443上。通過對每個實例進行健康檢查，不健康的實例可以被識別並自動替換，從而確保應用的可用性和穩定性。  B選項建議在創建管理實例組時選擇多區域（Multi-Zone）而非單區域（Single-Zone）。雖然這樣可以提高應用的高可用性，但它不直接解決不健康VM的重建問題。  C選項和D選項都提到了在實例模板中添加標籤或啟動腳本。這些方法可能有助於實現自定義的健康檢查或監控，但它們不如直接使用GCP提供的健康檢查機制來得直接和標準化。  因此，A選項是最佳的做法，因為它直接使用GCP的健康檢查功能來確保HTTPS應用的虛擬機在出現不健康狀態時能夠被自動檢測並重建。     Your company has a Google Cloud Platform project that uses BigQuery for data warehousing. Your data science team changes frequently and has few members.You need to allow members of this team to perform queries.You want to follow Google-recommended practices. What should you do?   A. \n   1. Create an IAM entry for each data scientist's user account. \n   2. Assign the BigQuery jobUser role to the group.\nB. \n   1. Create an IAM entry for each data scientist's user account.\n   2. Assign the BigQuery dataViewer user role to the group.\nC. \n   1. Create a dedicated Google group in Cloud Identity. \n   2. Add each data scientist's user account to the group. \n   3. Assign the BigQuery jobUser role to the group.\nD. \n   1. Create a dedicated Google group in Cloud Identity. \n   2. Add each data scientist's user account to the group. \n   3. Assign the BigQuery dataViewer user role to the group\n \n    \n    解題  答案C, DataViewer does not allow user to perform queries.  C的步驟是：   在Cloud Identity中創建一個專門的Google群組。  將每個資料科學家的用戶帳戶添加到這個群組中。  給這個群組分配BigQuery jobUser角色。  BigQuery jobUser角色允許群組成員執行BigQuery作業，包括運行查詢     Your company has a 3-tier solution running on Compute Engine. The configuration of the current infrastructure is shown below.Each tier has a service account that is associated with all instances within it. You need to enable communication on TCP port 8080 between tiers as follows:   Instances in tier #1 must communicate with tier #2.  Instances in tier #2 must communicate with tier #3.  What should you do?     A. \n    1. Create an ingress firewall rule with the following settings: \n         Targets: all instances\n         Source filter: IP ranges (with the range set to 10.0.2.0/24)\n         Protocols: allow all \n    2. Create an ingress firewall rule with the following settings:\n         Targets: all instances\n         Source filter: IP ranges (with the range set to 10.0.1.0/24) \n         Protocols: allow all\nB. \n    1. Create an ingress firewall rule with the following settings:\n         Targets: all instances with tier #2 service account\n         Source filter: all instances with tier #1 service account\n         Protocols: allow TCP:8080 \n    2. Create an ingress firewall rule with the following settings:\n         Targets: all instances with tier #3 service account\n         Source filter: all instances with tier #2 service account\n         Protocols: allow TCP: 8080\nC. \n    1. Create an ingress firewall rule with the following settings:\n         Targets: all instances with tier #2 service account\n         Source filter: all instances with tier #1 service account\n         Protocols: allow all \n    2. Create an ingress firewall rule with the following settings:\n         Targets: all instances with tier #3 service account\n         Source filter: all instances with tier #2 service account\n         Protocols: allow all\nD. \n    1. Create an egress firewall rule with the following settings:\n         Targets: all instances\n         Source filter: IP ranges (with the range set to 10.0.2.0/24)\n         Protocols: allow TCP: 8080 \n    2. Create an egress firewall rule with the following settings:\n         Targets: all instances\n         Source filter: IP ranges (with the range set to 10.0.1.0/24)\n         Protocols: allow TCP: 8080\n \n   \n    解題  答案是B,   先排除不是 8080 port的選項  egress 是對外，ingress才是授權連線  選項A\n這個選項提議創建兩條入站(ingress)防火牆規則，基於IP範圍來允許所有協議的通信。然而，這並不精確地針對要求的TCP端口8080，且使用IP範圍而非服務帳戶作為過濾條件，可能不是最佳選擇，因為它沒有細化到特定的服務帳戶或所需的端口。  選項B\n這個選項建議基於服務帳戶創建兩條入站(ingress)防火牆規則，專門允許TCP端口8080的通信。第一條規則允許第一層的實例與第二層的實例通信，第二條規則允許第二層的實例與第三層的實例通信。這完全符合題目的要求，是一個精確且高效的解決方案。  選項C\n與選項B類似，這個選項也是基於服務帳戶創建防火牆規則，但它允許所有協議的通信，而不是僅限於TCP端口8080。這樣的設置比題目要求的更為寬泛，可能會引入不必要的安全風險。  選項D\n這個選項建議創建出站(egress)防火牆規則，這與題目要求的入站(ingress)通信不符。雖然它專注於TCP端口8080，但是從方向上說，它不適用於這個特定的需求。     You are given a project with a single Virtual Private Cloud (VPC) and a single subnetwork in the us-central1 region. There is a Compute Engine instance hosting an application in this subnetwork.\nYou need to deploy a new instance in the same project in the europe-west1 region. This new instance needs access to the application. You want to follow Google-recommended practices. What should you do?   A. \n    1. Create a subnetwork in the same VPC, in europe-west1. \n    2. Create the new instance in the new subnetwork and use the first instance's private address as the endpoint.\nB. \n    1. Create a VPC and a subnetwork in europe-west1. \n    2. Expose the application with an internal load balancer. \n    3. Create the new instance in the new subnetwork and use the load balancer's address as the endpoint.\nC. \n    1. Create a subnetwork in the same VPC, in europe-west1. \n    2. Use Cloud VPN to connect the two subnetworks. \n    3. Create the new instance in the new subnetwork and use the first instance's private address as the endpoint.\nD. \n    1. Create a VPC and a subnetwork in europe-west1. \n    2. Peer the 2 VPCs. \n    3. Create the new instance in the new subnetwork and use the first instance's private address as the endpoint.\n \n   \n    解題  你有一個項目，其中包含一個單一的虛擬私有雲(VPC)和一個位於美國中部(us-central1)地區的子網絡。在這個子網絡中，有一個Compute Engine實例托管著一個應用程式。你需要在同一項目中的歐洲西部(europe-west1)地區部署一個新實例，且這個新實例需要訪問原有應用程式。題目要求按照Google推薦的實踐操作。  選項A 建議在相同VPC中，為europe-west1地區創建一個新的子網絡，並在此子網絡中創建新實例，使用第一個實例的私有地址作為端點。這是一個符合Google推薦做法的直接且簡潔的方法，因為它利用了同一VPC內跨地區的自動私有連接功能。  選項B 提議創建一個新的VPC和子網絡，並使用內部負載平衡器暴露應用程式。這個選項雖然可行，但它引入了不必要的復雜性，包括額外的VPC和負載平衡器配置，這並不是Google推薦的最佳實踐。且沒必要。  選項C 建議使用Cloud VPN連接兩個子網絡。雖然這可以實現跨地區連接，但對於位於同一VPC內的實例來說，這是一種過於複雜和不必要的方法。VPN在這題用不到.....  選項D 建議創建一個新的VPC和子網絡，並進行VPC對等連接。這同樣比題目要求的更為複雜，因為它需要額外的VPC和對等連接設置。且沒必要。  正確答案是A。這是最簡單直接的方法，符合Google的推薦實踐，允許在同一VPC內跨地區自動進行私有連接，無需額外的連接或負載平衡設置。  Subnets：每個 VPC network 都包含一到多組 IP 區間，稱為子網域(subnets).       Your projects incurred more costs than you expected last month.Your research reveals that a development GKE container emitted a huge number of logs, which resulted in higher costs. You want to disable the logs quickly using the minimum number of steps. What should you do?   A. Go to the Logs ingestion window in Stackdriver Logging, and disable the log source for the GKE container resource.\n\nB. Go to the Logs ingestion window in Stackdriver Logging, and disable the log source for the GKE Cluster Operation resource.\n\nC. \n  1. Go to the GKE console, and delete existing clusters.\n  2. Recreate a new cluster.\n  3. Clear the option to enable legacy Stackdriver Logging.\n\nD. \n    1. Go to the GKE console, and delete existing clusters.\n    2. Recreate a new cluster. \n    3. Clear the option to enable legacy Stackdriver Monitoring.\n \n   \n    解題  你發現上個月項目的成本超出預期，原因是開發用的GKE容器產生了大量日誌，導致成本增加。你希望通過最少的步驟快速禁用這些日誌。  選項A 提議在Stackdriver Logging的日誌攝取窗口中，禁用GKE容器資源的日誌源。這是一個直接且有效的方法，可以立即停止日誌的攝取，從而降低成本。  選項B 建議禁用GKE Cluster Operation資源的日誌源。這可能不會完全解決問題，因為它專注於操作日誌而非容器產生的日誌。  選項C 和 選項D 都提議刪除現有的集群並重新創建，這是一種非常極端且耗時的方法，並不推薦作為首選方案，特別是當可以通過更簡單的配置變更來解決問題時。  正確答案是A。這是最快且最直接的方法來停止特定容     You have a website hosted on App Engine standard environment. You want 1% of your users to see a new test version of the website. You want to minimize complexity. What should you do?   A. Deploy the new version in the same application and use the --migrate option.\n\nB. Deploy the new version in the same application and use the --splits option to give a weight of 99 to the current version and a weight of 1 to the new version.\n\nC. Create a new App Engine application in the same project. Deploy the new version in that application. Use the App Engine library to proxy 1% of the requests to the new version.\n\nD. Create a new App Engine application in the same project. Deploy the new version in that application. Configure your network load balancer to send 1% of the traffic to that new application.\n \n    \n    解題  B  您在App Engine標準環境上托管了一個網站。您希望1%的用戶看到網站的新測試版本。您希望盡量減少複雜性，應該怎麼做？  選項A：在同一應用中部署新版本並使用--migrate選項。這個選項用於遷移流量，但並不適用於只對一小部分用戶展示新版本的情境。  選項B：在同一應用中部署新版本並使用--splits選項，給當前版本分配99的權重，新版本分配1的權重。這是一種簡單且有效的方法，允許您按比例分配流量到不同版本，正好符合只讓1%的用戶看到新測試版本的需求。  選項C & D：在同一項目中創建一個新的App Engine應用並部署新版本，然後使用App Engine庫或網絡負載平衡器將1%的請求代理到新版本。這些選項增加了管理複雜性，因為它們要求創建全新的應用並進行額外配置。     You have a web application deployed as a managed instance group.\nYou have a new version of the application to gradually deploy.\nYour web application is currently receiving live web traffic.\nYou want to ensure that the available capacity does not decrease during the deployment.\nWhat should you do?   A. Perform a rolling-action start-update with maxSurge set to 0 and maxUnavailable set to 1. \n\nB. Perform a rolling-action start-update with maxSurge set to 1 and maxUnavailable set to 0.\n\nC. Create a new managed instance group with an updated instance template. Add the group to the backend service for the load balancer. When all instances in the new managed instance group are healthy, delete the old managed instance group. \n\nD. Create a new instance template with the new application version. \nUpdate the existing managed instance group with the new instance template. \nDelete the instances in the managed instance group to allow the managed instance group to recreate the instance using the new instance template.\n \n   \n    解題  您的網絡應用作為一個管理實例組部署，您有一個新版本的應用需要逐步部署。您的網絡應用當前正在接收實際網絡流量。您想確保在部署期間可用容量不會減少，應該怎麼做？  選項A：進行滾動更新（rolling-action start-update），設置maxSurge為0，maxUnavailable為1。這個選項意味著在更新過程中不會增加額外的實例（maxSurge=0），且同一時間最多有一個實例不可用（maxUnavailable=1）。這可能會在更新期間暫時減少可用容量，不符合題目要求。  選項B：進行滾動更新，設置maxSurge為1，maxUnavailable為0。這個選項在更新過程中允許臨時增加一個實例（maxSurge=1），確保在任何時刻都不會有實例不可用（maxUnavailable=0），從而保持可用容量不變。這完全符合題目要求，是一種既安全又有效的更新策略。   maxSurge: 升級過程中最多可以比原先設定所多出的pod 數量\nmaxUnavailable:最多可以有幾個 pod 處在無法服務的狀態  選項C：創建一個新的受管理實例組，並使用更新後的實例模板。將新組添加到負載平衡器的後端服務中，所有新管理組中的實例健康後，刪除舊的管理實例組。這個選項雖然可以保證在部署新版本時不減少可用容量，但比選項B更為繁瑣和昂貴。  選項D：創建一個新的實例模板並包含新版本的應用程序。使用新的實例模板更新現有的受管理實例組，然後刪除實例組中的實例，讓受管理實例組使用新的實例模板重新創建實例。這個選項並沒有明確保證在更新過程中保持可用容量不變，且刪除再創建的過程可能會暫時減少可用容量。     You are building an application that stores relational data from users.\nUsers across the globe will use this application.\nYour CTO is concerned about the scaling requirements because the size of the user base is unknown.\nYou need to implement a database solution that can scale with your user growth with minimum configuration changes.\nWhich storage solution should you use?   A. Cloud SQL\nB. Cloud Spanner \nC. Cloud Firestore \nD. Cloud Datastore\n  \n    解題  根據情境，需要一個可以隨著用戶增長而輕鬆擴展的數據庫解決方案，且涉及到關係性數據的存儲  A. Cloud SQL：是一種完全管理的關係數據庫服務，支援MySQL、PostgreSQL等。雖然它對於許多應用來說是個好選擇，但當涉及到需要自動橫向擴展以支持全球用戶和未知規模增長的應用時，Cloud SQL可能需要更多的配置和手動擴展操作。  B. Cloud Spanner：是Google Cloud提供的一種全球分佈式數據庫服務，既提供了關係數據庫的ACID事務特性，又具備NoSQL數據庫的橫向擴展能力。它能夠在全球範圍內無縫擴展，非常適合對於大小未知且可能迅速增長的用戶基礎。  C. Cloud Firestore：是一種高度擴展的NoSQL數據庫，適用於存儲靈活的、非結構化的數據。雖然它非常適合需要實時同步數據的應用，但對於需要關係數據存儲的場景可能不是最佳選擇。  D. Cloud Datastore：現在被Cloud Firestore的數據庫模式所取代，主要是針對應用程式提供自動擴展的NoSQL數據存儲解決方案。雖然適合存儲非關係性數據，但並不是專門設計來處理關係數據的最佳選項。  選項B：Cloud Spanner 是最適合你的需求的解決方案。它不僅提供了必要的關係數據庫功能，還能夠隨著用戶增長自動橫向擴展，並且需要的配置變更最小。但不便宜XD     You are the organization and billing administrator for your company.\nThe engineering team has the Project Creator role on the organization.\nYou do not want the engineering team to be able to link projects to the billing account.\nOnly the finance team should be able to link a project to a billing account, but they should not be able to make any other changes to projects.\nWhat should you do?   A. Assign the finance team only the Billing Account User role on the billing account.\nB. Assign the engineering team only the Billing Account User role on the billing account.\nC. Assign the finance team the Billing Account User role on the billing account and the Project Billing Manager role on the organization.\nD. Assign the engineering team the Billing Account User role on the billing account and the Project Billing Manager role on the organization.\n \n   \n    解題  答案為C，   Billing Account User 角色允許用戶管理計費賬戶的設置，包括將計費賬戶關聯到項目上。但是，這個角色本身不允許用戶對項目進行其他更改。  Project Billing Manager 角色可以讓用戶更改項目的計費賬戶關聯。將此角色授予財務團隊並在組織層級進行此操作，確保他們可以對任何項目進行計費賬戶的關聯操作，但沒有足夠的權限進行其他項目設置的更改。  選項A不符合需求，因為它只涵蓋了對計費賬戶的操作，沒有提及對項目計費的管理權限。  選項B和D都不適合，因為它們提供了工程團隊關聯計費賬戶的能力，這是你想要避免的。       You have an application running in Google Kubernetes Engine (GKE) with cluster autoscaling enabled.\nThe application exposes a TCP endpoint. There are several replicas of this application.\nYou have a Compute Engine instance in the same region but in another Virtual Private Cloud (VPC),\ncalled gce-network, that has no overlapping IP ranges with the first VPC.\nThis instance needs to connect to the application on GKE.\nYou want to minimize effort.\nWhat should you do?   A. \n    1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. \n    2. Set the service's externalTrafficPolicy to Cluster. \n    3. Configure the Compute Engine instance to use the address of the load balancer that has been created.\nB. \n    1. In GKE, create a Service of type NodePort that uses the application's Pods as backend. \n    2. Create a Compute Engine instance called proxy with 2 network interfaces, one in each VPC. \n    3. Use iptables on this instance to forward traffic from gcenetwork to the GKE nodes. \n    4. Configure the Compute Engine instance to use the address of proxy in gce-network as endpoint.\nC. \n    1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. \n    2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal \n    3. Peer the two VPCs together. \n    4. Configure the Compute Engine instance to use the address of the load balancer that has been created.\nD. \n    1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. \n    2. Add a Cloud Armor Security Policy to the load balancer that whitelists the internal IPs of the MIG's instances. \n    3. Configure the Compute Engine instance to use the address of the load balancer that has been created.\n \n   \n    解題  要讓一個位於另一個VPC中的Compute Engine實例連接到GKE上運行的應用，而且希望盡量減少工作量，最合適的選項是：C   在GKE中，創建一個LoadBalancer類型的服務，將應用程序的Pod用作後端。  在此服務上添加一個注釋：cloud.google.com/load-balancer-type: Internal。  將兩個VPC進行對等連接。  配置Compute Engine實例以使用已創建的負載均衡器的地址。  從安全性和最佳實踐的角度來看，選擇一個允許在私有網絡內通信的解決方案（如VPC對等連接），通常會比選擇一個將流量暴露於公共互聯網的方案更為推薦。這樣的配置不僅能夠降低資料被截獲的風險，還能夠在一定程度上減少延遲和提高連接的穩定性。  在這樣的背景下，選項C（使用VPC對等連接的內部LoadBalancer）可能會被視為更加適合的選擇，因為它符合最佳安全實踐並且直接回應了題目中的暗示。  其餘答案  A   在GKE中，創建一個LoadBalancer類型的服務，將應用程序的Pod用作後端。這將創建一個負載均衡器（Load Balancer）。  將服務的externalTrafficPolicy設置為Cluster。這個設置確保外部流量被導向到叢集中的Pod。  配置Compute Engine實例以使用已創建的負載均衡器的地址作為端點。  提供了一種通過創建一個外部負載平衡器來連接GKE應用和Compute Engine實例的方法。儘管這是最直接的方法，且在技術上可行，但它涉及到通過互聯網路由流量，這在安全性和延遲方面可能不是最佳選擇。考慮到題目提到的實例位於同一地區且無IP範圍重疊，這暗示了一種傾向於使用更私密連接的解決方案。  B.   在GKE中，創建一個NodePort類型的服務，將應用程序的Pod用作後端。  創建一個名為proxy的Compute Engine實例，該實例有2個網絡接口，一個在每個VPC中。  在此實例上使用iptables將流量從gce-network轉發到GKE節點。  配置Compute Engine實例以使用gce-network中proxy的地址作為端點。  涉及到創建一個類型為NodePort的Service，並使用一個配置了兩個網絡介面的代理Compute Engine實例來轉發流量。這種方法增加了設置的複雜性，需要手動配置網絡和iptables規則。儘管這為兩個不同VPC間的通信提供了一種可能的路徑，但它遠比選項A和C更為複雜，並且可能引入額外的延遲和管理負擔。  D.   在GKE中，創建一個LoadBalancer類型的服務，將應用程序的Pod用作後端。  在負載均衡器上添加一個Cloud Armor安全策略，該策略將MIG實例的內部IP列入白名單。  配置Compute Engine實例以使用已創建的負載均衡器的地址。  提出了創建一個外部負載平衡器並使用Cloud Armor安全策略來限制訪問的方案。雖然這可以提供額外的安全性控制，但就連接兩個VPC中資源的需求而言，它並不比選項A提供更多的私密性或效率。此外，這個方案也涉及到流量經過互聯網，與選項A類似，可能不是題目暗示的最佳選擇。     Your organization is a financial company that needs to store audit log files for 3 years. Your organizationhas hundreds of Google Cloud projects. You need to implement a cost-effective approach for log file retention. What should you do?   A. Create an export to the sink that saves logs from Cloud Audit to BigQuery.\nB. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.\nC. Write a custom script that uses logging API to copy the logs from Stackdriver logs to BigQuery.\nD. Export these logs to Cloud Pub/Sub and write a Cloud Dataflow pipeline to store logs to Cloud SQL.\n \n    \n    解題  您的組織是一家金融公司，需要存儲3年的審計日誌文件。您的組織擁有數百個Google Cloud項目。您需要實施一種成本效益的方法來保留日誌文件。您應該怎麼做？  對於需要長期存儲審計日誌文件的金融公司來說，選擇成本效益高的存儲解決方案至關重要。考慮到需求是存儲審計日誌文件長達3年，我們應該選擇一個既能保證數據安全又能在成本上有效管理的方案。  選項A：將日誌導出到BigQuery可能對於分析日誌非常有用，但長期存儲大量日誌數據可能成本較高，尤其是如果這些日誌不需要經常訪問。  選項B：將日誌導出到設定為Coldline存儲類別的Cloud Storage桶是一種成本效益高的選擇，特別適合於需要長期存儲但訪問頻率低的數據。Coldline存儲為低頻訪問的數據提供了較低的存儲成本。  選項C：編寫自定義腳本使用日誌API將日誌從Stackdriver日誌複製到BigQuery，這需要額外的開發工作，並且在長期存儲大量數據時可能不是最成本效益的選擇。  選項D：將這些日誌導出到Cloud Pub/Sub，然後編寫一個Cloud Dataflow管道將日誌存儲到Cloud SQL，這在技術上可行，但對於僅需長期存儲而言，這種方案過於複雜且成本可能相對較高。  基於成本效益的考慮，選項B是最合適的選擇。它直接使用Cloud Storage的Coldline存儲類別來存儲審計日誌，既能滿足長期存儲的要求，又能保持較低的成本。     You want to run a single caching HTTP reverse proxy on GCP for a latency-sensitive website. This specific reverse proxy consumes almost no CPU. You want to have a 30-GB in-memory cache, and need an additional 2 GB of memory for the rest of the processes. You want to minimize cost. How should you run this reverse proxy?   A. Create a Cloud Memorystore for Redis instance with 32-GB capacity.\nB. Run it on Compute Engine, and choose a custom instance type with 6 vCPUs and 32 GB of memory.\nC. Package it in a container image, and run it on Kubernetes Engine, using n1-standard-32 instances as nodes.\nD. Run it on Compute Engine, choose the instance type n1-standard-1, and add an SSD persistent disk of 32 GB.\n \n   \n    解題  您想在GCP上為一個對延遲敏感的網站運行一個單一的緩存HTTP反向代理。這個特定的反向代理幾乎不消耗CPU。您想要有一個30GB的內存緩存，並需要額外的2GB內存來運行其他進程。您希望最小化成本。您應該如何運行這個反向代理？  A是在 GCP 上運行緩存 HTTP 反向代理的最具成本效益的解決方案。Cloud Memorystore for Redis 是一項託管服務，可為您的應用程序提供內存緩存。它提供對 Redis 協議的高吞吐量和低延遲訪問。Cloud Memorystore 為 Redis 實例提供 99.9% 可用性的 SLA 和自動故障轉移。在這種情況下，32 GB Redis 實例足以容納 30 GB 緩存以及其餘進程所需的額外 2 GB 內存。該解決方案具有高度可擴展性，允許您隨著需求的增長而增加 Redis 實例的大小。  B 不是一個經濟高效的解決方案，因為它需要具有 6 個 vCPU 和 32 GB 內存的自定義實例類型，這對於緩存 HTTP 反向代理來說是過度配置的。  C 不是一個經濟高效的解決方案，因為它使用 Kubernetes Engine，管理開銷較高，並且對於單個緩存 HTTP 反向代理來說可能不是必需的。  D 不是一個可行的解決方案，因為實例類型 n1-standard-1 僅提供 3.75 GB 內存，不足以滿足 30 GB 緩存以及其餘進程所需的額外 2 GB 內存。添加 32 GB 的 SSD 永久磁盤將無法為反向代理提供足夠的內存。  反向代理幾乎不消耗CPU  Cloud Memorystore for Redis提供的是一個全管式的Redis服務，可以非常適合用作高性能的緩存解決方案。考慮到題目的需求是一個高效的緩存機制，而不是一個通用的計算實例，選擇選項A：創建一個32-GB容量的Cloud Memorystore for Redis實例，確實是一個更為合適的解答。這樣可以直接提供足夠的緩存空間，而且由於是全管式服務，可以減少管理複雜性和維護負擔。     You are hosting an application on bare-metal servers own data center. The application needs access to Cloud Storage. However, security policies prevent the servers hosting the application from having public IP addresses or access to the internet. You want to follow Google-recommended practices to provide the application with access to Cloud Storage. What should you do?   A. 1. Use nslookup to get the IP address for storage.googleapis.com. \n   2. Negotiate with the security team to be able to give a public IP address to the servers. \n   3. Only allow egress traffic from those servers to the IP addresses for storage.googleapis.com.\n\nB. 1. Using Cloud VPN, create a VPN tunnel to a Virtual Private Cloud (VPC) in Google Cloud. \n   2. In this VPC, create a Compute Engine instance and install the Squid proxy server on this instance. \n   3. Configure your servers to use that instance as a proxy to access Cloud Storage.\n\nC. 1. Use Migrate for Compute Engine (formerly known as Velostrata) to migrate those servers to Compute Engine. \n   2. Create an internal load balancer (ILB) that uses storage.googleapis.com as backend. \n   3. Configure your new instances to use this ILB as proxy.\n\nD. 1. Using Cloud VPN or Interconnect, create a tunnel to a VPC in Google Cloud. \n   2. Use Cloud Router to create a custom route advertisement for 199.36.153.4/30. Announce that network to your on-premises network through the VPN tunnel. \n   3. In your on-premises network, configure your DNS server to resolve *.googleapis.com as a CNAME to restricted.googleapis.com.\n  \n    解題  您正在自家數據中心的實體服務器上托管一個應用程序。該應用程序需要訪問雲存儲。然而，安全策略阻止托管應用程序的伺服器具有公共IP地址或訪問互聯網的權限。您想要遵循Google建議的最佳實踐，以為應用程序提供訪問雲存儲的權限。您應該怎麼做？  A. 1. 使用nslookup獲取storage.googleapis.com的IP地址。\n2. 與安全團隊協商，以便為伺服器提供公共IP地址。\n3. 僅允許從這些伺服器到storage.googleapis.com的IP地址的出口流量。  B. 1. 使用Cloud VPN，在Google Cloud中創建一個與虛擬專用雲（VPC）的VPN隧道。\n2. 在此VPC中，創建一個Compute Engine實例，並在此實例上安裝Squid代理伺服器。\n3. 配置您的伺服器以使用該實例作為代理來訪問雲存儲。  C. 1. 使用Migrate for Compute Engine（以前稱為Velostrata）將這些伺服器遷移到Compute Engine。\n2. 創建一個使用storage.googleapis.com作為後端的內部負載平衡器（ILB）。\n3. 配置您的新實例以使用此ILB作為代理。  D. 1. 使用Cloud VPN或Interconnect，在Google Cloud中創建一個與VPC的隧道。\n2. 使用Cloud Router創建一個自定義路由廣告，針對199.36.153.4/30。通過VPN隧道向您的本地網路宣佈該網路。\n3. 在您的本地網路中，配置您的DNS伺服器，將*.googleapis.com解析為restricted.googleapis.com的CNAME。  託管應用程序的服務器無法直接訪問公共IP。因此，要訪問 Google Cloud，必須通過 VPN。  D 是推薦的解決方案，因為它提供了與 Cloud Storage 的安全直接連接，無需訪問 Internet 或將服務器暴露給公共 IP 地址。  通過設置 VPN 或互連隧道，本地服務器可以通過私有加密連接訪問 Google Cloud 資源。  199.36.153.4/30 的自定義路由通告可確保流量在本地網絡和 Google Cloud 之間正確路由。     You want to deploy an application on Cloud Run that processes messages from a Cloud Pub/Sub topic. You want to follow Google-recommended practices. What should you do?   A. 1. Create a Cloud Function that uses a Cloud Pub/Sub trigger on that topic. \n   2. Call your application on Cloud Run from the Cloud Function for every message.\n\nB. 1. Grant the Pub/Sub Subscriber role to the service account used by Cloud Run. \n   2. Create a Cloud Pub/Sub subscription for that topic. \n   3. Make your application pull messages from that subscription.\n\nC. 1. Create a service account. \n   2. Give the Cloud Run Invoker role to that service account for your Cloud Run application. \n   3. Create a Cloud Pub/Sub subscription that uses that service account and uses your Cloud Run application as the push endpoint.\n\nD. 1. Deploy your application on Cloud Run on GKE with the connectivity set to Internal. \n  2. Create a Cloud Pub/Sub subscription for that topic. \n  3. In the same Google Kubernetes Engine cluster as your application, deploy a container that takes the messages and sends them to your application.\n \n   \n    解題  要在Cloud Run上部署一個應用程式，並讓它處理來自Cloud Pub/Sub主題的消息，且按照Google推薦的做法操作  選項C：   創建一個服務帳號。  給予該服務帳號對你的Cloud Run應用的Cloud Run Invoker角色。  創建一個Cloud Pub/Sub訂閱，使用該服務帳號，並將你的Cloud Run應用設為推送端點。  選項A：透過Cloud Function作為中介來調用Cloud Run應用。雖然這是一種可行的方案，但它增加了額外的組件和可能的延遲，不是最直接或最高效的方法。  選項B：讓Cloud Run應用拉取消息。這需要應用定期檢查新消息，可能不如推送消息那樣即時，且增加了應用的複雜度。  選項D：在GKE上部署Cloud Run應用，並使用一個額外的容器來轉發消息。這種方法不僅增加了部署的複雜性，也可能不是最成本效益的選擇，特別是當Google提供了更簡潔的集成方案時。     You need to deploy an application, which is packaged in a container image, in a new project. The application exposes an HTTP endpoint and receives very few requests per day. You want to minimize costs. What should you do?   A. Deploy the container on Cloud Run.\nB. Deploy the container on Cloud Run on GKE.\nC. Deploy the container on App Engine Flexible.\nD. Deploy the container on GKE with cluster autoscaling and horizontal pod autoscaling enabled.\n \n   \n    解題  對於需要部署一個容器化應用程式，該應用程式包含一個HTTP端點且每天接收的請求量很少，並希望最小化成本的情境，最合適的選擇是：  A Cloud Run是一個完全管理的平台，能夠根據請求量自動擴展和縮減實例。對於接收請求量很少的應用程式，Cloud Run只在接收請求時運行你的容器，並在沒有請求時自動縮減到0，這樣可以顯著降低成本。另外主要因為它不包括基礎設施服務並且更便宜。  B Cloud Run on GKE（選項B）提供了在Google Kubernetes Engine（GKE）上運行Cloud Run應用的能力，這對於需要GKE特定功能的應用程式很有用。然而，對於大多數場景，特別是請求量很少且希望最小化成本的應用程式，選項A已經足夠且成本更低。  C App Engine Flexible（選項C）也支持容器化應用程式，但相對於Cloud Run，它的運行成本通常較高，因為App Engine Flexible會持續運行你的應用實例，即使沒有接收請求。  D GKE（選項D）是一個功能強大的容器管理系統，支持集群自動擴展和水平Pod自動擴展。雖然這對於需要高度自定義和控制的大型應用程式很有用，但對於每天請求量很少的應用程式來說，維護GKE集群可能導致不必要的成本。     Your company has an existing GCP organization with hundreds of projects and a billing account.Your company recently acquired another company that also has hundreds of projects and its own billing account. You would like to consolidate all GCP costs of both GCP organizations onto a single invoice. You would like to consolidate all costs as of tomorrow. What should you do?    A. Link the acquired company's projects to your company's billing account.\n\n B. Configure the acquired company's billing account and your company's billing account to export the \nbilling data into the same BigQuery dataset.\n\n C. Migrate the acquired company's projects into your company's GCP organization. Link the migrated projects to your company's billing account.\n\n D. Create a new GCP organization and a new billing account. Migrate the acquired company's projects and your company's projects into the new GCP organization and link the projects to the new billing account.\n  \n    解題  要將兩個公司的GCP成本合併到單一發票上，且從明天開始實施，最直接且有效的方法是  答案選A，要改變Project 的 organization需要Google 的協助，無法自己設定，所以單純link billing account過來最簡單     You built an application on Google Cloud that uses Cloud Spanner. Your support team needs to monitor the environment but should not have access to table data. You need a streamlined solution to grant the correct permissions to your support team, and you want to follow Google- recommended practices. What should you do?   A. Add the support team group to the roles/monitoring.viewer role\nB. Add the support team group to the roles/spanner.databaseUser role.\nC. Add the support team group to the roles/spanner.databaseReader role.\nD. Add the support team group to the roles/stackdriver.accounts.viewer role.\n \n   \n    解題  答案A，單純考IAM   roles/monitoring.viewer : 允許用戶查看監控數據，但不提供訪問Cloud Spanner表數據的權限。這正符合需求，即讓支援團隊能監控環境，但不讓他們訪問到數據本身。這是一個簡潔且符合Google推薦做法的解決方案。  D不直接跟Cloud Spanner有關係，B,C使勇基本上都可以接觸到Cloud Spanner表數據     For analysis purposes, you need to send all the logs from all of your Compute Engine instances to a BigQuery dataset called platform-logs. You have already installed the Cloud Logging agent on all the instances. You want to minimize cost. What should you do?   A. \n   1. Give the BigQuery Data Editor role on the platform-logs dataset to the service accounts used by your instances. \n   2. Update your instances' metadata to add the following value: logs-destination: bq://platform-logs.\n\nB. \n   1. In Cloud Logging, create a logs export with a Cloud Pub/Sub topic called logs as a sink. \n   2. Create a Cloud Function that is triggered by messages in the logs topic. \n   3. Configure that Cloud Function to drop logs that are not from Compute Engine and to insert Compute Engine logs in the platform-logs dataset.\n\nC. \n   1. In Cloud Logging, create a filter to view only Compute Engine logs. \n   2. Click Create Export. \n   3. Choose BigQuery as Sink Service, and the platform-logs dataset as Sink Destination.\n\nD.\n   1. Create a Cloud Function that has the BigQuery User role on the platform-logs dataset. \n   2. Configure this Cloud Function to create a BigQuery Job that executes this query: INSERT INTO dataset.platform-logs (timestamp, log) SELECT timestamp, log FROM compute.logs WHERE timestamp > DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY) \n   3. Use Cloud Scheduler to trigger this Cloud Function once a day.\n  \n    解題  為了將所有Compute Engine實例的日誌發送到名為platform-logs的BigQuery數據集，並且希望最小化成本，最適合的方法是：  答案C，Key Point:filter   在Cloud Logging中，創建一個過濾器以僅查看Compute Engine日誌。  點擊「創建導出」。  選擇BigQuery作為接收服務（Sink Service），並將platform-logs數據集作為接收目的地（Sink Destination）。  另外這個方法直接利用Cloud Logging的導出功能將日誌直接導入BigQuery，不需要額外的中介服務如Cloud Pub/Sub或Cloud Function，從而最小化成本。此方法也是直接和高效的，可以確保所有的Compute Engine日誌都被捕獲並導出到指定的BigQuery數據集中。  選項A 提到了更新實例的元數據來直接將日誌發送到BigQuery，但這並不是Cloud Logging提供的標準方法，也不是最佳實踐。  選項B 通過使用Cloud Pub/Sub和Cloud Function來處理日誌，雖然這是一種可能的解決方案，但相對於直接導出到BigQuery，它引入了額外的步驟和潛在的成本。  選項D 用Cloud Function來定期執行BigQuery作業將日誌數據插入到數據集，這不僅複雜且可能增加成本，而且不是處理實時日誌數據的最佳方法。     You are using Deployment Manager to create a Google Kubernetes Engine cluster. Using the same Deployment Manager deployment, you also want to create a DaemonSet in the kube-system namespace of the cluster. You want a solution that uses the fewest possible services. What should you do?   A. Add the cluster's API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet. \n\nB. Use the Deployment Manager Runtime Configurator to create a new Config resource that contains the DaemonSet definition.\n\nC. With Deployment Manager, create a Compute Engine instance with a startup script that uses kubectl to create the DaemonSet.\n\nD. In the cluster's definition in Deployment Manager, add a metadata that has kube-system as key and the DaemonSet manifest as value.\n  \n    解題  若要使用Deployment Manager創建Google Kubernetes Engine (GKE) 集群，並在同一個Deployment Manager部署中為該集群的kube-system命名空間創建DaemonSet，同時希望使用最少的服務，那麼最佳選擇是：  選擇A為何是最佳選擇：在Deployment Manager中添加集群的API作為新的類型提供者(Type Provider)，並使用這個新類型來創建DaemonSet。  這個方法通過使用類型提供者直接在Deployment Manager中整合GKE，允許你直接通過Deployment Manager定義和管理資源（如DaemonSets）。這種方式高效利用了Deployment Manager的現有功能，無需額外的中介服務或手動步驟。  選項B：使用Deployment Manager Runtime Configurator創建一個包含DaemonSet定義的新配置資源，這更適合於運行時配置，並不像添加類型提供者那樣直接支持Kubernetes資源管理。  選項C：創建一個帶有啟動腳本的Compute Engine實例，該腳本使用kubectl來創建DaemonSet，這引入了不必要的複雜性和資源（即Compute Engine實例本身），這與使用最少服務的目標相悖。  選項D：在Deployment Manager的集群定義中添加一個包含DaemonSet清單的元數據條目，這並不是一個通過Deployment Manager部署Kubernetes資源的支持方法。  因此，選項A是使用Deployment Manager同時創建GKE集群和部署DaemonSet的最直接有效方法，符合最少服務使用的目標。   詳細說明  Google Cloud Deployment Manager是一種基於宣告式語言的服務，用於自動化資源的部署。它允許你定義所需的雲端資源和它們之間的關係，然後自動化創建和管理這些資源。  在Deployment Manager中，類型提供者(Type Provider) 是一種讓你能夠擴展Deployment Manager以支援新服務或API的機制。類型提供者基本上是一種定義了如何與外部服務或API通信的配置。創建類型提供者後，你可以在Deployment Manager的模板中使用這些新類型，就像使用內置資源類型一樣。  對於這個問題，具體步驟如下：  添加GKE API作為新的類型提供者：這一步是在Deployment Manager中創建一個新的類型提供者，這個類型提供者定義了如何通過GKE API來操作Kubernetes資源。這意味著你將能夠直接在Deployment Manager的配置文件中定義Kubernetes資源，如DaemonSet。  使用這個新類型創建DaemonSet：一旦類型提供者被創建，你就可以在Deployment Manager的模板中定義DaemonSet資源了。這樣，當Deployment Manager運行時，它會通過GKE API自動在指定的Kubernetes集群中創建DaemonSet。  這個過程的優點在於能夠直接從Deployment Manager管理Kubernetes資源，無需手動運行kubectl命令或使用外部腳本。這樣做可以提高自動化程度，並且讓資源管理更加集中和一致。  簡而言之，選項A的做法是通過擴展Deployment Manager的能力，直接整合GKE API，從而在Deployment Manager中直接管理Kubernetes資源，如DaemonSet，這種方法避免了使用額外的工具或服務，並且利用了Deployment Manager的強大功能來簡化資源部署和管理。     You are building an application that will run in your data center. The application will use Google Cloud Platform (GCP) services like AutoML. You created a service account that has appropriate access to AutoML. You need to enable authentication to the APIs from your on-premises environment. What should you do?   A. Use service account credentials in your on-premises application.\n\nB. Use gcloud to create a key file for the service account that has appropriate permissions.\n\nC. Set up direct interconnect between your data center and Google Cloud Platform to enable authentication for your on- premises applications.\n\nD. Go to the IAM & admin console, grant a user account permissions similar to the service account permissions, and use this user account for authentication from your data center.\n \n   \n    解題  為了從你的內部部署環境中啟用對GCP服務（如AutoML）的身份驗證，最佳做法是使用服務帳戶(service account)憑證。因此，正確的選擇是：  B. 使用 gcloud 創建具有適當權限的服務帳戶金鑰文件。     You are using Container Registry to centrally store your company's container images in a separate\nproject. In another project, you want to create a Googleb Kubernetes Engine (GKE) cluster. You want to ensure that Kubernetes can download images from Container Registry. What should you do?   A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.\n\nB. When you create the GKE cluster, choose the Allow full access to all Cloud APIs option under 'Access scopes'.\n\nC. Create a service account, and give it access to Cloud Storage. Create a P12 key for this service account and use it as an imagePullSecrets in Kubernetes.\n\nD. Configure the ACLs on each image in Cloud Storage to give read-only access to the default Compute Engine service account\n \n   \n    解題  當你的GKE集群和Container Registry不在同一個專案中時，如何設置，使得GKE可以成功地從Container Registry拉取映像？  答案是A，考IAM  A. 在儲存映像的專案中，為Kubernetes節點使用的服務帳戶授予Storage Object Viewer IAM角色。**  Storage Object Viewer **是Google Cloud的一個IAM角色，它賦予帳戶權限去閱讀Google Cloud Storage中的對象，而Container Registry的背後存儲就是使用Google Cloud Storage。  B. 'Access scopes'表示Allow full access to all Cloud。這個選項是指當你建立GKE集群時，給予這個集群完全訪問所有Google Cloud API的權限。儘管這會讓GKE集群能夠訪問Container Registry，但它也給予了集群訪問所有其他Google Cloud服務的能力，這可能會有安全性的風險。  C. 這個選項是建議你創建一個新的服務帳戶，然後給它一個P12格式的密鑰。之後，在Kubernetes中使用這個密鑰作為imagePullSecrets，以保證Kubernetes可以從Container Registry拉取映像。雖然這個方法理論上是可行的，但它比較繁瑣，且  P12密鑰已不再是Google Cloud推薦的做法 。  D. \"在Cloud Storage的每一個映像上設置ACL…太繁瑣麻煩了，這答案PASS     You deployed a new application inside your Google Kubernetes Engine cluster using the YAML\nfile specified below    You check the status of the deployed pods and notice that one of them is still in PENDING status    You want to find out why the pod is stuck in pending status. What should you do?   A. Review details of the myapp-service Service object and check for error messages.\nB. Review details of the myapp-deployment Deployment object and check for error messages.\nC. Review details of myapp-deployment-58ddbbb995-lp86m Pod and check for warning messages.\nD. View logs of the container in myapp-deployment-58ddbbb995-lp86m pod and check for warning messages.\n \n   \n    解題  你在Google Kubernetes Engine (簡稱GKE，Google的容器管理系統)中部署了一個新的應用程式，部署完之後，你檢查了那些運行的應用程式（在這裡稱為\"pods\"），發現其中一個還在\"等待\"狀態（Pending）。你想要知道為什麼這個應用程式（pod）一直在等待，沒有正常運行。  A. 查看\"myapp-service\"服務物件的詳細資料並檢查錯誤訊息。檢查與服務相關的設定和可能的錯誤。  B. 查看\"myapp-deployment\"部署物件的詳細資料並檢查錯誤訊息，檢查部署的設定，看是否有什麼配置上的問題或錯誤訊息  C. 查看\"myapp-deployment-58ddbbb995-lp86m\"這個pod的詳細資料並檢查警告訊息  (主要關注的是整個pod的狀態。當Kubernetes嘗試啟動一個pod時，如果有問題，它通常會在pod的狀態或事件中留下一些警告或錯誤訊息。這可以是關於資源不足、課程配置問題或其他與Kubernetes系統相關的問題。)  D. 查看在\"myapp-deployment-58ddbbb995-lp86m\" pod裡的容器的日誌，並檢查警告訊息。  (這是針對pod內部的容器。一個pod可以包含多個容器，而這些容器裡的應用可能會有自己的日誌。如果容器中的應用程序遇到問題（例如配置問題、連接到數據庫的問題等），它通常會在日誌中輸出相關的錯誤或警告訊息。)  答案是C 基本上從C先去粗看，找不出原因才會細部去看D的蛛絲馬跡     You are setting up a Windows VM on Compute Engine and want to make sure you can log in to\nthe VM via RDP. What should you do?   A. After the VM has been created, use your Google Account credentials to log in into the VM.\n\nB. After the VM has been created, use gcloud compute reset-windows-password to retrieve the login credentials for the VM.\n\nC. When creating the VM, add metadata to the instance using 'windows-password' as the key and a password as the value.\n\nD. After the VM has been created, download the JSON private key for the default Compute Engine service account. Use the credentials in the JSON file to log in to the VM \n  \n    解題  如何設定一台在Compute Engine上的Windows虛擬機（VM），以確保你可以透過RDP(遠端桌面協定)來登入這台虛擬機。  答案是B  A. 這選項意思是創建虛擬機（VM）後，使用你的Google帳戶資料登入VM。實際上，你不能使用Google帳戶直接登入Windows VM。…  B. 創建VM後，使用**  gcloud compute reset-windows-password **來獲取VM的登入憑證。這是Google Cloud的一個命令，可以讓你重設並取得Windows虛擬機的密碼。這使你能夠透過RDP登入。  C. 在創建VM時，使用'metadata'添加'windows-password'作為鍵，並使用密碼作為值。創建虛擬機的時候，直接設定一個密碼。但這不是Google Cloud建議的安全做法。  D. 創建VM後，下載預設的Compute Engine服務帳戶的JSON私鑰。使用JSON文件中的憑證登入VM。這個選項是提議你使用Google Cloud的服務帳戶來登入VM。但這主要是用於API存取，不是用於RDP登入。     You want to configure an SSH connection to a single Compute Engine instance for users in the\ndev1 group. This instance is the only resource in this particular Google Cloud Platform project that the dev1 users should be able to connect to. What should you do?   A. Set metadata to enable-oslogin=true for the instance. Grant the dev1 group the compute.osLogin role. Direct them to use the Cloud Shell to ssh to that instance.\n\nB. Set metadata to enable-oslogin=true for the instance. Set the service account to no service account for that instance. Direct them to use the Cloud Shell to ssh to that instance.\n\nC. Enable block project wide keys for the instance. Generate an SSH key for each user in the dev1 group. Distribute the keys to dev1 users and direct them to use their third-party tools to connect\n\nD. Enable block project wide keys for the instance. Generate an SSH key and associate the key with that instance. Distribute the key to dev1 users and direct them to use their third-party tools to connect.\n \n   \n    解題  這題目是關於如何設定對Google Cloud Platform（GCP）上的一台Compute Engine實例進行SSH連接的權限，並專門針對dev1群組中的用戶。目標是讓這個特定群組的用戶能夠連接到這台實例，而這台實例是該GCP項目中唯一允許dev1用戶連接的資源。  答案是A  A. 將該實例的metadata設定為enable-oslogin=true。給**  dev1  群組授予  compute.osLogin **角色。指導他們使用Cloud Shell ssh連接到該實例。這種方法使用了osLogin特性，允許基於IAM權限的SSH登錄。  B. 將該實例的metadata設定為enable-oslogin=true。對該實例設置no service account。指導他們使用Cloud Shell ssh連接到該實例。   與選項A相似，但取消了該實例的service account。 (拿掉Service Account)  C. 啟用block project wide keys。為**  dev1  群組中的每個用戶生成SSH密鑰。將密鑰分發給  dev1 **的用戶，並指導他們使用第三方工具進行連接。不允許使用專案範圍的SSH密鑰，而是為每個使用者單獨生成密鑰。  D. 為實例啟用block project wide keys。生成SSH密鑰並與該實例關聯。將密鑰分發給**  dev1 **的用戶，並指導他們使用第三方工具進行連接。   與選項C相似，但是只生成一組SSH密鑰，然後將其與該實例關聯，並分發給所有**  dev1 **群組的用戶。  根據需求，你想要限制只有**  dev1 **群組的用戶能夠SSH連接到該實例。最直接且基於IAM權限控制的方法是使用osLogin特性。因此，選項A最符合這種需求。選項A允許你基於IAM角色控制哪些用戶可以SSH到該實例，且使用Cloud Shell可以讓這些用戶不需要額外配置他們的SSH客戶端。     You need to produce a list of the enabled Google Cloud Platform APIs for a GCP project using the\ngcloud command line in the Cloud Shell. The project name is my-project. What should you do?   A. Run gcloud projects list to get the project ID, and then run gcloud services list --project <project ID>.\nB. Run gcloud init to set the current project to my-project, and then run gcloud services list --available.\nC. Run gcloud info to view the account value, and then run gcloud services list --account <Account>.\nD. Run gcloud projects describe <project ID> to verify the project value, and then run gcloud services list --available\n  \n    解題  你需要使用 gcloud 命令行工具（在 Cloud Shell 中）來產生一份列表，這份列表要顯示出 Google Cloud Platform 的哪些 API 是被啟用的，對於名稱為 \"my-project\" 的 GCP 專案。  答案是A  A.    gcloud projects list  可以幫你列出所有的GCP專案。之後你再用    gcloud services list --project <project ID>  來查詢某一特定專案所啟用的API。這方法是正確的，但在題目中已提供了專案名稱為 \"my-project\"，所以理論上不需要再用    gcloud projects list  來查專案ID。  B. 使用    gcloud init  可以設定當前的專案。但是    gcloud services list --available  會列出所有可用的API，而不是已啟用的API。  C.    gcloud info  會提供你帳號的資訊，但是我們想知道的是哪些API被啟用，和帳號資訊無關。  D.    gcloud projects describe <project ID>  可以給你關於特定專案的詳細資訊，但是這個命令和查看已啟用的API無關。而    gcloud services list --available  會列出所有可用的API，不是已啟用的。     You are building a new version of an application hosted in an App Engine environment. You want\nto test the new version with 1% of users before you completely switch your application over to the new version. What should you do?   A. Deploy a new version of your application in Google Kubernetes Engine instead of App Engine and then use GCP Console to split traffic.\nB. Deploy a new version of your application in a Compute Engine instance instead of App Engine and then use GCP Console to split traffic.\nC. Deploy a new version as a separate app in App Engine. Then configure App Engine using GCP Console to split traffic between the two apps.\nD. Deploy a new version of your application in App Engine. Then go to App Engine settings in GCP Console and split traffic between the current version and newly deployed versions accordingly.\n \n   \n    解題  D  A - 建置在GKE上，依據題目是錯誤的  B - 建置在Compute Engine也不是建置在App Engine所以也是錯誤的  C - 這題錯在前半段，他說以『a separate app』就是建置一個獨立的服務與原本的不同，因此他的流量應該為獨立的和舊的版本無法做到導流，所以無法達到分流的狀況。  D - 建立新的版本再分配流量給不同程式的應用版本會是較佳的做法。     You need to provide a cost estimate for a Kubernetes cluster using the GCP pricing calculator for Kubernetes. Your workload requires high IOPs, and you will also be using disk snapshots. You start by entering the number of nodes, average hours, and average days. What should you do next?   A. Fill in local SSD. Fill in persistent disk storage and snapshot storage. \nB. Fill in local SSD. Add estimated cost for cluster management.\nC. Select Add GPUs. Fill in persistent disk storage and snapshot storage. \nD. Select Add GPUs. Add estimated cost for cluster management.\n  \n    解題  當使用GCP定價計算器為Kubernetes集群提供成本估算時，需要考慮的關鍵因素包括節點的數量、運行時間、存儲需求，以及是否需要高性能的輸入輸出操作（IOPs）。如果您的工作負載需要高IOPs並且您計劃使用磁盤快照，則應該特別關注與存儲相關的選項。  A  A，填寫本地SSD、持久化磁盤存儲和快照存儲。這個選項考慮到了需要高IOPs的工作負載，本地SSD提供了高速的存取能力，非常適合IOPs密集型應用。同時，也包括了持久化磁盤和快照存儲的成本，這是為了滿足數據持久性和數據保護的需求。  B，填寫本地SSD。添加集群管理的估計成本。這個選項同樣提到了本地SSD，但是它強調添加集群管理的成本，而沒有明確提到持久化磁盤存儲和快照存儲，這可能遺漏了工作負載中關於數據存儲和保護的重要部分。  C，選擇添加GPU。填寫持久化磁盤存儲和快照存儲。雖然GPU對於需要大量計算的工作負載非常有用，但是對於需要高IOPs的場景，GPU的添加並不直接關聯。這個選項沒有提到本地SSD，可能不完全符合高IOPs需求。  D，擇添加GPU。添加集群管理的估計成本。這個選項類似於C，同時也沒有考慮到本地SSD和具體的存儲需求，因此可能不是最適合的選項。  依據題目描述，應該要先評估每一個Node上所需要用到的硬碟資源，並解他需要高IOPs所以可以選擇Local SSD，最後在考慮其他的成本例如所有APP節點運行得時間和平均時間。     You are using Google Kubernetes Engine with autoscaling enabled to host a new application. You want to expose this new application to the public, using HTTPS on a public IP address. What should you do?   A. Create a Kubernetes Service of type NodePort for your application, and a Kubernetes Ingress to expose this Service via a Cloud Load Balancer.\n\nB. Create a Kubernetes Service of type ClusterIP for your application. Configure the public DNS name of your application using the IP of this Service.\n\nC. Create a Kubernetes Service of type NodePort to expose the application on port 443 of each node of the Kubernetes cluster. Configure the public DNS name of your application with the IP of every node of the cluster to achieve load-balancing.\n\nD. Create a HAProxy pod in the cluster to load-balance the traffic to all the pods of the application. Forward the public traffic to HAProxy with an iptable rule. Configure the DNS name of your application using the public IP of the node HAProxy is running on.\n \n   \n    解題  答案A，K8S 建設NodePort服務，並且將我的Servicer 設定給K8S Ingress並且再將Ingress透過Cloud Load Balancer來開對外的聯通。  B - ClusterIP 無法直接透過外部Internet直連到K8S服務，必須在K8S外部多架一層Proxy代理作為跳板轉連至ClusterIP Service。  C - NodePort 限定Port必須在30000~32767之間，所以如果要在每個NodePort上開443會是無法執行的。  D - HAProxy 需要架設在外部，然後使用k8s Ingress開啟一個入口讓外部的流量連入K8s中     You need to enable traffic between multiple groups of Compute Engine instances that are currently running two different GCP projects. Each group of Compute Engine instances is running in its own VPC. What should you do?   A. Verify that both projects are in a GCP Organization. Create a new VPC and add all instances.\nB. Verify that both projects are in a GCP Organization. Share the VPC from one project and request that the Compute Engine instances in the other project use this shared VPC.\nC. Verify that you are the Project Administrator of both projects. Create two new VPCs and add all instances.\nD. Verify that you are the Project Administrator of both projects. Create a new VPC and add all instances.\n  \n    解題  要在兩個不同GCP項目中運行的多組Compute Engine實例之間啟用流量，且每組實例都在自己的VPC中運行   「enable traffic」在這裡指的是允許或啟用網絡流量在不同虛擬私人雲（VPC）或計算實例（Compute Engine instances）之間流動。  最佳的方法是利用VPC對等連接或共享VPC功能。這些功能允許不同項目中的VPC網路安全地共享資源，而無需通過公共互聯網進行通信，從而保證了效率和安全性。  A -  你的VPC一定要建立在某一個專案底下，並且沒有分享出來，在另一個專案是無法將實例加入其中。  C -  應不需要驗證，因透過ＩＡＭ你能操做的專案會設定在專屬帳號上，後面就不用說了  D -  與Ｃ一樣的理由  B - 將其中一個專案的ＶＰＣ Share出來，使其可以將Compute Engine共享ＶＰＣ就可以互連了     You want to add a new auditor to a Google Cloud Platform project. The auditor should be allowed to read, but not modify, all project items. How should you configure the auditor's permissions?   A. Create a custom role with view-only project permissions. Add the user's account to the custom role. \nB. Create a custom role with view-only service permissions. Add the user's account to the custom role. \nC. Select the built-in IAM project Viewer role. Add the user's account to this role.\nD. Select the built-in IAM service Viewer role. Add the user's account to this role.\n \n   \n    解題  答案C.考IAM.且不需要用custom role...     You are operating a Google Kubernetes Engine (GKE) cluster for your company where different teams can run non-production workloads. Your Machine Learning (ML) team needs access to Nvidia Tesla P100 GPUs to train their models. You want to minimize effort and cost. What should you do?   A. Ask your ML team to add the accelerator: gpu annotation to their pod specification.\nB. Recreate all the nodes of the GKE cluster to enable GPUs on all of them.\nC. Create your own Kubernetes cluster on top of Compute Engine with nodes that have GPUs. \n  Dedicate this cluster to your ML team.\nD. Add a new, GPU-enabled, node pool to the GKE cluster. Ask your ML team to add the \n  cloud.google.com/gke-accelerator: nvidia-tesla-p100 nodeSelector to their pod specification.\n \n    \n    解題  你正在設定一個 GKE 的 Cluster 提供給組織內不同的團隊，用於非生產環境。你的 ML 團隊需要訪問Nvidia Tesla P100 GPU 來訓練他們的 models，你想要最小化費用，你會怎麼做?  A.  要求 ML 團隊 新增加速器將 GPU 備註到他們的 pod 規格，單純添加註解不足以確保Pod可以使用GPU資源  B.  重新建立 GKE 上所有  cluster 的 nodes ，並啟動 GPUs 永遠執行，這個選項會造成不必要的成本和工作量，因為不是所有節點都需要GPU支持  C. 建立你的個人 K8S cluster 包含 GPUs 的 Computer Engine nodes ，並提供給 ML 團隊使用，雖然這種方法可以工作，但它需要更多的管理和維護工作  D. 在 GKE 的 cluster 建立一個新的 GPU-enable 的 node pool，要求 ML team 新增 “cloud.google.com/gke-accelerator: nvidia-tesla-p100” nodeSelector 的 pod 規格  答案為D，建立node pool時就需要選擇...       Your VMs are running in a subnet that has a subnet mask of 255.255.255.240. The current subnet has no more free IP addresses and you require an additional 10 IP addresses for new VMs. The existing and new VMs should all be able to reach each other without additional routes. What should you do?   A. Use gcloud to expand the IP range of the current subnet.\nB. Delete the subnet, and recreate it using a wider range of IP addresses.\nC. Create a new project. Use Shared VPC to share the current network with the new project.\nD. Create a new subnet with the same starting IP but a wider range to overwrite the current subnet.\n   解題  你的 VM 目前在一個 VPC 的子網路內運行，子網路的遮罩為 255.255.255.240 ，當前子網路沒有多餘的閒置 IP ，你需要 10 個新的 IP 以提供給 新的 VM。所有的 VM 要能相互連線，你會怎麼做?  答案是A，注意subnet 只能擴展不能縮小     Your organization uses G Suite for communication and collaboration. All users in your\norganization have a G Suite account. You want to grant some G Suite users access to your Cloud Platform project. What should you do?   A. Enable Cloud Identity in the GCP Console for your domain.\nB. Grant them the required IAM roles using their G Suite email address.\nC. Create a CSV sheet with all users' email addresses. Use the gcloud command line tool to convert them into Google Cloud Platform accounts.\nD. In the G Suite console, add the users to a special group called cloud-console-users@yourdomain.com. Rely on the default behavior of the Cloud Platform to grant users access if they are members of this group.\n \n   \n    解題  你的組織使用 G Suite 來溝通協作。所有使用者在你的組織內都有一個 G Shite 的 account，你想要給某些 G Suite 使用者你的 GCP 專案權限，你會怎麼做?  答案是B. 使用他們的G Suite電子郵件地址給予他們所需的IAM角色。 這是一個直接且有效的方法。在GCP中，你可以通過用戶的電子郵件地址直接在IAM（身份與訪問管理）政策中指定用戶，從而賦予他們特定的角色和權限。這意味著如果他們已經有G Suite帳戶，你可以直接使用這些帳戶來授予他們訪問GCP項目的權限。  A. 在GCP控制台為你的域啟用Cloud Identity。 Cloud Identity是用於帳戶管理和安全的一種服務，但這不是將G Suite用戶直接授予GCP項目訪問權的必要步驟。  C. gcloud 沒有這種功能  D. 沒有這種預設群組     You have a Google Cloud Platform account with access to both production and development projects.\nYou need to create an automated process to list all compute instances in development and production\nprojects on a daily basis. What should you do?   A. Create two configurations using gcloud config. \n   Write a script that sets configurations as active, individually. \n   For each configuration, use gcloud compute instances list to get a list of compute resources.\n\nB. Create two configurations using gsutil config. \n   Write a script that sets configurations as active, individually. \n   For each configuration, use gsutil compute instances list to get a list of compute resources.\n\nC. Go to Cloud Shell and export this information to Cloud Storage on a daily basis.\n\nD. Go to GCP Console and export this information to Cloud SQL on a daily basis.\n \n   \n    解題  答案為A，  B. gsutil 已棄用  C D 兩者皆非自動化     You have a large 5-TB AVRO file stored in a Cloud Storage bucket. Your analysts are proficient\nonly in SQL and need access to the data stored in this file. You want to find a cost-effective\nway to complete their request as soon as possible. What should you do?   A. Load data in Cloud Datastore and run a SQL query against it.\n\nB. Create a BigQuery table and load data in BigQuery. Run a SQL query on this table and drop \n   this table after you complete your request.\n\nC. Create external tables in BigQuery that point to Cloud Storage buckets and run a SQL query \n   on these external tables to complete your request.\n\nD. Create a Hadoop cluster and copy the AVRO file to NDFS by compressing it. \n   Load the file in a hive table and provide access to your analysts so that they can run SQL queries.\n \n   \n    解題  你有一個5TB大的 AVRO 檔案儲存在 Cloud Storage bucket 內。你們的分析師只精通 SQL 且他們需要訪問這個檔案。你想要找一個低成本且快速回應的方法，你會怎麼做?  答案是C，建立一個 BigQuery external tables 並指向 Cloud Storage buckets，在此 external table 執行 SQL query。在BigQuery中創建指向Cloud Storage桶的外部表格，並在這些外部表格上運行SQL查詢以完成請求。 這也是一個很好的選項，因為它不需要將數據從Cloud Storage實際移動到BigQuery中，可以節省加載數據的時間和成本。外部表格允許你直接在存儲在Cloud Storage中的數據上運行查詢，這對於只需臨時分析數據的場景非常合適。  A. Datastore是NoSQL  B. 可行但費用較高，因為資料額外儲存了一份在BigQuery  D. Hadoop 並非在此情境下所需使用     You need to verify that a Google Cloud Platform service account was created at a particular time.\nWhat should you do?   A. Filter the Activity log to view the Configuration category. Filter the Resource type to Service Account.\nB. Filter the Activity log to view the Configuration category. Filter the Resource type to Google Project.\nC. Filter the Activity log to view the Data Access category. Filter the Resource type to Service Account.\nD. Filter the Activity log to view the Data Access category. Filter the Resource type to Google Project.\n \n   \n    解題  答案為A  A 這是正確的做法。在活動日誌中，創建服務帳戶的行為被歸類為配置變更（Configuration category）。通過篩選資源類型為Service Account，你可以找到關於服務帳戶創建的具體記錄。  B 這個選項不正確。雖然創建服務帳戶確實是一種配置變更，但是過濾條件應該是Service Account而不是Google Project。  C 這個選項不正確。Data Access類別通常用於記錄對數據的訪問事件，而不是資源的創建或配置變更。  D 這個選項不正確，因為它關注的是數據訪問類別，而且篩選的資源類型也不適合查找服務帳戶的創建事件。     You deployed an LDAP server on Compute Engine that is reachable via TLS through port 636 using UDP.\nYou want to make sure it is reachable by clients over that port. What should you do?   A. Add the network tag allow-udp-636 to the VM instance running the LDAP server.\nB. Create a route called allow-udp-636 and set the next hop to be the VM instance running the LDAP server.\nC. Add a network tag of your choice to the instance. \n   Create a firewall rule to allow ingress on UDP port 636 for that network tag.\nD. Add a network tag of your choice to the instance running the LDAP server. \n   Create a firewall rule to allow egress on UDP port 636 for that network tag.\n \n   \n    解題  要確保通過UDP協議在636端口上部署的LDAP伺服器可以被客戶端訪問  你需要創建一條防火牆規則來允許該端口的流量進入（ingress）。這涉及到設定GCP上的網絡標籤（network tag）和相應的防火牆規則。  A 單獨添加網絡標籤到VM實例是不夠的，還需要創建一條匹配該標籤的防火牆規則來允許UDP 636端口的流量。  B 路由用於定義IP網絡流量如何在VPC網絡內或跨VPC網絡傳遞，而不是用來控制端口層面的訪問權限。  C 這是正確的做法。首先給實例添加一個網絡標籤，然後創建一條防火牆規則，指定允許針對該標籤的UDP 636端口的進入流量。  D 這個選項是關於允許出站流量（egress），而不是讓客戶端可以訪問LDAP服務器所需的進入流量（ingress）。  答案為C     You need to set a budget alert for use of Compute Engineer services on one of the three Google Cloud\nPlatform projects that you manage. All three projects are linked to a single billing account. What should you do?   A. Verify that you are the project billing administrator. \n   Select the associated billing account and create a budget and alert for the appropriate project.\nB. Verify that you are the project billing administrator. \n   Select the associated billing account and create a budget and a custom alert.\nC. Verify that you are the project administrator. \n   Select the associated billing account and create a budget for the appropriate project.\nD. Verify that you are project administrator. \n   Select the associated billing account and create a budget and a custom alert.\n \n   \n    解題  答案直覺就是A，  B. default alert就可以做到，不需要自訂  C、D. project administrator 沒有 billing相關權限     You are migrating a production-critical on-premises application that requires 96 vCPUs to perform its task. You want to make sure the application runs in a similar environment on GCP. What should you do?   A. When creating the VM, use machine type n1-standard-96.\nB. When creating the VM, use Intel Skylake as the CPU platform.\nC. Create the VM using Compute Engine default settings. Use gcloud to modify the running instance to have 96 vCPUs.\nD. Start the VM using Compute Engine default settings, and adjust as you go based on Rightsizing Recommendations.\n \n   \n    解題  對於需要將一個對生產至關重要的內部部署應用程序（要求96個虛擬CPU以進行運作）遷移到Google Cloud Platform（GCP），確保應用程序在GCP上運行於類似環境中非常重要。  A. 這是一個直接的解決方案，因為它指定了一種特定的機器類型，n1-standard-96，這提供了96個vCPU，符合需求。  B. 雖然指定CPU平台（如Intel Skylake）可以確保應用程序運行在特定的硬件上，但這並不直接解決vCPU數量的需求。  C. 修改正在運行的實例以增加vCPU數量並不是一個支持的操作。要更改機器類型，通常需要停止實例，然後更改其機器類型，而不是在運行時直接修改。  D. 雖然基於Rightsizing Recommendations進行調整是一種好的實踐，以確保資源使用最優化，但這對於迁移一個生產關鍵應用程序並且已知需要96個vCPU的情況，這種方法過於反應式且可能不滿足初始需求。  答案是A     You want to configure a solution for archiving data in a Cloud Storage bucket.\nThe solution must be cost-effective.\nData with multiple versions should be archived after 30 days.\nPrevious versions are accessed once a month for reporting.\nThis archive data is also occasionally updated at month-end. What should you do?   A. Add a bucket lifecycle rule that archives data with newer versions after 30 days to Coldline Storage.\nB. Add a bucket lifecycle rule that archives data with newer versions after 30 days to Nearline Storage.\nC. Add a bucket lifecycle rule that archives data from regional storage after 30 days to Coldline Storage.\nD. Add a bucket lifecycle rule that archives data from regional storage after 30 days to Nearline Storage.\n \n   \n    解題  要配置一個用於在Cloud Storage桶中存檔數據的解決方案，同時確保成本效益，需要考慮數據的訪問頻率和存儲成本。考慮到提供的情境——數據在30天後被存檔，之前的版本每月訪問一次用於報告，並且這些存檔數據在月底偶爾更新   Standard Storage: 高性能、高可用、頻繁存取。  Nearline Storage: 用於每月存取少於1次的data。  Coldline Storage: 用於每季存取少於1次的data。  Archive Storage: 用於每年存取少於1次的data，需保存多年的data。  選項A和C提到將數據存儲到Coldline，而選項B和D提到將數據存儲到Nearline。考慮到數據每月至少被訪問一次，並且偶爾更新，Nearline提供了一個成本效益較高的解決方案。  然而，選項B和D在描述上有細微差別，主要是是否從區域存儲（regional storage）轉移。根據題目的描述，重點是多版本數據在30天後的存檔策略，而不是特定的存儲類型轉移。因此，選擇應基於將數據存檔到適當的存儲類型。  考慮到成本效益和數據的訪問模式，B. Add a bucket lifecycle rule that archives data with newer versions after 30 days to Nearline Storage 似乎是最合適的選擇。這樣可以在保持成本低的同時，滿足對數據的訪問需求。     Your company's infrastructure is on-premises, but all machines are running at maximum\ncapacity. You want to burst to Google Cloud. The workloads on Google Cloud must be able to directly communicate to the workloads on-premises using a private IP range. What should you do?   A. In Google Cloud, configure the VPC as a host for Shared VPC.\n\nB. In Google Cloud, configure the VPC for VPC Network Peering.\n\nC. Create bastion hosts both in your on-premises environment and on Google Cloud. Configure both as proxy servers using their public IP addresses.\n\nD. Set up Cloud VPN between the infrastructure on-premises and Google Cloud.\n \n   \n    解題  您公司的基礎設施位於本地，但所有機器都以最大容量運行。您想要擴展到Google Cloud。Google Cloud上的工作負載必須能夠使用私有IP範圍直接與本地工作負載通信。您應該怎麼做？  答案是D，VPN正解  A. 在Google Cloud中配置VPC作為Shared VPC的主機。這主要用於在組織內不同的Google Cloud項目之間共享網絡資源，而不直接涉及與本地環境的連接。  B. 在Google Cloud中為VPC網絡對等連接（VPC Network Peering）配置VPC。VPC網絡對等連接允許兩個VPC網絡私密地交換流量，但這主要用於Google Cloud的VPC之間，而不是Google Cloud與本地環境之間。  C. 在您的本地環境和Google Cloud中創建堡壘主機。配置它們作為使用其公共IP地址的代理服務器。這可以提供一種間接的通信方式，但不是使用私有IP範圍進行直接通信的最佳選擇。  D. 在本地基礎架構和Google Cloud之間設置Cloud VPN。這允許您通過安全的VPN隧道直接使用私有IP地址範圍在本地環境和Google Cloud之間通信，是實現您需求的理想選擇。     You want to select and configure a solution for storing and archiving data on Google Cloud\nPlatform. You need to support compliance objectives for data from one geographic location. This data is archived after 30 days and needs to be accessed annually. What should you do?   A. Select Multi-Regional Storage. Add a bucket lifecycle rule that archives data after 30 days to Coldline Storage.\nB. Select Multi-Regional Storage. Add a bucket lifecycle rule that archives data after 30 days to Nearline Storage.\nC. Select Regional Storage. Add a bucket lifecycle rule that archives data after 30 days to Nearline Storage.\nD. Select Regional Storage. Add a bucket lifecycle rule that archives data after 30 days to Coldline Storage.\n \n   \n    解題  您希望選擇並配置Google Cloud平台上用於存儲和歸檔數據的解決方案。您需要支持來自一個地理位置的數據的合規性目標。這些數據在30天后進行歸檔，並且需要每年訪問。您應該怎麼做？  答案D  A. 選擇多區域存儲。添加一個存儲桶生命週期規則，將數據在30天后歸檔到Coldline Storage中。\nB. 選擇多區域存儲。添加一個存儲桶生命週期規則，將數據在30天后歸檔到Nearline Storage中。\nC. 選擇區域存儲。添加一個存儲桶生命週期規則，將數據在30天后歸檔到Nearline Storage中。\nD. 選擇區域存儲。添加一個存儲桶生命週期規則，將數據在30天后歸檔到Coldline Storage中。     Your company uses BigQuery for data warehousing. Over time, many different business units in\nyour company have created 1000+ datasets across hundreds of projects. Your CIO wants you to examine all datasets to find tables that contain an employee_ssn column. You want to minimize effort in performing this task. What should you do?   A. Go to Data Catalog and search for employee_ssn in the search box.\nB. Write a shell script that uses the bq command line tool to loop through all the projects in your organization.\nC. Write a script that loops through all the projects in your organization and runs a query on\n   INFORMATION_SCHEMA.COLUMNS view to find the employee_ssn column.\nD. Write a Cloud Dataflow job that loops through all the projects in your organization and runs a query on\n   INFORMATION_SCHEMA.COLUMNS view to find employee_ssn column.\n \n   \n    解題  您的公司在數據倉庫中使用BigQuery。隨著時間的推移，公司的許多不同業務部門在數百個項目中創建了1000多個數據集。您的首席信息官（CIO）希望您檢查所有數據集，找到包含員工社會安全號（employee_ssn）列的表格。您希望盡量減少執行此任務所需的工作量。您應該怎麼做？  A. 轉到Data Catalog並在搜索框中搜索employee_ssn。\nB. 編寫一個使用bq命令行工具來循環遍歷組織中所有項目的shell腳本。\nC. 編寫一個腳本，循環遍歷組織中的所有項目，並在INFORMATION_SCHEMA.COLUMNS視圖上運行查詢，以查找employee_ssn列。\nD. 編寫一個Cloud Dataflow作業，循環遍歷組織中的所有項目，並在INFORMATION_SCHEMA.COLUMNS視圖上運行查詢，以查找employee_ssn列。  答案是 A，因為它需要較少的精力，而其他選項則更耗時且容易出錯     You create a Deployment with 2 replicas in a Google Kubernetes Engine cluster that has a single preemptible node pool. After a few minutes, you use kubectl to examine the status of your Pod and observe one of them is still in Pending status: (圖在下面) What is the most likely cause?     A. The pending Pod's resource requests are too large to fit on a single node of the cluster.\n\nB. Too many Pods are already running in the cluster, and there are not enough resources left to schedule the pending Pod.\n\nC. The node pool is configured with a service account that does not have permission to pull the container image used by the pending Pod.\n\nD. The pending Pod was originally scheduled on a node that has been preempted between the creation of the Deployment and your verification of the Pods' status. It is currently being rescheduled on a new node.\n \n   \n    解題  您在Google Kubernetes Engine集群中创建了一個只有一個預設節點池的部署（Deployment），該部署包含2個副本。幾分鐘後，您使用kubectl檢查Pod的狀態，發現其中一個仍處於待定狀態：\n（圖像在下方）  最有可能的原因是什麼？  B，D也有可能，但最大常見可能是B  A. 挂起的Pod的資源需求過大，無法容納在集群的單個節點上。\nB. 集群中已經運行了太多的Pod，沒有足夠的資源來調度待定的Pod。\nC. 節點池配置了一個服務帳戶，該服務帳戶無權拉取待定Pod使用的容器映像。\nD. 待定的Pod最初被排定在一個節點上，而在部署創建和您驗證Pod狀態之間，該節點已被抢占。它目前正在被重新調度到一個新的節點上。     You want to find when users were added to Cloud Spanner Identity Access Management (IAM) roles on your Google Cloud (GCP) project. What should you do in the GCP Console?   A. Open the Cloud Spanner console to review configurations.\n\nB. Open the IAM & admin console to review IAM policies for Cloud Spanner roles.\n\nC. Go to the Stackdriver Monitoring console and review information for Cloud Spanner.\n\nD. Go to the Stackdriver Logging console, review admin activity logs, and filter them for Cloud Spanner IAM roles.\n \n   \n    解題  您想要查找用戶何時被添加到您的Google Cloud（GCP）項目上的Cloud Spanner身份訪問管理（IAM）角色。在GCP控制台上，您應該怎麼做？  A. 打開Cloud Spanner控制台以查看配置。\nB. 打開IAM和管理員控制台以查看Cloud Spanner角色的IAM策略。\nC. 轉到Stackdriver Monitoring控制台並查看Cloud Spanner的信息。\nD. 轉到Stackdriver Logging控制台，查看管理員活動日誌，並將其篩選為Cloud Spanner IAM角色。  答案 A 不正確，因為 Cloud Spanner 控制台僅顯示與 Cloud Spanner 實例和數據庫相關的配置，而不顯示 IAM 角色。  答案 B 部分正確，因為可以在 IAM 和管理控制台中查看和編輯 IAM 策略。但是，它不顯示用戶添加到 Cloud Spanner IAM 角色的歷史記錄。  答案 C 不正確，因為 Stackdriver Monitoring 用於監控 Google Cloud 資源和應用程序的性能，並且不提供有關 IAM 角色更改的信息。  答案是 D，因為 Stackdriver Logging 提供所有管理活動日誌的全面歷史記錄，包括用戶添加到 Cloud Spanner IAM 角色的時間。     Your company implemented BigQuery as an enterprise data warehouse.\nUsers from multiple business units run queries on this data warehouse.\nHowever, you notice that query costs for BigQuery are very high, and you need to control costs.\nWhich two methods should you use? (Choose two.)   A. Split the users from business units to multiple projects.\nB. Apply a user- or project-level custom query quota for BigQuery data warehouse.\nC. Create separate copies of your BigQuery data warehouse for each business unit.\nD. Split your BigQuery data warehouse into multiple data warehouses for each business unit.\nE. Change your BigQuery query model from on-demand to flat rate. Apply the appropriate number of slots to each Project.\n \n   \n    解題  BE  A: 將來自不同業務部門的用戶分成多個項目，本質上是好管理各部門預算，但無法設定上限  B: 在BigQuery數據倉庫上應用用戶或項目級別的自定義查詢配額  C: 為各部門間獨立 BigQuery data warehouse，經費爆炸  D: 同上  E: 將BigQuery查詢模型從需求導向轉換為定額模型，並為每個項目應用適當數量的配額     You are building a product on top of Google Kubernetes Engine (GKE).\nYou have a single GKE cluster.\nFor each of your customers, a Pod is running in that cluster, and your customers can run arbitrary code inside their Pod.\nYou want to maximize the isolation between your customers' Pods.\nWhat should you do?   A. Use Binary Authorization and whitelist only the container images used by your customers' Pods.\nB. Use the Container Analysis API to detect vulnerabilities in the containers used by your customers' Pods.\nC. Create a GKE node pool with a sandbox type configured to gvisor. Add the parameter runtimeClassName: gvisor to the specification of your customers' Pods.\nD. Use the cos_containerd image for your GKE nodes. Add a nodeSelector with the value cloud.google.com/gke-os- distribution: cos_containerd to the specification of your customers' Pods.\n \n   \n    解題  為了最大化客戶Pod之間的隔離，最佳選擇是C選項：創建一個配置了sandbox類型為gvisor的GKE節點池。然後在客戶Pod的規格中添加runtimeClassName: gvisor參數。  題目：最大程度地增強客戶 Pod 之間的隔離性  A: 使用 Binary Authorization 並只將客戶 Pod 容器 image 列入白名單  ⇒ 雖然這可以控制容器映像的使用，但它無法提供足夠的隔離，因為它只控制了容器映像的可用性，而不是實際的運行隔離。  B: 使用 Container Analysis API 來檢測 Pod 使用 container 漏洞  ⇒ 只能用來檢測漏洞  C:  gvisor (輕量化的 container runtime 軟體，它是Google 設計用來增強容器的隔離性和安全性的軟體層。)，把 gvisor 配置成 sandbox ，能有效隔離應用程式  D: Container-Optimized OS（COS）也是提供了一些安全性措施，但它不提供 runtime 隔離     Your customer has implemented a solution that uses Cloud Spanner and notices some read latency-related performance issues on one table.\nThis table is accessed only by their users using a primary key.\nThe table schema is shown below."}]