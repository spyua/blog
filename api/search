[{"id":"content:0.code:1.Refcotr閱讀.md","path":"/code/refcotr","dir":"code","title":"重構筆記","description":"","keywords":["2019/11/13"],"body":"  重構筆記  2019/11/13   Lazy Class   別開創無所謂的Class(Ex 指宣告一個變數, Inline Class),邏輯資料相同可以使用繼承延伸,Super Class。要設計Class仙藥思考它的合理性。  Speculative Generality   在設計時，預留太多未來可能會用的擴充點。彈性使用Template模式，然後寫成介面，ConcreateClass去設計跟Imp。  遇到不能關閉的程式，要考慮好資源回收與OOM問題。\n   1.Collapse Hierachy  2.Inline Class  3.Remove Parameter  4.Remove Method  Temporay Field   Class欄位過多，在替代變數命名尚不清楚會讓開發者混淆，這是在開發過程中在需求還不清楚會常遇到，盡量避免這種狀況發生。  Message Chains(過度耦合訊息練)   Fun串Fun太多得意思....使用垂直折疊、提取或是使用委託與封裝，使用注入。  Middle Man(中間轉手人)   Class放與這個Class不相干的內容，邏輯提煉出來其他模組，或使用把功能寫成父類別繼承，或用注入盡量避免這件事情  Inappropriate Intimacy(互相依賴)   過度互相依賴，或是沒邏輯性的互相依賴(亂使用繼承)。 讀卡機讀取票卡例子(讀卡機，票卡自己也需判斷黑名單)。\n   1.可以定義一個卡片Interface(鎖卡，解卡，判斷)。此Interface讓讀卡機繼承，讓讀卡機注入...(依賴注入,RW定義一個介面，再去實作)  2.使用委託註冊介面. Call Back方式把有註冊過的方式拉進Class做處理。  Alternative Class with different Interface(異曲同工的類別)   做Extract SuperClass   Incomplete Libary Class(不完美程式庫類別)   如果要改一點類別庫直接修改，大改套模式..EX:套裝飾者模式,或使用繼承~~~ New程式碼直接延接  Data Class(純稚資料類別)   如果你有資料結構Class專門存取，很多Class會使用他，建議寫Get Set(c#直接產生)。  Refuesed Bequest(被拒絕的遺贈)   繼承錯誤.  Comments(過多的註釋)   包Package或好的命名可以避免"},{"id":"content:0.code:2.依賴注入(DI).md","path":"/code/(di)","dir":"code","title":"依賴注入(DI)","description":"DI在目前許多軟體架構中是不可或缺的設計架構功能之一，此章節會闡述DI精神及介紹.Net的DI使用。","keywords":["A. 依賴注入(Dependency Injection)","B. 容器概念","C. Ioc(Inversion of Control)控制反轉","D. C# DI 框架 [範例請點我]"],"body":"  DI在目前許多軟體架構中是不可或缺的設計架構功能之一，此章節會闡述DI精神及介紹.Net的DI使用。  A. 依賴注入(Dependency Injection)  先來講依賴跟注入的概念  a. Dependency  依賴如字面上所述，在軟體中，我們很常遇到物件彼此相依的狀況。如下圖，在做計算時需做Printer輸出資訊，因此Calculator物件會相依Printer物件，則在Instance Calculator物件時則就需要同步Instance Printer物件並帶入Calculator物件中。       public     class     Calculator\n   {\n         public     Printer     Printer   {  get  ;  private     set  }\n         public     Add  (  int     a  ,   int     b  ){\n             var     sum     =   a  +  b;\n           Printer.  ConsoleOut  (sum);\n       }\n         public     Calculator  (  Printer     printer  ){\n           Printer   =   printer;\n       }\n   }\n   public     class     Printer\n   {\n         public     void     ConsoleOut  (  string     txt  ) \n       {\n           Console.  WriteLine  (txt);\n       }\n   }\n   static     class     Program\n   {\n         static     void     Main  ()\n       {\n             var     printer     =     new     Printer  ();\n             var     calculator     =     new     Calculator  (printer);\n           calculator.  Add  (  1  +  1  ); \n       }\n   }  這例子為Calculator依賴Printer，所以控制權不是在Printer身上。什麼意思? 簡單來說當Printer有異動時，會有一定程度是影響到Calculator的。  對於物件依賴這件事情我在網上看到一個例子描述還蠻貼切的，今天有一名8+9在吸食毒品如下。8+9 以為自己吸食毒品只是滿足自己的快感，他還以為他自己的意志行為是被自己所掌控  錯!!!  其實8+9這時候所有的行為已經被毒品所控制，再也離不開毒品了。    b. Dependency With Interface  那我們該如何解除依賴關係? 一般來說，在實作方法時，我們會讓物件去相依介面，讓物件彼此因介面而解偶，如下圖       public     class     Calculator\n   {\n         public     IPrinter     Printer   {  get  ;  private     set  }\n         public     Add  (  int     a  ,   int     b  ){\n             var     sum     =   a  +  b;\n           Printer.  ConsoleOut  (sum);\n       }\n         public     Calculator  (  IPrinter     printer  ){\n           Printer   =   printer;\n       }\n   }\n   public     class     Printer  :  IPrinter\n   {\n         public     void     ConsoleOut  (  string     txt  ) \n       {\n           Console.  WriteLine  (txt);\n       }\n   }\n     public     interface     IPrinter  {\n         void     ConsoleOut  (  string     txt  );\n   }\n     static     class     Program\n   {\n         static     void     Main  ()\n       {\n             IPrinter     printer     =     new     Printer  ();\n             var     calculator     =     new     Calculator  (printer);\n           calculator.  Add  (  1  +  1  ); \n       }\n   }  因相依介面，若我們要抽換功能，例如原本的Console輸出改成輸出至記事本。只需要在新增一個記事本輸出方法，替換掉原本的28行的printer即可。而這狀況我們稱為Dependency Inversion Principle(DIP)，依賴倒轉原則。簡單來說就是解除高階模組和低階模組的依賴關係。   高低階模組定義   高階模組指的是呼叫者(Caller)-Calculator   低階模組就是被呼叫者(Callee)-Printer  我們再回到8+9例子，今天想要讓8+9改過向上，戒毒成為奮發向上的好青年。因為現在8+9直接依賴著毒品，我們讓8+9改成依賴藥品這個介面。    現在我們成功讓8+9依賴藥品而不是毒品。然後再將做一個健康食品的類別實作藥品，然後偷偷把毒品換成健康食品。這樣子8+9以為自己吃的藥品是毒品，實際上卻是每天吃健康食品，於是8+9頭腦變好了 走路也不晃了 考試也考100分成為國家的棟樑。  c. Injection  接著講注入，上述Calculator例子注入方式稱為建構子注入，其實注入平常我們就有在使用。一般人比較不會注意到這些行為其實就是一種注入。常見的注入模式有三種   建構子注入(Constructor Injection)  屬性注入(Property Injection)  方法注入(Method Injection)  建構子注入(Constructor Injection)     // 汽車的抽象介面\n   public     interface     ICar   {\n         // 行駛汽車\n         void     run  ();\n   }\n     // 司機的抽象介面\n   public     interface     IDriver   {\n         // 司機駕駛汽車\n         void     drive  ();\n   }\n     // 實作司機的抽象類別\n   public     class     Driver     implements     IDriver   {\n         private   ICar car;\n         // 建構子方式注入抽象類別\n         public     Driver  (ICar   car  ){\n             this  .car   =   car;\n       }    \n       @  Override\n         public     void     drive  () {\n           car.  run  ();\n       }\n   }  屬性注入(Property Injection)     // 汽車的抽象介面\n   public     interface     ICar   {\n         // 行駛汽車\n         void     run  ();\n   }\n     // 司機的抽象介面\n   public     interface     IDriver   {\n         // 司機駕駛汽車\n         void     drive  ();\n   }\n     // 實作司機的抽象類別\n   public     class     Driver     implements     IDriver   {\n         private   ICar car;\n         // 使用setter來傳遞物件 (c# get set)\n         public     setCar  (ICar   car  ){\n             this  .car   =   car;\n       }\n         \n       @  Override\n         public     void     drive  () {\n           car.  run  ();\n       }\n   }  方法注入(Property Injection)     // 汽車的抽象介面\n   public     interface     ICar   {\n         // 行駛汽車\n         void     run  ();\n   }\n    \n   // 司機的抽象介面\n   public     interface     IDriver   {\n         // 司機駕駛汽車\n         void     drive  (ICar   car  );\n   }\n       // 實作司機的抽象類別\n   public     class     Driver     implements     IDriver   {\n          // 使用介面來傳遞物件\n       @  Override\n         public     void     drive  (ICar   car  ) {\n           car.  run  ();\n       }\n   }   在了解Dependency與Injection後，應該就可以理解相依注入動作就在於在Instance物件後放置對應的相應物件中  B. 容器概念  上述DI概念講完後，接著我們要述說容器的概念。A章節提到關於相依的問題，雖然我們可以透過介面去作解偶。但一般在大型專案物件複雜度及數量一定會是更複雜的狀態。因此有了容器的機制設計產生。  容器的概念在於把物件全都收到一個盒子中，當要使用物件時再去盒子拿資料。有點像是打高爾夫球人員要打高爾夫時都會準備一個球袋把要用的球桿放進球袋中，並帶一個球僮陪伴在旁。當要使用哪一支高爾夫球桿時直接告訴球童即可。  a. 窮人與有錢人的依賴注入方式  上述講解完後，相信目前對相依注入及容器有一定的概念。而注入部分一般分成窮人注入與有錢人注入。   我們一般稱為Poor DI(Dependency Injection)，由使用者手動創建以new物件的方式，各自注入，除了麻煩外而且會有傳遞注入等等的問題。  有錢人的注入方式，我們一般都會使用DI容器來完成，由框架或類別庫撰寫的容器，提供物件給予使用者使用，猶如上述所講的球童跟高爾夫球員關係一樣。使用者只需要在撰寫程式前設定好物件後，就不需要在手動注入。  C. Ioc(Inversion of Control)控制反轉  窮人跟有錢人，我們當然選擇當有錢人!(使用DI容器)。若我們使用DI容器去管理我們物件時，此時我們即可達到控制反轉的設計。  簡單來說A物件程式內部需要使用B物件，程序需自行在A物件去new B物件。由程序主動去控制，有了容器，這一切交給容器去控制(新增物件流程)即可。  如果說DIP 是解偶物件之間的依賴，IOC 就是對物件依賴流程控制的反轉。以常見的web框架而言，將監聽http 請求，解析請求等，包裝進框架，一般使用者並不用主動去處理解析請求，處理http請求的流程，由主動處理轉交給了框架，因此，所以框架其實也是一種IoC的設計。   你可以將IOC是一種設計模式，將流程控制重定向到外部處理程序或控制器來提供控制結果，而不是透過控制項(大多情境就是程序)來直接得到結果  D. C# DI 框架   [範例請點我]  上述聊完後，相信對於DI、容器、DIP與IOC有一定認知。接著就需要進入實作部分。在.NET中最常見的DI有兩套如下   Microsoft.Extensions.DependencyInjection  Autofac  上述提到注入三種方式(建構子、屬性與方法)，Autofac都有提供，而ASP.NET DI的目前只有建構子注入方式。網上大多是Web範例，在此使用這兩套DI工具使用在DeskTop Windows From。  Microsoft.Extensions.DependencyInjection  範例DI設定在DIServiceConfigure.cs  注入服務生命週期型態  服務生命週期指：透過 DI 取得某個元件時，是每次要求得建立一顆新物件，還是從頭到尾共用一個 Instance (執行個體-物件)。   1.AddSingleton (單一性)  2.AddTransient (暫時性)  3.AddScoped (範圍性)  1. AddSingleton (單一性)  整個程序只建立一個 Instance，任何時候都共用它。簡單來說就是程序中不同流程使用此物件時，他都為同一份物件，有點像是Static，差在於使用DI可做物件設計及抽換。  下圖為Asp.Net DI生命週期圖示，物件相依關係由左至右。    而在範例模擬中設計，物件對應可視為   Rqeuest : Button_Singleton_Click 按下  第一個圈 : Call LogController  第二個圈 : Call LogController2  Instance : SingletonLogRepository  Repository注入部分我們使用AddSingleton，而物件在Instance時，我們會建置Guid去觀察他是否為同一個物件。         // 系統單一物件定義使用，或沒有異部與大量Request問題，可直接用Singleton\n   collection.  AddSingleton  <  ISingletonLogRepository  ,   LogRepository  >();  當我們按下Button_Singleton_Click時，會去呼叫LogController及LogController2裡的SingletonLogRepository物件。並印出Guid。     private     void     Button_Singleton_Click  (  object     sender  ,   EventArgs     e  )\n   {\n         //var provider = DIServiceConfigure.GetProvider();\n         //var logController = provider.GetRequiredService<ILogController>();\n         var     log     =     \"Log1(Singleton):\"  +  \"UUID-\"  +  LogController.  OperationId  (  \"Singleton\"  );\n         var     log2     =     \"Log2(Singleton):\"     +     \"UUID-\"     +   LogController2.  OperationId  (  \"Singleton\"  );\n       richTextBox_Info.  AppendText  (log  +  \"  \\n  \"  );\n       richTextBox_Info.  AppendText  (log2   +     \"  \\n  \"  );\n       richTextBox_Info.  AppendText  (LogController.  QueryLogCount  ());\n   }  此時我們可以看到兩個印出來的UUID會完全相同。代表在SingletonLogRepository在Controller與Controller2中為同一個物件。    2. AddTransient (暫時性)  定義上為程序中每次要求物件(包含物件要其他相依物件)時就建立一個新的，永不共用。  下圖為 Asp.Net DI生命週期圖示，物件相依關係由左至右。    而在範例模擬中設計，物件對應可視為   Rqeuest : Button_Transient_Click 按下  第一個圈 : Call LogController  第二個圈 : Call LogController2  Instance : TransientLogRepository  Repository注入部分我們使用AddTransient，而物件在Instance時，我們會建置Guid去觀察他是否為同一個物件。     // 異步，且須大量Request的建議使用Transient (WundowsForm簡易Sample較難模擬)\n   collection.  AddTransient  <  ITransientLogRepository  ,   LogRepository  >();  當我們按下Button_Transient_Click時，會去呼叫LogController及LogController2裡的SingletonLogRepository物件。並印出Guid。     private     void     Button_Transient_Click  (  object     sender  ,   EventArgs     e  )\n   {\n        // 模擬多次Request\n        //var provider = DIServiceConfigure.GetProvider();\n        //var logController = provider.GetRequiredService<LogController>();\n        //var log = \"Log1(Transient):\" + \"UUID-\" + logController.GUID.ToString();\n        //richTextBox_Info.AppendText(log + \"\\n\");\n              // 單次Request\n        var     log     =     \"Log1(Transient):\"     +     \"UUID-\"     +   LogController.  OperationId  (  \"Transient\"  );\n        var     log2     =     \"Log2(Transient):\"     +     \"UUID-\"     +   LogController2.  OperationId  (  \"Transient\"  );\n      richTextBox_Info.  AppendText  (log   +     \"  \\n  \"  );\n      richTextBox_Info.  AppendText  (log2   +     \"  \\n  \"  );\n          //richTextBox_Info.AppendText(LogController.QueryLogCount());\n   }  此時我們可以看到兩個印出來的UUID會不相同。代表在TransientLogRepository在Controller與Controller2中為不同物件。    上述模擬範例其實只模擬一個Request1的狀況。根據定義，程序中每次要求元件時就建立一個新的物件，對此我們已再按多次Button來做模擬。要模擬這狀況，就需要再跟Container拿取Controller物件，在範例中Controller與Controller2都是注入AddTransient，我們將模擬多次Request區塊註解打開，並註解單次Request程式碼     private     void     Button_Transient_Click  (  object     sender  ,   EventArgs     e  )\n   {\n         // 模擬多次Request\n         var     provider     =   DIServiceConfigure.  GetProvider  ();\n         var     logController     =   provider.  GetRequiredService  <  LogController  >();\n         var     log     =     \"Log1(Transient):\"     +     \"UUID-\"     +   logController.GUID.  ToString  ();\n       richTextBox_Info.  AppendText  (log   +     \"  \\n  \"  );\n           // 模擬單次Request\n         //var log = \"Log1(Transient):\" + \"UUID-\" + LogController.OperationId(\"Transient\");\n         //var log2 = \"Log2(Transient):\" + \"UUID-\" + LogController2.OperationId(\"Transient\");\n         //richTextBox_Info.AppendText(log + \"\\n\");\n         //richTextBox_Info.AppendText(log2 + \"\\n\");\n           //richTextBox_Info.AppendText(LogController.QueryLogCount());\n   }  此時我們可以看到每次的UUID就會不相同，代表在Controller在每次跟Container拿取時都為不同物件。相對的，注入其他物件時也是同一個狀況。    3. AddScope  (範圍性)  Scope我覺得是最難了解的，直接看 Asp.Net DI生命週期圖示，物件相依一樣關係由左至右。如圖所示，程序中要求物件(包含物件要其他相依物件)時，這個Flow處理過程中用到的物件則為同一個物件。而第二次再次要物件時，則會跟第一次的物件是不一樣的物件。    我們已Call Dialog方式去模擬多次Request，程式碼這邊不多做解釋，結果與物件對照如下圖，觀察Instance部分物件分別為   SingletonLogRepository  TransientLogRepository  ScopedLogRepository  可以看到ScopedLogRepository，在同一次的Request Flow，LogController與LogService的LogRepository UUID為一樣的，但在第二次打開Dialog時，則UUID會與第一次的不同。這點會跟Singleton有很大的不同。  在此我們也可以看到Transaction則是在每個物件中，及每次Request都為不同UUID。    其實Scoped跟Transaction之間有時候蠻容易混淆的。對我來說比較好懂得在於Scoped在跟Container要物件時，若前一個物件還未dispose(生命週期還未結束)，則都是同一個物件。物件結束生命週期後在新的Request後才會在新增新的物件。而Transaction就無生命週期概念，在每一次要求物件時，都會New一個新的給他，有點像平常我們想用物件就New Instance的概念。  生命週期小結論  上述描述完後，沒意外應該會對注入的生命週期會有所了解。而在Web的世界中，這三種注入方式會很常被使用到。在每一次Http Request情境，Request具有連線即結束，在這狀況下的連線相關物件基本上就會使用Scoped，因此在Web情境，大多數物件都會使用Scoped注入。  但WindowsForm App下，其實我們最常使用的會是Singleton居多，其次是Transaction，Scoped狀況就比較少，因為WindowsForm一開始畫面就那些就載入到 memory中，除非我們將畫面dispose掉，然後再重新開啟畫面，此時就會建議使用Scoped注入。  Transaction使用場景比較會偏向用後就直接dispose，不過這種應用場景，我們很常直接手動去new物件.實際架構應用上目前我也沒太多經驗。  注入抽換  生命週期講完後，接著就是闡述關於抽換實體物件。範例中我們使用IPrinter注入抽換PrinterMethodA與PrinterMethodB。  在一開始我們IPrinter注入為PrinterMethodA，在按下button_Printer_Click按鈕時，Console則會印出MethodA Print:Prionter Out    此時我們將PrinterMethodA改成PrinterMethodB     collection.  AddTransient  <  IPrinter  ,   PrinterMethodB  >();  此時在按下button_Printer_Click按鈕時，Console則會印出MethodB Print:Prionter Out    另外我們也可以注入IPrinter List，只要注入多Concreate實體     collection.  AddTransient  <  IPrinter  ,   PrinterMethodA  >();\n   collection.  AddTransient  <  IPrinter  ,   PrinterMethodB  >();  就可注入多PrinterMethod方法     private     LogController     LogController  ;\n   private     LogController2     LogController2  ;\n     // 多重注入\n   private     IEnumerable  <  IPrinter  >   Printer  ;\n     public     Form1  (  IEnumerable  <  IPrinter  >   printer  ,\n                  LogController     logController  , \n                  LogController2     logController2  )\n   {\n         InitializeComponent  ();\n       LogController   =   logController;\n       LogController2   =   logController2;\n         // 多重注入\n       Printer   =   printer;\n   }    我們只須改Container設定，主程式都不用更動，即可抽換程式中所有物件用到IPrinter的地方。  AutoFac  範例DI設定在AutofacConfig.cs  AutoFac與 ASP.NET DI 注入生命週期概念其實大同小異，下圖為對應表  出處    根據對應表，在範例程式要換成Autofac範例，只需將Bootstrapper與Form.cs裡Button_Scoped_Click的Net DI程式碼註解掉，並解開Autofac註解相關程式碼。即可觀察注入物件生命週期的不同。  .github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-762058{color:#6F42C1;}.dark .ct-762058{color:#B392F0;}.ct-617022{color:#005CC5;}.dark .ct-617022{color:#79B8FF;}.ct-086898{color:#6A737D;}.ct-157101{color:#E36209;}.dark .ct-157101{color:#FFAB70;}.ct-952708{color:#032F62;}.dark .ct-952708{color:#9ECBFF;}"},{"id":"content:0.index.md","path":"/","dir":"","title":"Home","description":"","keywords":[],"body":"     Hakuna Matata.   I am a dedicated learner, and together with my friend, we have formed a team called Code Sense in Kaohsiung. We engage in research and study on a weekly basis, with a passion for learning new technologies and skills.Continual learning is the driving force of my life.     8-9 years of software development and maintenance experience  3-4 years of experience in automation domain development  1-2 years of experience in department software training and management  Familiar with integration and connection of various factory systems (  MES ,   WMS ,   PLC )  Proficient in web system front-end and back-end development and database design  Well-versed in measurement instrument and motor PC Base control (  RS232 ,   ModBusTCP ,   EtherCAT )      My Personal Moments.      Reading Blog   Regular Reading and Public Journal of Thoughts and Moods.[  Medium ]    Code Sense Trello   Regular Study and Discussion Sessions with Friends.\n[  Code Sense Trello ]    Slider   My Presentation Slides.[  Slider Link ]    Technical Documentation   Regular document writing and temporary storage.[  Hackmd ]"},{"id":"content:1.architecture:1.DDD實戰-Module.md","path":"/architecture/ddd-module","dir":"architecture","title":"DDD實戰-Module","description":"","keywords":["一、關於Module","二、構成Module考量五要素","三、Package Vs Module","四、一般Module設計方法","五、未使用DDD的一般Service服務設計","六、在DDD世界中的Module設計","補充","參考"],"body":"  DDD實戰-Module  一、關於Module  在闡述Module前，讓我們先來比對非物件化設計與物件化設計的差異性。看到下圖左，在非物件化的傳統設計，資料與方法操作上是整個拆開設計，在資料流複雜外我們可以看相依性高，偶合的狀況也較高。  接著討論物件化設計部分，先不論封裝等物件操作技巧，單純根據資料與方法關係設計出物件(物件特性:資料(Data) 物件行為:方法(Function))，我們可以看到原本互相依賴的Fun關係可各自獨立使用，在資料流上也較為單純。    物件化後，雖然在資料操作面上簡化許多，但隨著專案功能性逐漸增加，物件與功能處理流程上會趨近越複雜，如下圖為一個簡易的系統，此系統根據外部Sensor系統獲取、過濾與計算資料，在沒模組化的設計前提，可以看到Control與Data Flow呈現一個較零散的關係狀態    此時我們根據Sensor功能額外設計一個Sensor模組如下，此時我們就可以針對Sensor相對應的資料模組將之封裝在模組內，此模組對外則就單純開放運算(calculation)與過濾(filtering)的功能。  模組化後可以明顯看出控制與資料流的彼此相依性值，因此降低了修改與擴充狀況的互相影響性值。    模組化指是將  系統功能程序作分離獨立(特定功能class的容器) ，除了功能獨立外，也強調設計上可以根據功能隨意抽換模組。達到高內聚、低耦合的目的，進而提高開發者的生產力(將複雜的功能拆分管理)。並讓程式碼能夠透過引用的方式來重複使用，提升重用性(Reusable)   Modular design allows code to remain agile in the face of ever-changing requirements.   二、構成Module考量五要素   Propose:Module功能目標單一職責，盡量不要與其他模組設計有太多相依關係。  Interface:模組功能API所提供使用方式要簡潔易懂，通常User不需要去了解實際內部的實作方式，只需專注在確定輸入什麼，會輸出什麼可達到什麼功能。  Encapsulation:封裝模組，除了讓不暴露資料結構讓使用者亂使用外，對於在修改細節上也能較不容易直接影響使用端。另外再使用抽象實作上，物件抽象化多少還是難以避免Leaky Abstractions的問題。  Implementation:實作上除了考量功能正確性外還需考慮效能、測試與功能架構程式碼最小化。  Connection(關聯性):呼應Propose功能單一職責，將與其他模組相依性最小化。   三、Package Vs Module  在了解Module構成要素後~隨著專案模組(Module)的增加，將難以管理及問題的追蹤，這時候就能將模組(Module)打包成套件(Package)，利用其階層式的結構來彈性規劃模組(Module)。   Module:單一功能模組  Package:多Module組成  四、一般Module設計方法  在非以領域事件為出發點的設計上，大部分狀況會根據功能設計成物件與介面使用。下圖為Zebra SDK Package的Module列項，我們可以大致分得出，他的Module設計就是根據功能性值去區分(graphics, certificate...)    接著我們點近discovery看提供什麼API功能，可以看到可以使用的介面功能以及相關功能可使用的功能物件。    在點進個別更詳細功能介紹，我們就會看到這物件功能具有什麼資料特質、物件實體化須提供什麼參數以及此物件可使用哪些方法。   Field: address，IP or Mac Adress  Constructor:物件實體化須提供印表機的IP or Mac Adress  Method:可使用的物件功能，在此例看起來需實作getConnection功能    上述為印表機找到印表機裝置功能的模組化介紹   五、未使用DDD的一般Service服務設計  上述一般Module設計概念聊完，在聊DDD Module設計之前先來聊一下在一般未使用DDD領域設計的服務系統會如何設計。  在對大部分的開發者，一開始習慣設計都以數據為考量的集中式設計架構。設計架構上會出現比較常見到的分層式設計，大致分成Controller, Service, Repositories, Models   xxx/Model\n   數據庫Model、Request Model, Response Model  xxx/Controller\n   給Client端的API第一時間接口，提供Get,Post,Delete,Update API。除了此在此層一般都會安插屬性驗證Client第一時間傳過來的資料是否正確。並作實際的DTO(Object 與DB Model Mapping)轉換。  xxx/Service\n   這層基本上就是作商業邏輯的處哩，進到此層的資料基本上都是做完DTO轉換，在此層通常會作實際的資料邏輯處理處理完後再往DB方向送。  xxx/Repositorie\n   DataSource(DBContext)上一層，一般會除了實際面DataSource讀寫變更操作外，Source 資料Join處理也會在此層處理。一般多這一層都是為了隔開DataSource的來源切換，不管置換不同的DB系統，或是Source改成Shared Prefs，都可快速置換資料來源。     六、在DDD世界中的Module設計  上述稍微帶過Module的設計概念後，接著探討在DDD世界裡，Module的設計概念如何~大致分成幾個探討議題  1.DDD設計步驟流程     在探討需求架構DDD設計的第一步，就是根據需求情境列出事件風暴(Event storming)，並在事件風暴中的用戶操作、事件、以及依賴關係根據這些要素設計歸納出領域與實體。  接著第二步在領域實體之間找尋彼此務的關聯性，將具有相關的實體組合成聚合(Aggregate)，同時確定聚合根(Aggregate Root)。在聚合根行程時，基本上第一層邊界(邏輯邊界-虛線)也會跟著產生，他們會在同一個服務器中運行。  當聚合規劃好後~會根據業務及語意邊界等因素，將一個或多個聚合規劃訂製在一個限界上下文內(服務邊界)，形成領域模型。    2.程式碼一級目錄架構     Interface(API Interface)\n   給使用者API介面，使用者透過Restful請求，將資料傳到此層，解析用戶傳送的請求資訊，資料的組裝、資料傳輸格式以及 Facade 介面等代碼都會放在這一層目錄裡。  Application\n   他有點像是原先集中式設計Service的功能，實作所有相依於指定前端之使用案例的地方。 例如，與 Web API 服務相關的實作。若使用的是 CQRS 方法，它便會包含查詢、微服務接受的命令，甚至是微服務之間的事件驅動通訊 (整合事件)。  Domain\n   它主要存放領域層核心業務邏輯相關的代碼。領域層可以包含多個聚合代碼包，它們共同實現領域模型的核心業務邏輯。聚合以及聚合內的實體、方法、領域服務和事件等代碼會放在這一層目錄裡。  Infrastructure\n   它主要存放基礎資源服務相關的代碼，為其它各層提供的通用技術能力、三方套裝軟體、資料庫服務、配置和基礎資源服務的代碼都會放在這一層目錄裡。  3.在DDD Module準則  例子:如何對電商平台上的顧客進行模塊設計  對於顧客來說，一般須要維護顧客的   個人訊息  收穫地址  付款方法  這三個之間的關係是緊密相關，不可獨立存在，我們根據這三點抽象出三個Aggregate   Customer 個人訊息  AddressBook 收穫地址  Wallet 付款方法  那該如何去放置這些Aggregate，是針對每一個Aggregate作資料夾分類還是這三個Aggregate放同一格資料夾?基本上這三個Aggregate就是一個Custer Module，所以都會放到Custer Module資料夾內。    當整理出Aggregate與Module後，接著會開始根據各Module去實作事件應用處理  基本上我們在DDD模塊的設計上有幾個注意要點   Module應該要和Domain概念一致:一般一組聚合集成(領域)，我們會相對應建立一個Module。  根據通用語言來命名:模組命名要一眼就看出這是在做什麼的。  模組設計盡量鬆偶合:盡量與其他模組不要有太多的偶合，若有也許在領域設計上還沒切得很乾淨。  如果有PeerModule或父子Module出現，盡量避免循環相依。  4.關於Module命名    5.Module界線與限界上下文不同  為了對領域模型中進行準確建模，需要將領域模型劃分成多個子域，每個子域對應一個或多個限界區域。 模塊。所以，從子域到限界某些再到模塊，應該是依次包含關係。  補充  補充一   Abstracion:\n   將真實世界物體與事件的大量資訊縮減一個概念或是一個現象的資訊含量來將其廣義化，保存和一特定目的有關的資訊。例如，將一個皮製的足球抽象化成一個球，只保留一般球的屬性(形狀)和行為(滾)等資訊。  Leaky Abstractions\n   所有非不證自明的抽象概念，都有某種程度的疏漏。例如TCP雖簡化(抽象化)網路行為，設計上也保證網路傳送過程中不遺漏資訊，但不保證就真的能完整傳到資訊，例如我們無法避開海底電纜被魚咬斷因此斷訊的狀況。  參考   範例  The 5 Essential Elements of Modular Software Design  The Law of Leaky Abstractions  The Three Principles of Excellent API Design  解析Python模組(Module)和套件(Package)的概念  Module Design   Domain Events vs. Integration Events in Domain-Driven Design and microservices architectures   DDD理论学习系列（13）-- 模块   DDD理论学习系列——案例及目录"},{"id":"content:1.architecture:2.DDD-簡易整理.md","path":"/architecture/ddd","dir":"architecture","title":"DDD實戰-簡易整理","description":"","keywords":["一、回顧","二、何謂Entity,如何定義他","三、跟ValueObject有何不同","四、如何產出 Entity Id?","五、.NET Core 實作微服務領域模型"],"body":"  DDD實戰-簡易整理  一、回顧  (DDD) 重點在於協助您在使用案例相關的商務實際情況下建立模型，然後根據Domain定義後續不同的Context與彼此的對應關係，再與事件驅動方式實際實現。  書中所提例子 : 電商系統，人員瀏覽商並下訂後交易。   定義Domain\n   根據問題空間與解決方法定義出Domain\n   Core Domain :產品最有價值部分 (Ex AI 推薦購買商品需求)  Supporting Subdomain : 未提供核心競爭力，但支援核心所需功能 (Ex 購物需求)  Generic Subdomain : 未提供核心競爭力，但整個系統都可能會用到它 (Ex 身份認證需求、金流串接)      根據語意(Linguistic)與業務能力(Business Capability)定義BoundContext   重點一、通常識別 Bounded Context 會由兩點下手：語意(Linguistic)與業務能力(Business Capability)。  電商例子(語意-業務能力)   登入-帳號管理 => 身分管理Context (Identity)  商品-商品選擇 => 商品目錄Context (Catalog)  下購-購買功能 => 選購Context (Purchase)  重點二、注重業務能力勝過資料分類 (習慣性地用資料表去起始設計系統，甚至把業務邏輯與 ORM 框架綁在一起。這麼一來容易造成物件乘載太多的責任，比如說「顧客」是屬於「會員管理系統」還是屬於「購物系統」？)  Context定義出後，根據幾種方法(設計模式，或撰寫程式技巧)去做Context Mapping    - Shared Kernel\n - Partnership\n - Anti-corruption Layer\n - Open Host Service/Published Language\n - Separate Way\n - Big Ball of Mud\n - Customer-Supplier\n - Conformist\n     使用或設計軟體架構最小化建置與維護「需求系統」所需要的人力資源。\n   軟體的架構與功能需求沒有關係  軟體架構是非功性需球 Non-Funcitonal Requirement (系統達成的任務的能力)  常見軟體架構大概有這些類型：\n   MVC  MVP  Layered Architecture  Client Server  Microservice  Event-Driven Architecture  Pipe-Filter  MVVM  DDD 不等於 Clean Architecture，兩者關注的面向不同。DDD 的主要目的是將軟體的模型更貼近業務需求，架構只是為了達到目的的工具。     二、何謂Entity,如何定義他  根據電商前面例子, 身分管理、 商品目錄與選購中，你覺得什麼是Entity?  顧客、訂單、商品等等。這些物件不被他們的屬性所辨識(比如年齡、金額)，而是由一個專屬的身份標誌 (Identity)來辨識。這種時候，我們就需要 Entity 的幫助讓我們在不同的物件中找到我們要的那一個。  Entity 最大的特徵就是有 Identity 的概念，所以常會搭配一個擁有唯一值的 ID 欄位。但這邊要澄清一個誤解，不是有 ID 就是 Entity，重點是你在不在乎他生命週期的變化。  Entity具有幾個特徵   具有唯一值ID  具有狀態  生命週期有可能無限長  一個 Entity 是可變的、長壽的，所以通常會有複雜的生命週期變化，如一套 CRUD 的操作  不只會實作資料屬性，還會實作具有相關領域邏輯的作業或方法  實體代表領域物件，而且主要是由其身分識別、連續性及一段時間的持續性所定義，而不只是由包含這些項目的屬性所定義。 如同 Eric Evans 說，「主要由其身分識別定義的物件稱為「實體」（Entity）。 實體在領域模型中很重要，因為它們是模型的基礎。  已Order訂單為例子   訂單ID  訂單屬性(ID,Name,Address)  訂單操作Method(EditName, EditAddress)    三、跟ValueObject有何不同   當一個物件沒有概念上的標識 (conceptual identity)，而你只關心它的屬性時，這個物件就可以建立成 Value Object。  Value Object 的屬性都是為了要描述某一個事物的特徵。  判斷這兩者的標準就在於系統在不在乎這個物件的生命週期變化。      四、如何產出 Entity Id?   1. 來自用戶的輸入  這是一個非常直接的做法，比如使用用戶的 email 或是身分證字號等等作為 ID，但也容易造成額外的成本。最大的成本就在於，你需要由用戶負責產生符合需求的身份認證資料非常困難。此時的 ID 可能是唯一的，但卻有可能是不正確的。  甚至，身分證字號也有重複的可能性。  因此，我們可以將用戶輸入的資料作為 Entity 的屬性。這些屬性可以用來做搜尋用，但大多時候並不適合作為 Entity 的 ID。   2. 使用持久化機制來產生  最常見的就是使用資料庫自動生成 ID，最常見的就是 SQL 對 ID 下 AUTO_INCREMENT 讓 ID 的值自動遞增。又或者也可以向資料庫索取一個 UUID (或 GUID) 作為 ID 的值。  這樣的做法好處是可以減少程式的複雜性，直接把產生的工作交給持久化機制處理。但也容易招致效能問題的疑慮(UUID/GUID 的產生)。而且當你無法從程式碼找出 ID 的生產機制時，也會增加程式碼的隱含性不利於閱讀。  另外，使用持久化機制時，也需要特別考量這個 ID 的生成應該要在該物件持久化 (ie 存入資料庫) 之前或是之後，以配合程式的需求。  註：這裡會使用「持久化」一詞是因為儲存資料的方式不止資料庫一種，故用更通稱的方式描述。   3. 在程式中產生  在程式中產生 ID 是最常見的方法之一，這種方法好處是可以更容易掌握生產的時機，此外，更可以客製化你的 ID 格式，比如一筆訂單你可以用 order-20190930-c764e787-8182 作為 ID，如此一來，在 debug 時就不用被一堆天文數字般的 ID 搞得昏頭脹腦。所以以個人經驗來說，即使增加了一點複雜度，會最推薦這個方式。   4. 由另一個 Bounded Context 提供  最複雜的一種就是來自於另一個 Bounded Context 提供的 ID。這種可能出現在當你需要調用 API 的時候，得到對方的資料後存取下來。這種方式的複雜點在於，你不只要考慮本地端的 Entity，也需要考慮外部 Bounded Context 的改變情況，雖然可以透過訂閱另一個 Bounded Context 的方式做到，但仍舊十分麻煩。  五、.NET Core 實作微服務領域模型      參考 :\n  https://ithelp.ithome.com.tw/articles/10223150  https://docs.microsoft.com/zh-tw/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/microservice-domain-model  https://docs.microsoft.com/zh-tw/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/ddd-oriented-microservice"},{"id":"content:2.desktop:1.WindowsForm找不到類型xxxx上的建構涵式.md","path":"/desktop/windowsformxxxx","dir":"desktop","title":"WindowsForm找不到類型xxxx上的建構涵式","description":"","keywords":["情境","錯誤訊息","解決方法"],"body":"  WindowsForm找不到類型xxxx上的建構涵式  情境  近期在設計DeskTop頁面時有遇到幾個頁面基底邏輯相同的狀況，於是特別設置Base Page去讓UC繼承使用。因為頁面其實長差不多，所以最後決定不使用參考引用而直接使用繼承。  讓A(UC_3Dswitch_CalibrationFileManagement)繼承B(UC_3Dswitch_FileManagementBase)。  錯誤訊息  編譯上都沒有問題，但此時再使用Design模式時，發生找不到類型錯誤如下    解決方法    宣告無注入空的建構子，       // 宣告無注入空的建構子\n   public     UC_3Dswitch_FileManagementBase  ()\n   {\n     }\n   public     UC_3Dswitch_FileManagementBase  (  AppSetting     appSetting  ) \n   {\n       ProductLineDataPath   =   appSetting.ProductLineDataPath;\n       SNFolderNameLength   =   appSetting.SNFolderNameLength;\n         InitializeComponent  ();\n   }  因原先Base設定注入所宣告AppSetting物件，故發生上述無法載入錯誤。看起來Deisnger模式在Control物件使用上Defaul都是預設空的建構子設置。  .github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-086898{color:#6A737D;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-762058{color:#6F42C1;}.dark .ct-762058{color:#B392F0;}"},{"id":"content:3.cloud-gcp:GKE.md","path":"/cloud-gcp/gke","dir":"cloud-gcp","title":"GKE","description":"GKE為GCP提供的SAAS等級的kubernetes服務。相對於自行架設kubernetes運行環境簡化了許多建置部屬、管理及擴展設定的工作。以SAAS提供kubernetes容器平台服務的優點如下","keywords":[],"body":"  GKE  GKE為GCP提供的SAAS等級的kubernetes服務。相對於自行架設kubernetes運行環境簡化了許多建置部屬、管理及擴展設定的工作。以SAAS提供kubernetes容器平台服務的優點如下   容易上手 : Google對kubernetesr進行封裝及抽象，使用者不需要了解底層細節即可上手。能直接透過介面操作達到快速部屬與管理設定。不然一般許多部份都需要自己做相關起建，例如..\n   介面需安裝相對應的工具並做設定才可  版本升級修補需人為去維護  需自行安裝與配置監控與日誌工具  安全性設定  資源設定擴展需自行維護"},{"id":"content:4.database:1.MSSQL使用指令測試Server硬碟速度小技巧.md","path":"/database/mssqlserver","dir":"database","title":"MSSQL使用指令測試Server硬碟速度小技巧","description":"","keywords":["讀取速度","寫入速度"],"body":"  MSSQL使用指令測試Server硬碟速度小技巧  讀取速度  選抽一個資料庫 下BACKUP DATABASE指令，備分資料庫不做寫入，只做讀取，可得到讀取速度值。     BACKUP     DATABASE   [FUXIN_CPL]   TO     DISK     =  'NULL'     WITH     COPY_ONLY    下圖可看到結果每秒讀取速度為180MB/sec    寫入速度     BACKUP     DATABASE   [FUXIN_CPL]   TO     DISK     =  'C:\\TEST.BAK'     WITH     COPY_ONLY  此時會得到讀寫時間為每秒153MB    每秒153MB為讀寫時間，此時須作運算處裡將寫入時間算出  讀取總頁數共688頁，一頁8k => 688*8.0 / 1024 = 5.375M  寫入時間為 0.035-0.03 = 0.005  5.375M/0.005 = 1075M  .github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-952708{color:#032F62;}.dark .ct-952708{color:#9ECBFF;}"},{"id":"content:5.keycloak:1.身份驗證與授權與Keycloak.md","path":"/keycloak/keycloak","dir":"keycloak","title":"身份驗證與授權與Keycloak","description":"","keywords":["一、關於身份驗證與授權"],"body":"  身份驗證與授權與Keycloak  一、關於身份驗證與授權  身份驗證和授權是系統安全性非常重要的環節。身份驗證用於識別使用者是誰，而授權則賦予使用者某些特定權限。更具體來說，這整個過程可以分為四個部分：   身分識別 (Identification)：這是一個讓系統知道你是誰的過程。例如，當你使用用戶名或電子郵件地址登入系統時，就是進行身分識別。  身分驗證 (Authentication)：這個過程讓系統確認你確實是你聲稱的那個人。通常是通過輸入密碼、使用FaceID或OTP來完成的。  授權 (Authorization)：這涉及到角色分配。根據你的角色，系統會賦予你不同的權限。例如，一個“編輯者”角色可能有編輯內容的權限，而一個“閱讀者”角色則只能閱讀。  存取控制 (Access Control)：這涉及到具體的操作權限。比如，在一個IT管理系統中，一個普通使用者可能可以重啟伺服器和查看系統日誌，但不能部署新的程式碼。然而，一個開發者則可能有這樣的權限。  在你登入系統，輸入帳號密碼為身分識別與身分驗證，系統驗證完後，會根據身分授予角色。至於此角色權限則可以在後台系統上設置。至於這部分的詳細實做概念牽扯還是蠻多的...會再找時間針對這部分做一個細部講解。  1. 身分識別驗證與授權簡易實作  了解這些基礎概念後，我們可以考慮如何手動實現這四個部分。   身分識別 (Identification) : 最常見的實現方式是透過一個使用者註冊頁面，讓使用者輸入基本資料，例如用戶名和密碼。這些信息會被存儲在後端的資料庫中（密碼會被加密）。  身分驗證 (Authentication) : 驗證的方法有多種。   密碼驗證 : 簡單地說，就是將輸入的密碼與資料庫中存儲的密碼進行比對。  多因素驗證 : 二次驗證，例如OTP、FaceID，或是手機&Mail驗證  Session/Token管理 : 用戶登入後，系統會生成一個session或token並發送給用戶。後續的所有請求都需要這個token以確認身份。  授權 (Authorization) : 這部分簡易實作基本上會有三部份   角色管理：在資料庫中設計一個角色和權限的模型。例如，每個使用者可以有一個或多個角色，每個角色有不同的權限。  權限檢查：每次使用者請求某個資源或操作時，檢查他們的角色是否有相應的權限。  API設計：設計API時，確保每個API端點都有適當的授權檢查。  存取控制 (Access Control)   基於角色的存取控制 (RBAC)：根據使用者的角色決定他們可以訪問的資源。  細緻的權限設定：允許系統管理者為每個角色定制細緻的權限，例如某角色只能讀取資料但不能編輯。  其他考慮   日誌和監控：記錄所有的登錄嘗試、授權請求等，以便日後分析和審計。  資料庫安全性：確保資料庫有適當的加密和備份策略。  定期檢查和更新：隨著時間的推移，可能會出現新的安全威脅。定期檢查和更新你的身份驗證和授權策略，以確保它們始終是安全的。  2. 身分識別驗證、授權與Keycloak  通過使用Keycloak，我們能夠更為高效地實現身分識別、身分驗證、授權，以及存取控制等功能。   身分識別 (Identification)   不僅提供使用者註冊功能，讓使用者可以用基本資訊，比如用戶名或電子郵件進行註冊，還支持多種社交登入方式，如Google或Facebook。  身分驗證 (Authentication   支援多種身分驗證方法，包括密碼、OTP、FaceID等，也提供Token管理，當使用者成功登入後，Keycloak 會發放一個 token，使用者可以使用此 token 來存取其他受保護的資源。  授權 (Authorization)   可以定義多個角色，並為每個角色分配不同的權限，使用者可以被分配到一個或多個角色，這些角色決定了使用者可以訪問哪些資源。  存取控制 (Access Control)   支援基於角色的存取控制 (RBAC)。你可以設定哪些角色可以訪問哪些資源。  一般來說，要全面實施這四大功能通常需要大量的時間和資源。開發者不只需要寫大量的程式碼，還必須維護系統的安全性、效能，並確保與其他系統的良好整合。有了Keycloak，這一切都變得相對簡單。"},{"id":"content:5.keycloak:2.OIDC與SAML.md","path":"/keycloak/oidcsaml","dir":"keycloak","title":"OIDC vs SAML","description":"在這部分，我們將探討OIDC和SAML。正如前一章節所提，身分驗證和授權是整個安全流程中非常關鍵的環節。一般來說，會有專門的解決方案來處理這些問題。OIDC和SAML都是為這個目的而設計的標準協議，它們提供一個集中式的方法來驗證使用者身份，並界定他們可以訪問哪些資源或執行哪些操作。","keywords":["1. Open ID Connect (OIDC)："],"body":"  OIDC vs SAML  在這部分，我們將探討OIDC和SAML。正如前一章節所提，身分驗證和授權是整個安全流程中非常關鍵的環節。一般來說，會有專門的解決方案來處理這些問題。OIDC和SAML都是為這個目的而設計的標準協議，它們提供一個集中式的方法來驗證使用者身份，並界定他們可以訪問哪些資源或執行哪些操作。  1. Open ID Connect (OIDC)：  OIDC是一個建立在OAuth 2.0之上的身分認證層。OAuth 2.0本身是一個專注於授權的框架，而OIDC則在這個基礎上增加了身分驗證功能。這樣，應用程式不僅能知道使用者有哪些權限，還能瞭解使用者是誰，並獲取他們的基本資訊，比如名稱和電子郵件地址。  a. OAuth 2.0  OAuth 2.0 是一個授權框架，允許第三方應用程式在使用者同意的情況下存取使用者在某個服務上的資訊，而不需要分享使用者的密碼。通常在OAuth 2.0，會有幾個角色，我們這邊舉一個簡單情境，你希望使用「快速日記」App，而這個App提供使用Google帳戶登入的功能來使用Google雲端硬碟服務。   Resource Owner(資源擁有者) : 通常就是User(你)， 能授予應用程式取得受保護資料的人，通常就是終端使用者（end-user）。例如你希望使用「快速日記」App，而這個App提供使用Google帳戶登入的功能。在OAuth的流程中，當App請求許可存取你的資料時，你會給予（或拒絕）這個請求。  Resource Server(Resource Server) : 存放使用者受保護資料的伺服器，以這個例子來說就是Google雲端硬碟，當「快速日記」App希望保存或讀取日記時，它會向此伺服器提出請求。  Client (客戶端)：通常指稱想要取得受保護資源的「應用程式」，以這個例子來說就是「快速日記」App。 當「快速日記」App希望保存或讀取日記時，它會向此伺服器提出請求。  Authorization Server (授權伺服器) : 驗證 Resource Owner 的身份，並且在獲得同意之後，發放「Access Token」給應用程式（Client）的伺服器。以這個例子來說就是 (Google的授權伺服器)。  下圖整個驗證Flow  \n   驗證Flow     Client 到 Resource Owner :   Request Credentials : 當你打開「快速日記」App並選擇使用Google帳戶登入時，App首先會引導你到Google的登入頁面。  Authenticate : 你將在Google的頁面上輸入你的Google帳戶憑證，即用戶名和密碼。這一步是由Google完成的，而「快速日記」App不會看到或知道你的密碼。  Consent : 一旦驗證成功，Google會顯示一個請求同意頁面。在這裡，Google會詢問你是否允許「快速日記」App訪問特定的Google帳戶資料。  Credentials : 「Resource Owner」（使用者）提供的身份資訊或某種用於辨識其身份的資料。這只是一個授權請求，而實際的身份驗證會在Resource Owner和Authorization Server之間完成。    Client 到 Authorization Server   Authorization Request : 如果你同意上述的權限請求，「快速日記」App會從Google的授權伺服器請求一個授權碼。  Authorization Code : Google的授權伺服器會回傳一個短暫的授權碼給「快速日記」App。  Access Token : ，「快速日記」App會使用這個授權碼再次向Google的授權伺服器請求取得訪問令牌（Access Token）。    Client 到 Resource Server   Access Token: 一旦取得訪問令牌，「快速日記」App便可以使用此令牌來存取Google雲端硬碟（或其他你同意的資料）。  Protected Resource: 當「快速日記」App希望保存或讀取日記時，它會使用這個Access Token向Google雲端硬碟（作為資源伺服器）提出請求，然後Google雲端硬碟會根據該令牌提供相對應的資料或服務。  更詳細的其實還有關係到Redirect部分，可以參照這篇   https://cloudsundial.com/salesforce-oauth-flows  寫得還算詳細。  "},{"id":"content:5.keycloak:3.關於SSO.md","path":"/keycloak/sso","dir":"keycloak","title":"關於SSO","description":"","keywords":["三、SSO 簡述"],"body":"  三、SSO 簡述  OIDC和SAML討論完後，我們來聊聊單一登入（SSO）。SSO是一個身份驗證方案，它讓使用者能透過一次登入就可訪問多個應用程式和網站。簡而言之：   透過單一的登入窗口，進行單一的身分驗證，就可以讓許多的服務共同來使用這個驗證結果  OIDC和SAML都可以實現這樣的SSO功能。舉例來說，假設你在工作中要使用三個不同的平台：   郵件系統（Email System）  公司內部網站（Intranet）  報表和數據分析平台（Analytics Platform）  通常你得記住這三個系統各自的帳號和密碼。但有了SSO，你只需透過一個統一的登入界面（比如由Keycloak管理）登入一次，然後就能自由地訪問這三個不同的平台，無需再逐一輸入帳號和密碼。  總之，SSO幫你將多個獨立的系統集成為單一的入口點。這樣不僅減少了你需要記住多組密碼的困擾，還降低了由於多個系統各自存儧行密碼所帶來的安全風險。  流程範例大致如下：   Step1(箭頭1) : 用者首先訪問「Application 01」的 URL 並按下登入按鈕，然後會被引導到 Keycloak 登入頁面。  Step2: 用戶在 Keycloak 成功登入後，將被重新導向回「Application 01」的主頁。  Step3(箭頭3): 如果用戶在合理的時間內再次訪問「Application 02」，則不需要重新登入。  箭頭2實際上是指示用戶從「應用程式01」被引導到Keycloak的登入頁面這一過程。簡單來說，當用戶嘗試在「應用程式01」登入（箭頭1）後，他們會被重定向到Keycloak以完成身份驗證（箭頭2）。  "},{"id":"content:5.keycloak:4.Keycloak Introduce.md","path":"/keycloak/keycloak-introduce","dir":"keycloak","title":"Keycloak Introduce","description":"我們剛才談到實現SSO（單一登入）的功能，那麼現在問題來了：有沒有一個工具或平台能讓我們更方便地實現這一切呢？答案是有的，那就是Keycloak。Keycloak是一個集成了多種身份驗證和授權機制（包括OIDC和SAML）的開源身份和訪問管理解決方案。","keywords":["2. Keycloak 細部解析"],"body":"  Keycloak Introduce  我們剛才談到實現SSO（單一登入）的功能，那麼現在問題來了：有沒有一個工具或平台能讓我們更方便地實現這一切呢？答案是有的，那就是Keycloak。Keycloak是一個集成了多種身份驗證和授權機制（包括OIDC和SAML）的開源身份和訪問管理解決方案。  Keycloak的特點如下   多協議支持: Keycloak支持OIDC和SAML，所以你不必為了不同的應用而選擇不同的解決方案。  易於管理: Keycloak有一個使用者友善的管理界面，你可以輕鬆設定用戶、角色和權限。  靈活性: 它是開源的，意味著你可以根據自己的需要對它進行定制。  詳細提供以下功能   身分驗證(Authentication)   單點登入/登出（Single Sign-On/Single Sign-Out）: 讓使用者只需登入一次，就能訪問多個不同的應用和服務。  多因素認證（Multi-Factor Authentication, MFA）: 除了密碼外，還可以透過SMS、郵件或其他方法進行身份驗證。  支持外部身分源: AD，LDAP，Social Login(Google, FB...)。  使用者管理（User Management）   使用者身分 CRUD（Create, Read, Update, Delete）: 簡單地管理使用者資訊，包括建立、查詢、更新和刪除。  屬性管理（Attribute Management）: 可以給使用者賬戶添加多種屬性和標籤。  使用者分組（User Grouping）: 組織使用者到不同的群組以方便管理。  授權（Authorization）   Role-Based Access Control(RBA）: 基於角色給予使用者不同的訪問權限。  Attribute-Based Access Control(ABAC）: 根據使用者的特定屬性（如年齡、部門等）來給予權限。  User-based Access Control (UBAC) : 直接對個別用戶賦予權限，而不是通過角色或屬性。這在只有少數用戶需要訪問特定資源的情況下特別有用。  Context-based Access Control (CBAC) : 更動態的授權方式，考慮到目前的情境或環境狀況（如目前正在執行的操作，或者資源的當前狀態）來做出授權決策。  Rule-based Access Control (Using JavaScript) : 使用 JavaScript 程式碼來定義特定的授權規則。這是一個非常靈活的方式，可以根據極其特定的需求來制定授權策略。  Time-based Access Control : 依據時間來決定是否允許訪問，例如只有工作時間允許訪問某個資源。  Support for custom Access Control Mechanism (ACMs) through a Service Provider Interface (SPI) : 高度定制的選項，允許你通過 Service Provider Interface (SPI) 來實現自己的授權機制。這對於需要非常特殊授權邏輯的場景來說是一個非常強大的工具。  安全性（Security）   密碼政策（Password Policies）: 可以設定密碼的複雜度、有效期等。  會話管理（Session Management）: 查看和管理當前活躍的使用者會話。  應用安全（Client Security）: 對接入的客戶端進行安全設定和驗證。  其他   事件監控（Events Monitoring）: 監控和記錄關於認證、授權等的事件。  擴展性（Extensibility）: 支持自定義插件和腳本，以擴展基礎功能。  2. Keycloak 細部解析  a. Keycloak Core  為了充分利用Keycloak，並根據我們的需求進行客製化，我們必須了解其核心組件以及它們是如何互動的。以下為Keycloak Core Block圖     Realm:master：可想像成一個隔離的命名空間，裡面有你的使用者、角色、客戶端等資料。你可以有多個Realm，每個Realm都有其獨立的設定。\n   Client：代表需要與Keycloak進行互動的應用程式或服務。像是網頁應用或API。這些客戶端會使用Keycloak進行身份驗證。  Roles：確定使用者在Client中可以執行哪些操作。  Security Defense：確保Realm的安全性，例如對抗暴力攻擊或強化密碼政策。  User Federation：允許你把外部的使用者來源（如LDAP）連接到Keycloak。  Roles：通常用於定義訪問權限。例如，管理員角色可能允許使用者更改系統設定。  Groups：一組使用者的集合，有助於管理與分配角色。  Events：記錄Keycloak的所有活動，如誰何時登錄或更改設定。  Users：這是指註冊到Realm的使用者。他們可以有不同的角色或屬於不同的群組。  Identity Provider (IdP)：確認使用者身份的部分，允許使用者用像是Google或Facebook這類的外部服務進行登錄。  核心和外部區塊的互動部分。例如，當一個使用者使用Twitter賬號登錄時，Twitter會和Keycloak中的Identity Provider互動，然後IdP再與Realm互動，確認使用者的身份並賦予他適當的角色和權限。  另外這邊稍微提一下Realm裡面的Roles跟外部的Roles有什麼不同   Realm裡面的Roles (Realm-level Roles)：這些角色是直接相對於Realm本身的。一旦你在Realm中定義了一個角色，你就可以將它指派給任何Realm內的使用者。它們通常是更通用的，例如“管理員”或“使用者”，並且可以跨多個客戶端使用。  外部的Roles (Client-level Roles)：這些角色是相對於特定的客戶端（應用程式或服務）的。所以它們是在特定客戶端的上下文中定義和使用的。允許你為每個應用程式定制更具體的角色。例如，你可能有一個\"編輯\"角色在你的CMS系統中，而有一個\"購物者\"角色在你的電商網站中。  簡單來說，Realm內的角色是全域性的，可以在整個Realm中使用，而Client-level角色是特定於某個應用程式的。  b. Kyecloak 角色  使用Keycloak服務時，裡面有幾種角色必須釐清他們的關係   Realm : 每一個Realm在Keycloak中都代表了一個獨特的命名空間或領域。在同一個Keycloak實例中，不同的Realm之間的資料和設定是完全隔離的。例如，行銷部門和研發部門可能有不同的應用程式和使用者，因此他們可以在不同的Realm中被管理。某種程度有點像Project概念。   設定 : 每個Realm都有自己獨特的設定，包括但不限於認證策略、令牌生命週期、SMTP設定等。這意味著你可以為不同的組織或專案客製化其身份和訪問管理策略。  使用者和客戶端 : 每個Realm內都有其專屬的Users和Clients。例如，兩個不同的Realm之間的Users是不可以交互認證的。  事件和審計 : 可以為每個Realm單獨配置事件和審計策略，以追踪和記錄Realm內的活動。  Clients : 通常代表你想要與Keycloak整合的應用程式或服務。定義了如何與那些應用程式或服務進行交互，包括認證方法、回調URL等。例如有一個Web應用程式和一個手機應用程式，兩者都需要身份驗證。在這種情況下，你可以為每個應用程式設定一個Client，並為它們設定不同的認證流程或訪問限制。   設定 : Clients的設定包括如何與其進行認證的具體細節，例如回調URL、認證方法、封裝方法等。包含協議，可能是OpenID Connect、SAML 2.0。  角色 : 你可以在每個Client裡設置特定的角色，這些角色可以賦予給使用者，以決定他們在該Client中可以進行哪些操作。  Users : Users基本上是真實的個體，如員工或客戶。   設定 : 在Keycloak中，User的憑證（如密碼）是存儲在User的設定中。但是，具體的認證流程（例如，如何驗證這些憑證）是由Client來定義的。  與Client的關係 : Users在Clients中獲得訪問令牌，這些令牌決定了他們在該Client中可以進行哪些操作。例如，一個User可能在一個Client中具有\"讀者\"的角色，在另一個Client中具有\"管理員\"的角色。  Groups : Groups代表了一種組織層次結構，可以將Users組合在一起。這允許管理者更容易地管理大量使用者和其訪問權限。   設定 : 跟Users一樣，Groups也可以有其自己的屬性和設定。例如，你可以為某個Group設定一個特定的屬性，然後所有屬於該Group的Users都可以看到或使用這個屬性。  角色賦予 : 可以將角色賦予給一個Group，然後所有屬於那個Group的Users都會繼承這些角色。  靈活性 : 一個User可以同時屬於多個Group。例如，一個User可能同時是\"研發團隊\"和\"高級工程師\"這兩個Groups的成員。  Role : 角色是一種用於表示使用者或群組所擁有的權限的方式。換句話說，角色定義了使用者或群組可以執行哪些操作或訪問哪些資源。例如，您可能有一個\"管理員\"角色，該角色允許使用者訪問和修改所有資源，而\"編輯者\"角色則可能只允許使用者修改，但不能刪除資源。   設定 : 在Keycloak中，角色可以分配給單個使用者或群組。當使用者試圖訪問某個資源或執行某個操作時，系統會檢查他們所分配的角色是否具有所需的權限。  角色的類型：Realm比較偏向Keycloak設定管理權限，客戶端角色比較偏向客戶端API使用權限。  Realm角色：可分配給Realm中的任何使用者或群組。例如，Realm範疇的\"管理員\"角色允許使用者管理整個Realm的設定。  客戶端角色：只能分配給特定客戶端的使用者或群組。例如，一個\"編輯器\"角色在\"新聞應用程式\"客戶端可能意味著使用者可以發布新的新聞文章，但在另一個\"帳單系統\"客戶端，相同的\"編輯器\"角色可能有完全不同的權限。  最後稍微用圖舉個他們關係的例子     Client：在此領域中的應用程式或服務，用戶會透過它進行認證。  Role 1, 2, 3, 4：這些是在該Realm中定義的角色。角色通常代表某些權限或能力。  Users：代表該Realm中的所有用戶。  Group 1, 2, 3… n：代表不同的用戶群組。每個群組可能有不同的權限和角色。  User 1：當此用戶登入時，被賦予了Role 1角色，並且是Group 1, Group 2, 和 Group 3的成員。 而 User 2 用戶登入時，被賦予了Role 2角色，並且是Group 2, Group 3, 和 Group 5的成員。最後User 3 用戶登入時，會被賦予了Role 4角色，並且是Group 2, Group 3, Group 4, 和 Group 5的成員。  可以看到Keycloak如何將角色和群組賦予用戶。這有助於管理哪些用戶可以訪問哪些資源，以及他們可以執行哪些操作。此外，通過將用戶分組，可以輕鬆地管理大量用戶的權限，而不必逐一配置。"},{"id":"content:100.ironman-gcp:Cloud.md","path":"/ironman-gcp/cloud","dir":"ironman-gcp","title":"Cloud","description":"","keywords":[],"body":""},{"id":"content:101.license:1.ACE.md","path":"/license/ace","dir":"license","title":"ACE [模擬考題]","description":"","keywords":[],"body":"  ACE [  模擬考題 ]     Every employee of your company has a Google account. Your operational team needs to manage a large number of instances on Compute Engine. Each member of this team needs only administrative access to the servers. Your security team wants to ensure that the deployment of credentials is operationally efficient and must be able to determine who accessed a given instance. What should you do?     A. Generate a new SSH key pair. Give the private key to each member of your team. Configure the public key in the metadata of each instance.\n  B. Ask each member of the team to generate a new SSH key pair and to send you their public key. Use a configuration management tool to deploy those keys on each instance.\n  C. Ask each member of the team to generate a new SSH key pair and to add the public key to their Google account. Grant the compute.osAdminLogin role to the Google group corresponding to this team.\n  D. Generate a new SSH key pair. Give the private key to each member of your team. Configure the public key as a project- wide public SSH key in your Cloud Platform project and allow project-wide public SSH keys on each instance.\n  \n    解題  答案為C，基本上就是考IAM帳戶管理控制  公司每位員工都有Google帳戶，而運營團隊需要管理大量的Compute Engine實例。每位團隊成員都需要對這些虛擬機器有管理權限，但只限於管理權限，不需要其他額外的權限。希望部署這些訪問權限的方式要高效，且之後能追踪到哪位員工訪問了特定的實例。   A.生成一個新的SSH密鑰對，將私鑰給團隊的每個成員，並在每個實例的元數據中配置公鑰。這種方法的問題在於所有成員共享相同的私鑰，這不僅安全風險高，而且無法追蹤具體人員的訪問。  B.要求團隊的每個成員生成一個新的SSH密鑰對並將他們的公鑰發給你。使用配置管理工具在每個實例上部署這些密鑰。這個方法能夠實現每個成員都有自己的密鑰，從而提高安全性並能追蹤到每個人的訪問，但部署公鑰的過程可能會比較繁瑣。  C.要求團隊的每個成員生成一個新的SSH密鑰對並將公鑰添加到他們的Google帳戶中。給予對應這個團隊的Google群組compute.osAdminLogin角色。這個方法不僅確保了每個成員都有自己的密鑰，還利用了GCP的IAM（Identity and Access Management）功能來管理訪問權限，同時也簡化了密鑰的部署過程。  D. 生成一個新的SSH密鑰對，將私鑰給團隊的每個成員，在你的Cloud Platform項目中配置公鑰為項目範圍內的公開SSH密鑰，並允許在每個實例上使用項目範圍的公開SSH密鑰。這個選項同樣存在A選項的問題，即共享私鑰並不能追蹤到具體個人。     You need to create a custom VPC with a single subnet. The subnet's range must be as large as possible. Which range should you use?   A. 0.0.0.0/0\nB. 10.0.0.0/8\nC. 172.16.0.0/12\nD. 192.168.0.0/16\n  \n    解題  答案為B，考CIDR（Classless Inter-Domain Routing）  詢問如何在Google Cloud Platform（GCP）上創建一個自定義虛擬私有雲（VPC）並設定一個單一子網，使得這個子網的IP範圍盡可能大。   A. 0.0.0.0/0 - 這個範圍代表所有可能的IPv4地址，但它不是一個實際可用於子網的範圍，因為它用於特殊目的（例如路由規則中表示任何地址）。  B. 10.0.0.0/8 - 這個範圍在私有地址空間中是可用的，並且提供了最大的IP地址範圍，大約有16777216個可用地址（2^24）。這是一個廣泛用於大型網絡的範圍。 (/8表示前8位是網絡地址，剩下的24位（32-8=24）是主機地址。所以，可以有224224個可能的地址。)  C. 172.16.0.0/12 - 這也是私有地址空間的一部分，但提供的地址數量少於10.0.0.0/8範圍，大約有1048576個可用地址（2^20）。(/12表示前12位是網絡地址，剩下的20位（32-12=20）是主機地址。所以，可以有220220個可能的地址。)  D. 192.168.0.0/16 - 這個範圍同樣屬於私有地址空間，提供的IP地址數量更少，大約有65536個可用地址（2^16）。(/16表示前16位是網絡地址，剩下的16位（32-16=16）是主機地址。所以，可以有216216個可能的地址。)     You want to select and configure a cost-effective solution for relational data on Google Cloud Platform. You are working with a small set of operational data in one geographic location. You need to support point-in-time recovery. What should you do?   A. Select Cloud SQL (MySQL). Verify that the enable binary logging option is selected. \nB. Select Cloud SQL (MySQL). Select the create failover replicas option.\nC. Select Cloud Spanner. Set up your instance with 2 nodes.\nD. Select Cloud Spanner. Set up your instance as multi-regional.\n \n   \n    解題  答案是A，考Cloud SQL 及對 Cloud Spanner 選用上認知  這個問題是關於在Google Cloud Platform（GCP）上選擇和配置一個成本效益高的關聯式數據存儲解決方案。考慮的情境是你正在處理一個小型的運營數據集，而且這些數據只需要在一個地理位置存儲。此外，你需要支持點時間恢復（Point-in-Time Recovery, PITR），這意味著你需要能夠恢復到數據庫在過去任何一個特定時間點的狀態。   A. 選擇Cloud SQL (MySQL)。確保選擇了啟用二進制日誌記錄選項。   Cloud SQL是一個完全管理的關聯式數據庫服務，支持MySQL等流行的數據庫系統。啟用二進制日誌記錄是支持點時間恢復的一個要求，因為它可以記錄數據庫的所有更改，從而允許恢復到特定的時間點。   B. 選擇Cloud SQL (MySQL)。選擇創建故障轉移副本選項。   創建故障轉移副本提高了數據庫的可用性和災難恢復能力，但它不直接與支持點時間恢復的需求相關。   C. 選擇Cloud Spanner。設置你的實例為2個節點。   Cloud Spanner是一個完全管理的、水平可擴展的關聯式數據庫服務，支持全球分佈的數據庫和強一致性。但對於一個小型數據集且只在一個地理位置的需求來說，Cloud Spanner可能是一個過於昂貴的選項，尤其是當只需要點時間恢復這一特定功能時。   D. 選擇Cloud Spanner。設置你的實例為多區域。   這個選項提供了高可用性和災難恢復能力，但與C選項一樣，對於小型數據集來說，這是一個成本較高的解決方案，並且超出了只需要一個地理位置存儲的需求。     You want to configure autohealing for network load balancing for a group of Compute Engine instances that run in multiple zones, using the fewest possible steps. You need to configure re-creation of VMs if they are unresponsive after 3 attempts of 10 seconds each. What should you do?   A. Create an HTTP load balancer with a backend configuration that references an existing instance group. Set the health check to healthy (HTTP)\nB. Create an HTTP load balancer with a backend configuration that references an existing instance group. Define a balancing mode and set the maximum RPS to 10.\nC. Create a managed instance group. Set the Autohealing health check to healthy (HTTP)\nD. Create a managed instance group. Verify that the autoscaling setting is on.\n \n   \n    解題  答案是C， ref :   https://cloud.google.com/compute/docs/tutorials/high-availability-autohealing  這題考的是如何在Google Cloud Platform上為運行在多個區域的Compute Engine實例群組配置網絡負載均衡的自動修復功能，並且要求用盡可能少的步驟完成。自動修復功能能夠檢測到實例因無響應而失效時自動重新創建實例。具體來說，題目要求配置系統在實例經過3次每次10秒的嘗試無響應後進行重新創建。   A. 創建一個HTTP負載均衡器，並且配置後端參照一個現有的實例群組。設置健康檢查為健康(HTTP): 這個選項設置了HTTP負載均衡器並使用健康檢查，但是主要聚焦在流量分配而非自動修復。  B. 創建一個HTTP負載均衡器，並且配置後端參照一個現有的實例群組。定義一個平衡模式並設置最大RPS為10: 這個選項同樣是設置HTTP負載均衡器，聚焦在處理請求的能力上，與自動修復無關。  C. 創建一個管理的實例群組。設置自動修復健康檢查為健康(HTTP): 這個選項直接指向了自動修復的需求，通過在管理的實例群組中設置健康檢查來達到當實例無響應時自動重新創建的目標。  D. 創建一個管理的實例群組。驗證自動擴展設置是否開啟: 雖然這個選項涉及到管理的實例群組，但是它聚焦在自動擴展上，與問題中要求的自動修復功能不直接相關。     You are using multiple configurations for gcloud. You want to review the configured Kubernetes Engine cluster of an inactive configuration using the fewest possible steps. What should you do?   A. Use gcloud config configurations describe to review the output.\nB. Use gcloud config configurations activate and gcloud config list to review the output. \nC. Use kubectl config get-contexts to review the output.\nD. Use kubectl config use-context and kubectl config view to review the output.\n \n    \n    解題  答案是D，考gcloud config指令在GKE上應用  如何在使用Google Cloud SDK（gcloud）的多配置環境中，用最少的步驟審查一個不活躍配置下的Kubernetes Engine集群配置。   A. 使用gcloud config configurations describe來審查輸出。 這個命令用於顯示當前或指定配置的詳細信息，但不直接針對Kubernetes Engine集群的配置。  B. 使用gcloud config configurations activate命令可以切換到一個特定的配置，然後使用gcloud config list可以查看當前激活配置的詳細設置。這個方法直接關聯到gcloud工具和Google Cloud平台的配置，但它更多地是關於查看gcloud CLI的配置，而不直接指向Kubernetes Engine集群的具體配置。  C. kubectl config get-contexts命令顯示所有可用的上下文。每個上下文代表一個連接到特定Kubernetes集群的設定。這個命令快速顯示了所有配置的上下文，但它不切換到這些上下文或直接審查它們的細節。  D. kubectl config use-context允許你切換到一個特定的Kubernetes上下文（這個上下文可能是指向一個特定的Kubernetes Engine集群），而kubectl config view能夠讓你查看當前的kubectl配置，包括與所選上下文相關的配置。這對於審查Kubernetes Engine集群的配置來說，是一種更直接的方法。     Your company uses Cloud Storage to store application backup files for disaster recovery purposes.\nYou want to follow Google's recommended practices. Which storage option should you use?   A. Multi-Regional Storage\nB. Regional Storage\nC. Nearline Storage\nD. Coldline Storage\n \n   \n    解題  答案是D, 考對Storage認知，基本上題目提到備份檔案，代表要存取的資料時長時間不會去異動他的，所以答案選Coldline Storage(D)。  使用雲端儲存來儲存應用程式的備份檔案，目的是為了災難恢復。並且遵循Google的建議做法。當我們說備份檔案是為了diaster恢復，這意味著這些文件不太可能經常被存取，但在必要時需要能迅速取得。   A. 資料會分散儲存在多個區域中，主要適用於那些需要在全球多個地點進行高頻率存取的數據。適用情境: 如果你有一個網站或應用，並希望全球的用戶都能快速存取資料。  B. 資料僅儲存在特定的區域中。這意味著它比多區域儲存更有地域性，但同時也具有高的存取速度。適用情境: 如果你的應用或服務主要是針對某一特定地理區域的用戶，例如只在亞洲。  C. 是一種低成本的儲存方式，適用於那些你不經常需要存取，但當需要時，你希望能在數秒內獲取的數據。適用情境: 假設你有一些資料，大概每月需要查看或使用一次。可選擇Nearline Storage  D. 用於那些很少存取的資料，但可能在未來需要它們。成本非常低，但取得資料時可能需要較長的時間。適用情境: 如果你有需要長期保存但很少存取的資料，例如備份或檔案存檔，那麼冷儲存是個好選擇。     Several employees at your company have been creating projects with Cloud Platform and paying for it with their personal credit cards, which the company reimburses. The company wants to centralize all these projects under a single, new billing account. What should you do?   A. Contact cloud-billing@google.com with your bank account details and request a corporate billing account for your company.\nB. Create a ticket with Google Support and wait for their call to share your credit card details over the phone.\nC. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organizarion.\nD. In the Google Cloud Platform Console, create a new billing account and set up a payment method.\n \n    \n    解題  答案為D  探討的是如何將一個公司內多個員工為了工作目的而分別使用個人信用卡支付的Google雲端平台（GCP）項目，統一到一個公司的計費帳戶下。這樣做的目的是為了讓公司能夠更有效地管理雲端資源的費用和項目，避免個別員工需要先行支付然後再報銷的不便和風險。   A. 聯絡Google的計費部門的電子郵件地址，並提供你的銀行帳戶詳細資訊，請求為公司建立一個企業計費帳戶。  B. 通過創建支持票務並等待通話來分享信用卡詳細資訊。這個選項在處理計費問題時通常不是推薦的做法，因為涉及到信用卡資訊的共享應該通過安全的方法進行。  C. 在Google雲端平台控制台中，前往資源管理器並將所有項目移至根組織。這個選項解決了項目組織的問題，但並未直接解決計費帳戶的統一問題。  D. 在Google雲端平台控制台中創建一個新的計費帳戶並設置支付方式。這是解決問題的直接方法，允許公司設置一個中央計費帳戶並將所有現有和未來的項目關聯到這個帳戶。這樣，公司可以直接管理所有雲端資源的費用，而不需要員工個別支付並求報銷。     You have an application that looks for its licensing server on the IP 10.0.3.21. You need to deploy the licensing server on Compute Engine. You do not want to change the configuration of the application and want the application to be able to reach the licensing server. What should you do?   A. Reserve the IP 10.0.3.21 as a static internal IP address using gcloud and assign it to the licensing server.\nB. Reserve the IP 10.0.3.21 as a static public IP address using gcloud and assign it to the licensing server.\nC. Use the IP 10.0.3.21 as a custom ephemeral IP address and assign it to the licensing server.\nD. Start the licensing server with an automatic ephemeral IP address, and then promote it to a static internal IP address\n \n    \n    解題  答案為A  有一個應用程式，該應用程式依賴於一個具有固定IP地址（10.0.3.21）的伺服器。你需要在Google Compute Engine上部署這個伺服器，而且不希望更改應用程式的配置。你應該怎麼做才能讓應用程式能夠正確地連接到這個伺服器？   A. 此選項建議使用gcloud命令行工具預先保留10.0.3.21作為靜態內部IP地址，並將其分配給認證伺服器。  B. 此選項建議使用gcloud工具將10.0.3.21保留為靜態公共IP地址。  C. 使用10.0.3.21作為臨時（ephemeral）IP地址  D. 建議首先使用自動分配的臨時IP啟動認證伺服器，然後再將其提升（或更改）為靜態內部IP地址。  上述四個選項以A的設定，就算VM重啟，IP地址也會保持不變。其餘三個，B實作上不建議使用公用IP，C的話臨時IP會在虛擬機重啟或停止會更動，最後D在VM啟動後，還需要進行額外的步驟更改IP地址。選項A是最好的解決方案，因為它確保了即使虛擬機器重啟，IP地址也會保持不變。而且它使用的是內部IP，適合於內部應用程式和伺服器之間的通信。     You are deploying an application to App Engine. You want the number of instances to scale based on request rate. You need at least 3 unoccupied instances at all times. Which scaling type should you use?   A. Manual Scaling with 3 instances.\nB. Basic Scaling with min_instances set to 3.\nC. Basic Scaling with max_instances set to 3\nD. Automatic Scaling with min_idle_instances set to 3.\n \n    \n    解題  D、ref:  https://cloud.google.com/appengine/docs/legacy/standard/python/how-instances-are-managed  題目希望您選擇一個scale策略，使應用程式的Instance可以基於請求速率自動調整，而且任何時候都至少有3個未被使用的實例。   A. 手動設定要運行的實例數量，不考慮當前的請求量。  B. 基本Scale基於請求速率和其他指標進行伸縮，但它也允許您設定最小實例數量。  C. 設定最多只能有3個實例運行，這不符合題目要求始終有3個“未被使用”的實例。  D. 自動伸縮允許實例數量根據實際的請求負載動態調整。  答案D，這題很明顯D為Automatic Scaling，字面上意思就是確保了有3個始終未被使用的實例，並且會根據請求速率自動調整其他實例數量。稍微提一下min_instances與min_idle_instances不一樣。min_instances只保證至少有3個實例運行，不管它們是否處於空閒狀態。min_idle_instances確保有3個實例始終處於空閒狀態，所以隨時可以開始處理新的請求。   補充：\nAn instance of an auto-scaled service is always running. \nHowever, an instance of a manual or basic scaled service can be either running or stopped. \nAll instances of the same service and version share the same state.\n     You have a development project with appropriate IAM roles defined. You are creating a production project and want to have the same IAM roles on the new project, using the fewest possible steps. What should you do?   A. Use gcloud iam roles copy and specify the production project as the destination project.\nB. Use gcloud iam roles copy and specify your organization as the destination organization.\nC. In the Google Cloud Platform Console, use the 'create role from role' functionality.\nD. In the Google Cloud Platform Console, use the 'create role' functionality and select all applicable permissions\n \n    \n    解題  A  如何最有效地在新的專案中複製或遷移既有的IAM角色設定。   A. 使用gcloud iam roles copy並指定生產專案作為目標專案。 這個選項建議使用gcloud命令行工具來直接複製一個角色到另一個專案。  B. 使用gcloud iam roles copy並指定你的組織作為目標組織。 這個選項也是使用gcloud命令行工具，但是建議將角色複製到整個組織範圍，這樣所有專案都能夠繼承這個角色。  C. 在Google Cloud Platform Console中，使用'create role from role'功能。 這個選項建議在GCP控制台中使用一個具體功能來從一個現有角色創建一個新角色。  D. 在Google Cloud Platform Console中，使用'create role'功能並選擇所有適用的權限。 這個選項建議手動在GCP控制台中創建一個新角色，並從頭開始選擇所需的權限。  答案是A，C沒有這個指令     You need a dynamic way of provisioning VMs on Compute Engine. The exact specifications will be in a dedicated configuration file. You want to follow Google's recommended practices. Which method should you use?   A. Deployment Manager\nB. Cloud Composer\nC. Managed Instance Group\nD. Unmanaged Instance Group\n \n   \n    解題  A  這個問題是關於在Google Cloud Platform（GCP）上動態配置和管理虛擬機（VMs）的最佳方法。特別是，它詢問如何根據一個專門的配置文件準確地配置VMs，同時遵循Google推薦的實踐。  A. Deployment Manager 已經於2022年終止服務，官方建議使用KRM 或 Terraform。原使用方法應為配置Yaml使其可以自動建置與增加VM。  B. Cloud Composer基於 Apache Airflow，是一個完全管理的工作流程自動化工具，用於建立、計畫、監控和管理工作流程。比較像在自動化建立GCP相關服務並整合  C. Managed Instance Group (MIG) (Migrate to Virtual Machines) 支持負載均衡、自動擴展和滾動更新，確保指定數量的實例始終是健康的和運行的。例如，如果MIG中的一個實例失效，MIG會自動替換該實例，以維持所需的實例數量。MIG還可以基於CPU使用率或其他指標動態調整實例的數量。  D. Unmanaged Instance Group 允許您組織一組單獨的實例，但不自動管理實例的生命週期。     You have a Dockerfile that you need to deploy on Kubernetes Engine. What should you do?   A. Use kubectl app deploy <dockerfilename>.\nB. Use gcloud app deploy <dockerfilename>.\nC. Create a docker image from the Dockerfile and upload it to Container Registry. \n   Create a Deployment YAML file to point to that image. Use kubectl to create the deployment with that file.\nD. Create a docker image from the Dockerfile and upload it to Cloud Storage. \n   Create a Deployment YAML file to point to that image. Use kubectl to create the deployment with that file.\n \n   \n    解題  C,  這個問題是關於如何在Google Kubernetes Engine (GKE) 上部署一個Docker容器。具體來說，它詢問當你有一個Dockerfile時，應該怎麼做才能將它部署到Kubernetes集群中。  A. 使用kubectl app deploy   。 這個命令格式並不正確，kubectl沒有app deploy這個指令。  B. 使用gcloud app deploy   。 這是Google Cloud Platform上的App Engine應用部署命令，用於部署App Engine應用，而不是用於Kubernetes Engine上部署Docker容器。  C. 從Dockerfile創建一個docker映像並將其上傳到Container Registry。創建一個指向該映像的Deployment YAML文件。使用kubectl來用該文件創建部署。 這是一個典型的流程，用於在Kubernetes上部署容器化應用。首先，你需要從Dockerfile構建一個Docker映像，然後將該映像推送到一個容器映像庫（在這裡是Google Container Registry）。接著，你需要創建一個Deployment的YAML配置文件，指定如何運行你的容器映像，最後使用kubectl命令來根據YAML文件創建部署。  D.  從Dockerfile創建一個docker映像並將其上傳到Cloud Storage。創建一個指向該映像的Deployment YAML文件。使用kubectl來用該文件創建部署。 這個選項建議將映像上傳到Google Cloud Storage，但這不是容器映像的標準存儲方式。通常，容器映像應該被推送到一個容器註冊中心，如Google Container Registry或Docker Hub。     Your development team needs a new Jenkins server for their project. You need to deploy the server using the fewest steps possible. What should you do?   A. Download and deploy the Jenkins Java WAR to App Engine Standard.\nB. Create a new Compute Engine instance and install Jenkins through the command line interface.\nC. Create a Kubernetes cluster on Compute Engine and create a deployment with the Jenkins Docker image.\nD. Use GCP Marketplace to launch the Jenkins solution.\n \n   \n    解題  D  您的開發團隊需要一個新的Jenkins伺服器用於他們的專案。您需要使用最少的步驟來部署伺服器。您應該怎麼做？  A. 下載並部署Jenkins Java WAR到App Engine Standard。  B. 創建一個新的Compute Engine實例並通過命令行介面安裝Jenkins。  C. 在Compute Engine上創建一個Kubernetes集群，並使用Jenkins Docker映像創建一個部署。  D. 使用GCP Marketplace啟動Jenkins解決方案。    https://cloud.google.com/solutions/using-jenkins-for-distributed-builds-on-compute-engine     You need to update a deployment in Deployment Manager without any resource downtime in the deployment. Which command should you use?   A. gcloud deployment-manager deployments create --config <deployment-config-path>\nB. gcloud deployment-manager deployments update --config <deployment-config-path>\nC. gcloud deployment-manager resources create --config <deployment-config-path>\nD. gcloud deployment-manager resources update --config <deployment-config-path>\n \n    \n    解題  B  如何使用Google Cloud Deployment Manager來更新一個現有部署，同時確保更新過程中不會導致任何資源的停機。Deployment Manager是一個基於資源的配置管理系統，允許你使用模板來自動創建、更新和管理Google Cloud資源。  A: 這個命令用於創建一個新的部署，並不適用於更新現有部署  B: 這個命令用於更新一個現有的部署。如果你的目標是在不停機的情況下更新部署，這是正確的選擇。  C: 這個命令用於創建新資源，而不是更新現有部署。  D: 這個選項不是一個實際存在的命令。在Deployment Manager中，資源的更新是通過更新部署來實現的，而不是直接對資源進行更新。 \n      You need to run an important query in BigQuery but expect it to return a lot of records. You want to find out how much it will cost to run the query. You are using on-demand pricing. What should you do?   A. Arrange to switch to Flat-Rate pricing for this query, then move back to on-demand.\n\nB. Use the command line to run a dry run query to estimate the number of bytes read. Then convert that bytes estimate to dollars using the Pricing Calculator.\n\nC. Use the command line to run a dry run query to estimate the number of bytes returned. Then convert that bytes estimate to dollars using the Pricing Calculator.\n\nD. Run a select count (*) to get an idea of how many records your query will look through. Then convert that number of rows to dollars using the Pricing Calculator.\n \n   \n    解題  B  這個問題是關於如何在使用Google Cloud BigQuery時，事先估算出一個查詢操作的成本。BigQuery是Google Cloud提供的一個大數據分析平台，它允許用戶存儲和查詢大量數據。BigQuery提供兩種計費模式：按需定價（on-demand pricing）和固定費率定價（flat-rate pricing）。按需定價根據查詢處理的數據量計費，而固定費率定價則允許用戶為一定的查詢容量支付固定費用。  A. 安排在這次查詢時切換到固定費率定價，然後再切回按需定價。 這個選項在技術上可行，但對於一次查詢來說過於繁瑣，且並非成本估算的直接方法。  B. 使用命令行運行一次試運行（dry run）查詢來估算讀取的字節數。然後使用定價計算器將這個字節估算轉換成美元。 這是一個有效的方法，因為BigQuery的按需定價是根據查詢分析的數據量來計費的，而不是基於返回的記錄數。這允許用戶在實際運行查詢前獲得成本估算。簡單來說按需定價可以做一個模擬估算的意思。  C. 使用命令行運行一次試運行查詢來估算返回的字節數。然後使用定價計算器將這個字節估算轉換成美元。 這個選項似乎有誤，因為BigQuery的費用是根據查詢過程中掃描的數據量來計算的，而不是基於查詢結果返回的數據量。  D. 運行一個select count (*)查詢來獲得你的查詢將查看多少記錄。然後使用定價計算器將這個行數轉換成美元。 這個方法不適用於估算成本，因為它並不考慮查詢實際上會掃描多少數據。BigQuery的費用計算基於查詢的數據量，而不是結果集的大小。     You have a single binary application that you want to run on Google Cloud Platform. You decided to automatically scale the application based on underlying infrastructure CPU usage. Your organizational policies require you to use virtual machines directly. You need to ensure that the application scaling is operationally efficient and completed as quickly as possible. What should you do?   A. Create a Google Kubernetes Engine cluster, and use horizontal pod autoscaling to scale the application.\nB. Create an instance template, and use the template in a managed instance group with autoscaling configured.\nC. Create an instance template, and use the template in a managed instance group that scales up and down based on the time of day.\nD. Use a set of third-party tools to build automation around scaling the application up and down, based on Stackdriver CPU usage monitoring.\n \n   \n    解題  B  這題在問的是，當你有一個單一的二進制應用程式，並希望在Google Cloud Platform（GCP）上運行這個應用程式時，如何根據底層基礎設施的CPU使用率自動調整應用程式的規模，同時要求操作效率高且迅速完成，而且還要遵循組織政策直接使用虛擬機（VM）。  A. 建立一個 GKE，使用橫向自動擴展設定應用 (題目要求用VM)  B. 建立一個 instance template ，並在 managed instance group 搭配 autoscaling configured 使用該template  C. 建立一個 instance template ，並在 managed instance group 中使用該模板，該 instance group 根據時間進行縮放  D. 使用第三方工具，基於 Stackdriver CPU 監看自動擴縮應用程式  最適合的選項是B：創建一個實例模板，並在一個配置了自動擴展的管理實例群組中使用該模板。這樣可以直接在虛擬機上運行應用程式，並根據CPU使用率自動調整應用程式的規模，符合操作效率高且快速完成的要求。選項C和D提供了基於時間或使用第三方工具的解決方案，這可能不如直接使用GCP內建的功能那樣操作高效且快速。   Instance template（實例模板）是一種Google Cloud Platform（GCP）的資源，用於定義虛擬機實例的配置。當你需要創建許多具有相同配置的虛擬機時，實例模板可以幫助你實現快速且一致的部署。     You are analyzing Google Cloud Platform service costs from three separate projects. You want to use this information to create service cost estimates by service type, daily and monthly, for the next six months using standard query syntax. What should you do?   A. Export your bill to a Cloud Storage bucket, and then import into Cloud Bigtable for analysis.\nB. Export your bill to a Cloud Storage bucket, and then import into Google Sheets for analysis.\nC. Export your transactions to a local file, and perform analysis with a desktop tool.\nD. Export your bill to a BigQuery dataset, and then write time window-based SQL queries for analysis.\n \n    \n    解題  D  這道題目是關於如何使用Google Cloud Platform（GCP）上的工具來分析三個不同項目的服務成本，並基於這些資料來預估未來六個月每種服務類型的日常和月度成本。選項中提供了不同的方法來達成這個目標，問題在於找出最合適的方式。  A. 將你的賬單導出到Cloud Storage桶，然後導入到Cloud Bigtable進行分析。 Cloud Bigtable是一個高效能的NoSQL數據庫服務，適用於大規模數據分析，但它可能不是分析賬單數據最直觀或成本效益最高的選擇。  B. 將你的賬單導出到Cloud Storage桶，然後導入到Google Sheets進行分析。 Google Sheets是一個雲端試算表應用，適合進行較小規模的數據分析和預算規劃，但可能不適合處理大量資料或進行複雜的時間窗口基礎的SQL查詢。  C. 將你的交易記錄導出到本地文件，並使用桌面工具進行分析。 這是一個選項，但它可能不利於自動化或規模化分析，且無法充分利用GCP提供的強大數據處理能力。  D. 將你的賬單導出到一個BigQuery數據集，然後撰寫基於時間窗口的SQL查詢進行分析。 BigQuery是一個企業級的數據倉庫服務，支持快速SQL查詢，非常適合進行大規模數據分析。通過將賬單數據導入BigQuery，你可以利用其強大的分析能力來執行複雜的查詢，如基於時間窗口的成本預估。  選項D是最佳選擇，因為它允許你利用BigQuery的強大查詢能力來分析賬單數據，並預測未來幾個月的服務成本。這種方法支持標準查詢語法，適合進行複雜的時間序列分析，且能夠處理大量數據，非常適合於成本估算的需求。     You need to set up a policy so that videos stored in a specific Cloud Storage Regional bucket are moved to Coldline after 90 days, and then deleted after one year from their creation. How should you set up the policy?   A. Use Cloud Storage Object Lifecycle Management using Age conditions with SetStorageClass and Delete actions. Set the SetStorageClass action to 90 days and the Delete action to 275 days (365-90).\n\nB. Use Cloud Storage Object Lifecycle Management using Age conditions with SetStorageClass and Delete actions. Set the SetStorageClass action to 90 days and the Delete action to 365 days.\n\nC. Use gsutil rewrite and set the Delete action to 275 days (365-90).\n\nD. Use gsutil rewrite and set the Delete action to 365 days.\n  \n    解題  B  如何設定一個策略，使得特定的Cloud Storage區域性儲存桶中的影片檔案在創建後90天自動轉移到Coldline存儲類別，並在創建後一年被自動刪除。  要實現這一點，你需要使用Cloud Storage的物件生命周期管理功能。物件生命周期管理允許你根據指定的條件（例如文件的年齡、存儲類別等）自動執行操作（如刪除文件或改變文件的存儲類別）。這是通過在儲存桶中設定規則來完成的。  A: 使用Cloud Storage物件生命周期管理，根據文件年齡設定SetStorageClass和Delete動作。將SetStorageClass動作設定為90天，Delete動作設定為275天（365-90）。這個選項的計算方法錯誤，因為它假設你需要在轉移後的時間計算刪除動作，但是Delete應該從原始創建日期計算365天。  B: 使用Cloud Storage物件生命周期管理，根據文件年齡設定SetStorageClass和Delete動作。將SetStorageClass動作設定為90天，Delete動作設定為365天。這是正確的設定方式，因為它確保了文件在創建後90天轉移到Coldline，並在創建後一年被刪除，無論其在90天時的存儲類別變更。  C 和 D: 使用gsutil rewrite命令並設定Delete動作。這些選項並不支持自動基於檔案年齡轉換存儲類別或自動刪除檔案的功能。     You have a Linux VM that must connect to Cloud SQL. You created a service account with the appropriate access rights. You want to make sure that the VM uses this service account instead of the default Compute Engine service account. What should you do?   A. When creating the VM via the web console, specify the service account under the 'Identity and API Access' section.\n\nB. Download a JSON Private Key for the service account. On the Project Metadata, add that JSON as the value for the key compute-engine-service- account.\n\nC. Download a JSON Private Key for the service account. On the Custom Metadata of the VM, add that JSON as the value for the key compute-engine-service-account.\n\nD. Download a JSON Private Key for the service account. After creating the VM, ssh into the VM and save the JSON under ~/.gcloud/compute-engine-service-account.json.\n \n   \n    解題     You created an instance of SQL Server 2017 on Compute Engine to test features in the new version. You want to connect to this instance using the fewest number of steps. What should you do?   A. Install a RDP client on your desktop. Verify that a firewall rule for port 3389 exists.\n\nB. Install a RDP client in your desktop. Set a Windows username and password in the GCP Console. Use the credentials to log in to the instance.\n\nC. Set a Windows password in the GCP Console. Verify that a firewall rule for port 22 exists. Click the RDP button in the GCP Console and supply the credentials to log in.\n\nD. Set a Windows username and password in the GCP Console. Verify that a firewall rule for port 3389 exists. Click the RDP button in the GCP Console, and supply the credentials to log in\n \n    \n    解題"}]